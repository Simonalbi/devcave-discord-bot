<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/" version="2.0">
    <channel>
        <title>New blog articles in Microsoft Community Hub</title>
        <link>https://techcommunity.microsoft.com/t5/</link>
        <description>Microsoft Community Hub</description>
        <pubDate>Sat, 28 Feb 2026 12:42:06 GMT</pubDate>
        <dc:creator>Community</dc:creator>
        <dc:date>2026-02-28T12:42:06Z</dc:date>
        <item>
            <title>GenRec Direct Learning: Moving Ranking from Feature Pipelines to Token-Native Sequence Modeling</title>
            <link>https://techcommunity.microsoft.com/t5/microsoft-developer-community/genrec-direct-learning-moving-ranking-from-feature-pipelines-to/ba-p/4494252</link>
            <description>&lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Authors: Chunlong Yu, Han Zheng, Jie Zhu, I-Hong Jhuo, Li Xia, Lin Zhu, Sawyer Shen&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559740&amp;quot;:276}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;H4&gt;&lt;SPAN class="lia-text-color-21"&gt;&lt;STRONG&gt;TL;DR&amp;nbsp;&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Most modern ranking stacks rely on large generative models as&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;feature extractors&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;, flattening their outputs into vectors that are then fed into downstream rankers. While effective, this pattern introduces&amp;nbsp;additional&amp;nbsp;pipeline complexity and often dilutes token‑level semantics.&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;GenRec&amp;nbsp;Direct Learning (DirL)&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;explores a different direction: using a&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;generative, token‑native sequential model&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;as the ranking engine itself. In this formulation, ranking becomes an&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;end‑to‑end sequence modeling&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;problem over user behavior, context, and candidate items—without an explicit feature‑extraction stage.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Why revisit the classic L2 ranker design?&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Large‑scale recommender systems have historically evolved as layered pipelines: more signals lead to more feature plumbing, which in turn introduces more&amp;nbsp;special cases. In our&amp;nbsp;previous&amp;nbsp;L2 ranking architecture, signals were split into&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;dense&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;and&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;sparse&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;branches and merged late in the stack (Fig. 1). As the system matured, three recurring issues became increasingly&amp;nbsp;apparent.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P class="lia-align-center"&gt;&lt;SPAN data-contrast="auto"&gt;Figure 1: traditional&amp;nbsp;ranking DNN&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335551550&amp;quot;:2,&amp;quot;335551620&amp;quot;:2}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;1) Growing pipeline surface area&lt;/SPAN&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;Each new signal expands the surrounding ecosystem—feature definitions, joins, normalization logic, validation, and offline/online parity checks. Over time, this ballooning surface area slows iteration, raises operational overhead, and increases the risk of subtle production inconsistencies.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;2) Semantics diluted by flattening&lt;/SPAN&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;Generative models naturally capture rich structure: token‑level interactions, compositional meaning, and contextual dependencies. However, when these representations are flattened into sparse or dense feature vectors, much of that structure is lost—undermining the very semantics that make generative representations powerful.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;3) Sequence modeling is treated as an add-on&lt;/SPAN&gt;&lt;/STRONG&gt;&amp;nbsp;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;While traditional rankers can ingest history features, modeling long behavioral sequences and fine‑grained temporal interactions typically&amp;nbsp;requires&amp;nbsp;extensive manual feature engineering. As a result, sequence modeling is often&amp;nbsp;bolted on&amp;nbsp;rather than treated as a first‑class concern.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;DirL goal:&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;treat ranking as&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;native sequence learning&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;, not as “MLP over engineered features.”&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;img /&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;What “Direct Learning” means in DirL&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;The core shift behind&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Direct Learning (DirL)&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;is simple but fundamental.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Instead of the conventional pipeline:&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;generative model → embeddings → downstream ranker,&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;DirL adopts an end‑to‑end formulation:&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;tokenized sequence → generative sequential model → ranking score(s).&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;In DirL, user context, long‑term behavioral history, and candidate item information are all represented within a single, unified token sequence. Ranking is then performed directly by a generative, token‑native sequential model.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;This design enables several key capabilities:&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Long‑term behavior modeling beyond&amp;nbsp;short summary&amp;nbsp;windows&lt;/SPAN&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;The model&amp;nbsp;operates&amp;nbsp;over extended user histories, allowing it to capture long‑range dependencies and evolving interests that are difficult to&amp;nbsp;represent&amp;nbsp;with fixed‑size aggregates.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Fine‑grained user–content interaction learning&lt;/SPAN&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;By modeling interactions at the token level, DirL learns detailed behavioral and content patterns rather than relying on&amp;nbsp;coarse, pre‑engineered features.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Preserved cross‑token semantics within the ranking model&lt;/SPAN&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;Semantic structure is&amp;nbsp;maintained&amp;nbsp;throughout the ranking process, instead of being collapsed into handcrafted dense or sparse vectors before scoring.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559685&amp;quot;:720}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559685&amp;quot;:720}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Architecture overview (from signals to ranking)&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;1) Unified Tokenization&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;All inputs in DirL are converted into a&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;shared token embedding space&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;, allowing heterogeneous signals to be modeled within a single sequential backbone. Conceptually, each input sequence consists of three token types:&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;User / context tokens&lt;/SPAN&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;These tokens encode&amp;nbsp;user&amp;nbsp;or request‑level information, such as age or cohort‑like attributes, request or canvas context, temporal signals (e.g., day or time), and user‑level statistics like historical CTR.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;History tokens&lt;/SPAN&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;These&amp;nbsp;represent&amp;nbsp;prior user interactions over time, including signals such as&amp;nbsp;engaged&amp;nbsp;document IDs, semantic or embedding IDs, and topic‑like attributes. Each interaction is mapped to a token, preserving temporal order and enabling long‑range behavior modeling.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Candidate tokens&lt;/SPAN&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;Each candidate item to be scored is represented as a token constructed from document features and user–item interaction features. These features are concatenated and projected into a fixed‑dimensional&amp;nbsp;vector&amp;nbsp;via an MLP, yielding a token compatible with the shared embedding space.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Categorical features are embedded directly, while dense numerical signals are passed through MLP layers before being fused into their corresponding tokens.&amp;nbsp;As a result, the model backbone consumes a sequence of the form:&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;[1 user/context token] + [N history tokens] + [1 candidate token]&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;2) Long-sequence modeling backbone (HSTU)&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;To model long input sequence, DirL adopts a sequential backbone designed to scale beyond naïve full attention. In the current setup, the backbone consists of stacked HSTU layers with multi‑head attention and dropout for regularization. The hidden state of the candidate token from the final HSTU layer is then fed into an&amp;nbsp;MMoE&amp;nbsp;module for scoring.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;3) Multi-task prediction head (MMoE)&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Ranking typically&amp;nbsp;optimizes&amp;nbsp;multiple&amp;nbsp;objectives&amp;nbsp;(e.g., engagement‑related proxies). DirL employs a multi‑gate mixture‑of‑experts (MMoE) layer to support multi‑task prediction while sharing representation learning.&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;The&amp;nbsp;MMoE&amp;nbsp;layer consists of N shared experts and one task‑specific expert per task. For each task, a gating network produces a weighted combination of the shared experts and the task‑specific expert. The aggregated representation is then fed into a task‑specific MLP head to produce the final prediction.&amp;nbsp;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P class="lia-align-center"&gt;&lt;SPAN data-contrast="auto"&gt;Figure 2: DirL structure&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335551550&amp;quot;:2,&amp;quot;335551620&amp;quot;:2}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Early experiments: what worked and what&amp;nbsp;didn’t&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;What looked promising&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Early results indicate that a token‑native setup improves both inhouse evaluation metrics and online engagement (time spent per UU), suggesting that modeling long behavior sequences in a unified token space is directionally beneficial.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;The hard part: efficiency and scale&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;The same design choices that improve expressiveness also raise practical hurdles:&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="6" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Training velocity slows down&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&lt;STRONG&gt;: &lt;/STRONG&gt;long-sequence modeling and larger components can turn iteration cycles from hours into days, making ablations expensive.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="6" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Serving and training costs&amp;nbsp;increase&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&lt;STRONG&gt;:&amp;nbsp;&lt;/STRONG&gt;large sparse embedding tables + deep sequence stacks can dominate memory and compute.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="6" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Capacity constraints limit rollout speed&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&lt;STRONG&gt;:&lt;/STRONG&gt;&amp;nbsp;Hardware&amp;nbsp;availability and cost ceilings become a gating factor for expanding traffic and experimentation.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;In short: DirL’s main challenge&amp;nbsp;isn’t&amp;nbsp;“can it learn the right dependencies?”—it’s&amp;nbsp;“can we make it&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;cheap and fast enough&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;to be a production workhorse?”&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Path to production viability: exploratory directions&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Our current work focuses on understanding how to keep the semantic benefits of token‑native modeling while exploring options that could help reduce overall cost.&amp;nbsp;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;1)&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;Embedding tables&amp;nbsp;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="7" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;consolidate&amp;nbsp;and prune oversized sparse tables&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="7" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;rely more on shared token representations where possible&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;2) Right-size the sequence model&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="8" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;reduce backbone depth where marginal gains flatten&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="8" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;evaluate minimal effective token sets—identify which tokens actually move metrics.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="8" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;explore sequence length vs. performance curves to find the “knee”&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;3) Inference and systems optimization&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="9" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;dynamic batching tuned for token-native inference&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="9" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;kernel fusion and graph optimizations&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="9" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;quantization strategies that preserve ranking&amp;nbsp;model&amp;nbsp;behavior&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Why this direction matters&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;DirL explores a broader shift in recommender systems—from feature‑heavy pipelines with shallow rankers toward&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;foundation‑style sequential models&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;that learn directly from user trajectories. If token‑native ranking can be made efficient, it unlocks several advantages:&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Simpler modeling interfaces, with fewer feature‑plumbing layers.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559739&amp;quot;:0,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Stronger semantic&amp;nbsp;utilization, reducing information loss from aggressive flattening.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559739&amp;quot;:0,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;A more natural path to long‑term behavior and intent modeling.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559739&amp;quot;:0,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Early signals are encouraging. The next phase is about translating this promise into practice—making the approach&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;scalable, cost‑efficient, and fast enough to iterate&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;as a production system.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&lt;SPAN data-contrast="auto"&gt;Using Microsoft Services to Enable Token‑Native Ranking Research&lt;/SPAN&gt; &amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;This work was developed and&amp;nbsp;validated&amp;nbsp;within Microsoft’s internal machine learning and experimentation ecosystem.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Training data was derived from seven days of MSN production logs and user behavior labels, encompassing thousands of features, including numerical, ID‑based, cross, and sequential features. Model training was performed using a&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;PyTorch‑based deep learning framework built by the MSN infrastructure team&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;and executed on&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Azure Machine Learning&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;with a single A100 GPU.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;For online serving, the trained model was deployed on&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;DLIS&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;, Microsoft’s internal inference platform. Evaluation was conducted through controlled online experiments on the&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Azure Exp platform&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN data-contrast="auto"&gt;, enabling validation of user engagement signals under real production traffic.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Although the implementation leverages Microsoft’s internal platforms, the core ideas behind DirL are&amp;nbsp;broadly applicable. Practitioners interested in exploring similar approaches may consider the following high‑level steps:&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="14" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559683&amp;quot;:0,&amp;quot;335559684&amp;quot;:-2,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Construct a unified token space that captures user context, long‑term behavior sequences, and candidate items.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:0,&amp;quot;335559739&amp;quot;:0,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="14" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559683&amp;quot;:0,&amp;quot;335559684&amp;quot;:-2,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Apply a long‑sequence modeling backbone to learn directly from extended user trajectories.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:0,&amp;quot;335559739&amp;quot;:0,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="14" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559683&amp;quot;:0,&amp;quot;335559684&amp;quot;:-2,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Formulate ranking as a native sequence modeling problem, scoring candidates from token‑level representations.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:0,&amp;quot;335559739&amp;quot;:0,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="14" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559683&amp;quot;:0,&amp;quot;335559684&amp;quot;:-2,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="4" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Evaluate both model effectiveness and system efficiency, balancing gains in expressiveness against training and serving cost.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:0,&amp;quot;335559739&amp;quot;:0,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:0,&amp;quot;335559739&amp;quot;:0,&amp;quot;335559740&amp;quot;:300}"&gt;&lt;SPAN data-contrast="auto"&gt;Call to action&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:0,&amp;quot;335559739&amp;quot;:0,&amp;quot;335559740&amp;quot;:300}"&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&lt;SPAN data-contrast="auto"&gt;We encourage practitioners and researchers working on large‑scale recommender systems to experiment with token‑native ranking architectures alongside traditional feature‑heavy pipelines, compare trade‑offs in modeling power and system efficiency, and share insights on when direct sequence learning provides practical advantages in production environments.&lt;/SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Acknowledgement:&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;We would like to acknowledge the support and contributions from several colleagues who helped make this work possible.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;201341983&amp;quot;:0,&amp;quot;335559738&amp;quot;:210,&amp;quot;335559739&amp;quot;:210,&amp;quot;335559740&amp;quot;:300}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;We thank Gaoyuan Jiang and Lightning Huang for their assistance with model deployment, Jianfei Wang for support with the training platform, Gong Cheng for ranker monitoring, Peiyuan Xu for sequential feature logging, and Chunhui Han and Peng Hu for valuable discussions on model design.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;</description>
            <pubDate>Sat, 28 Feb 2026 07:00:00 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/microsoft-developer-community/genrec-direct-learning-moving-ranking-from-feature-pipelines-to/ba-p/4494252</guid>
            <dc:creator>chunlongyu</dc:creator>
            <dc:date>2026-02-28T07:00:00Z</dc:date>
        </item>
        <item>
            <title>Grok 4.0 Goes GA in Microsoft Foundry and Grok 4.1 Fast Arrives with Major Enhancements</title>
            <link>https://techcommunity.microsoft.com/t5/microsoft-foundry-blog/grok-4-0-goes-ga-in-microsoft-foundry-and-grok-4-1-fast-arrives/ba-p/4497964</link>
            <description>&lt;P&gt;&lt;SPAN data-contrast="auto"&gt;We first brought Grok 4.0 to Microsoft Foundry in September 2025, marking an important milestone in expanding Foundry’s multi-model ecosystem with frontier reasoning models from xAI. Since then, customer interest and usage have continued to build as developers explored Grok’s strengths in fast reasoning, sense-making, and interpretation of complex, ambiguous information. Today, we’re excited to announce that&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;Grok 4.0 is now generally available (GA) in Microsoft Foundry,&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;giving enterprises a production-ready path to deploy Grok at scale.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Building on that momentum,&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;Grok&amp;nbsp;4.1&amp;nbsp;Fast&amp;nbsp;Non Reasoning&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;,&amp;nbsp;is&amp;nbsp;now available in Microsoft Foundry&amp;nbsp;and Grok 4.1 Fast Reasoning is coming soon. Grok 4.1&amp;nbsp;introduces a suite of improvements that enhance conversation quality, creativity, and emotional intelligence while&amp;nbsp;maintaining&amp;nbsp;core reasoning strengths. According to&amp;nbsp;xAI,&amp;nbsp;Grok&amp;nbsp;4.1 delivers more natural, fluid dialogue&amp;nbsp;compared with earlier versions.&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P aria-level="3"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="none"&gt;&lt;SPAN data-ccp-parastyle="heading 3"&gt;Introducing Grok 4.1 Fast (Reasoning and Non-Reasoning)&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134245418&amp;quot;:true,&amp;quot;134245529&amp;quot;:true,&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Grok 4.1 Fast&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;is&amp;nbsp;optimized&amp;nbsp;for speed, scale, and agentic execution, giving developers flexibility to choose between&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;reasoning&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;and&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;non-reasoning&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;variants depending on workload requirements.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Grok 4.1 Fast (Reasoning):&lt;/SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;Designed for scenarios that require rapid multi-step reasoning, structured decision-making, and interpretation of complex inputs. This variant is well-suited for agent workflows,&amp;nbsp;analysis&amp;nbsp;pipelines, and applications that need fast responses without sacrificing reasoning depth.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Grok 4.1 Fast (Non-Reasoning):&lt;/SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;Optimized for&amp;nbsp;maximum&amp;nbsp;throughput and low latency, this variant is ideal for tasks such as summarization, classification, content transformation, and tool-driven execution where deterministic speed and efficiency matter more than deep reasoning.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Together, these options allow teams to&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;right-size performance and cost&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;by selecting the&amp;nbsp;appropriate Grok&amp;nbsp;4.1 Fast variant for each stage of an application from high-volume preprocessing and orchestration to targeted reasoning tasks.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P aria-level="3"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="none"&gt;&lt;SPAN data-ccp-parastyle="heading 3"&gt;What’s New with Grok 4.1&lt;/SPAN&gt;&lt;SPAN data-ccp-parastyle="heading 3"&gt;&amp;nbsp;Fast?&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134245418&amp;quot;:true,&amp;quot;134245529&amp;quot;:true,&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Grok 4.1 brings several enhancements that broaden the model’s applicability and user experience:&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Improved Conversational Quality:&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;According to&amp;nbsp;xAI,&amp;nbsp;Grok&amp;nbsp;4.1&amp;nbsp;Fast&amp;nbsp;offers smoother, more natural interaction patterns, making it more comfortable and intuitive to engage with, especially in multi-turn dialogues.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Enhanced Creativity and Emotional Awareness:&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;According to&amp;nbsp;xAI,&amp;nbsp;Grok&amp;nbsp;4.1&amp;nbsp;Fast&amp;nbsp;demonstrates&amp;nbsp;stronger creative writing capabilities and greater emotional intelligence, helping it generate more expressive and engaging outputs that better align with human expectations.&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Reduced Hallucination and Better Reliability:&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;According to&amp;nbsp;xAI,&amp;nbsp;Grok&amp;nbsp;4.1&amp;nbsp;Fast&amp;nbsp;produces fewer factual inaccuracies than its predecessor&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;These enhancements make Grok 4.1&amp;nbsp;Fast&amp;nbsp;a compelling choice for use cases that require engaging conversational interfaces, creative support, and rich natural language interaction.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;As with all frontier AI models, Grok-4.1 Fast introduces new capabilities alongside new operational considerations. Microsoft’s safety and responsible AI evaluations&amp;nbsp;indicate&amp;nbsp;that Grok-4.1 Fast may&amp;nbsp;demonstrate&amp;nbsp;increased risks in&amp;nbsp;safety&amp;nbsp;testing&amp;nbsp;compared with other models available through Azure. In practice, this means there may be&amp;nbsp;an increased&amp;nbsp;risk of generating explicit or potentially harmful&amp;nbsp;content.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;To support responsible deployment, customers should implement system-level safety instructions and leverage&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview" target="_blank"&gt;&lt;SPAN data-contrast="none"&gt;&lt;SPAN data-ccp-charstyle="Hyperlink"&gt;Azure AI Content Safety (AACS)&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;to help monitor and filter outputs. Because no single safety system can address every&amp;nbsp;possible risk&amp;nbsp;scenario, customers are encouraged to conduct their own evaluations and validation before deploying Grok-4.1 in production systems.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;To provide enhanced safety and enterprise reliability, Microsoft's deployment of Grok 4.1 features a system-applied safety prompt that cannot be disabled. Customers are expected to operate the model without attempting to bypass or interfere with this feature.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;335551550&amp;quot;:0,&amp;quot;335551620&amp;quot;:0,&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P aria-level="3"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="none"&gt;&lt;SPAN data-ccp-parastyle="heading 3"&gt;Enterprise-Ready Deployment via Azure AI Foundry&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134245418&amp;quot;:true,&amp;quot;134245529&amp;quot;:true,&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;With Grok 4.0 now GA in Foundry, enterprises gain the ability to incorporate advanced reasoning models into their workflows while enjoying the governance, compliance, and operational tooling that Azure provides.&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Models hosted in Foundry can be deployed&amp;nbsp;serverless&amp;nbsp;or with provisioned throughput, and customers&amp;nbsp;benefit&amp;nbsp;from centralized billing, identity&amp;nbsp;integration, and&amp;nbsp;access to&amp;nbsp;other Azure services.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Foundry’s model catalog also includes other Grok variants such as&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;Grok 4.1&amp;nbsp;Fast&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;and related non-reasoning SKUs, giving enterprises flexibility to balance&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;performance, latency, and cost&lt;/SPAN&gt;&lt;SPAN data-contrast="auto"&gt;&amp;nbsp;depending on their workloads.&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="none"&gt;Pricing&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="none"&gt;Model&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335551550&amp;quot;:2,&amp;quot;335551620&amp;quot;:2,&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="none"&gt;Deployment&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335551550&amp;quot;:2,&amp;quot;335551620&amp;quot;:2,&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="none"&gt;Input/1M Tokens&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335551550&amp;quot;:2,&amp;quot;335551620&amp;quot;:2,&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="none"&gt;Output/1M Tokens&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335551550&amp;quot;:2,&amp;quot;335551620&amp;quot;:2,&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="none"&gt;Availability&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335551550&amp;quot;:2,&amp;quot;335551620&amp;quot;:2,&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;&lt;SPAN data-contrast="none"&gt;Grok 4.1 Fast (Non-Reasoning)&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;SPAN data-contrast="none"&gt;Global Standard&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;SPAN data-contrast="none"&gt;$0.2&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;SPAN data-contrast="none"&gt;$0.5&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;SPAN data-contrast="none"&gt;Public Preview&amp;nbsp;on&amp;nbsp; 2/27/2026&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;&lt;SPAN data-contrast="none"&gt;Grok 4.1 Fast (Reasoning)&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;SPAN data-contrast="none"&gt;Global Standard&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134233117&amp;quot;:false,&amp;quot;134233118&amp;quot;:false,&amp;quot;201341983&amp;quot;:0,&amp;quot;335551550&amp;quot;:1,&amp;quot;335551620&amp;quot;:1,&amp;quot;335559685&amp;quot;:0,&amp;quot;335559737&amp;quot;:0,&amp;quot;335559738&amp;quot;:0,&amp;quot;335559739&amp;quot;:0,&amp;quot;335559740&amp;quot;:279}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;SPAN data-contrast="none"&gt;$0.2&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;SPAN data-contrast="none"&gt;$0.5&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;SPAN data-contrast="none"&gt;Coming Soon&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559739&amp;quot;:0}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P aria-level="3"&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="none"&gt;&lt;SPAN data-ccp-parastyle="heading 3"&gt;Looking Ahead&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;134245418&amp;quot;:true,&amp;quot;134245529&amp;quot;:true,&amp;quot;335559738&amp;quot;:281,&amp;quot;335559739&amp;quot;:281}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;The combination of&amp;nbsp;Grok’s&amp;nbsp;deep reasoning capabilities with the enterprise readiness of Microsoft Foundry opens new possibilities for production AI applications,&amp;nbsp;from complex analytical agents and research assistants to creative and customer-facing experiences.&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;With Grok 4.1’s conversational refinements further raising the model’s usability and expressiveness, Foundry customers can now experiment with and&amp;nbsp;scale&amp;nbsp;a broader set of AI-driven solutions, all within a trusted, governed environment.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;As Microsoft continues to expand Foundry’s catalog and partners like&amp;nbsp;xAI&amp;nbsp;continue to innovate, organizations have more options than ever to power next-generation AI applications across industries, use cases, and domains.&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Try Grok 4.1 Non-Reasoning&amp;nbsp; &amp;lt;&lt;A href="https://ai.azure.com/catalog/models/grok-4-1-fast-non-reasoning" target="_blank"&gt;AI Model Catalog | Microsoft Foundry Models&lt;/A&gt;&amp;gt;&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{&amp;quot;335559738&amp;quot;:240,&amp;quot;335559739&amp;quot;:240}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;</description>
            <pubDate>Sat, 28 Feb 2026 03:21:00 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/microsoft-foundry-blog/grok-4-0-goes-ga-in-microsoft-foundry-and-grok-4-1-fast-arrives/ba-p/4497964</guid>
            <dc:creator>Naomi Moneypenny</dc:creator>
            <dc:date>2026-02-28T03:21:00Z</dc:date>
        </item>
        <item>
            <title>Part 2: Safely Cleaning Orphaned Records in Change Tracking Side Tables</title>
            <link>https://techcommunity.microsoft.com/t5/azure-database-support-blog/part-2-safely-cleaning-orphaned-records-in-change-tracking-side/ba-p/4497998</link>
            <description>&lt;P&gt;&lt;STRONG&gt;Applies to:&lt;/STRONG&gt; Azure SQL Database (Change Tracking enabled)&lt;/P&gt;
                &lt;H2&gt;Recap (Part 1)&lt;/H2&gt;
                &lt;P&gt;In &lt;STRONG&gt;Part 1&lt;/STRONG&gt;, we covered how to &lt;EM&gt;detect&lt;/EM&gt; “orphaned” records in Change Tracking (CT) side tables — rows whose sys_change_xdes_id no longer has a matching transaction entry in the commit table (sys.syscommittab). This situation often leads to &lt;STRONG&gt;unexpected CT growth&lt;/STRONG&gt; and “stuck cleanup” symptoms because the mapping data required for normal cleanup is missing.&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Part 1 link:&lt;/STRONG&gt; &lt;A href="https://techcommunity.microsoft.com/blog/azuredbsupport/identifying-orphaned-records-in-change-tracking-side-tables-read%E2%80%91only-health-che/4495617" data-tabster="{&amp;quot;restorer&amp;quot;:{&amp;quot;type&amp;quot;:1}}" target="_blank"&gt;Identifying Orphaned Records in Change Tracking Side Tables (Read‑Only Health Check)&lt;/A&gt;&lt;/P&gt;
                &lt;H2&gt;Why Part 2 is needed&lt;/H2&gt;
                &lt;P&gt;A common “root pattern” we see in the field is:&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;Side-table cleanup &lt;EM&gt;attempts&lt;/EM&gt; to delete expired metadata&lt;/LI&gt;
                &lt;LI&gt;Some side-table deletions fail (locks/timeouts/errors)&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Commit-table cleanup proceeds anyway&lt;/STRONG&gt; (or a custom workflow deletes from commit table without validating side-table deletes)&lt;/LI&gt;
                &lt;LI&gt;Remaining side-table rows now reference xdes_id values that no longer exist in sys.syscommittab → &lt;STRONG&gt;orphans&lt;/STRONG&gt;&amp;nbsp;&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;P&gt;Microsoft Learn also emphasizes that &lt;STRONG&gt;syscommittab cleanup depends on side-table cleanup&lt;/STRONG&gt; — commit-table cleanup should happen only after side tables are cleaned.&lt;/P&gt;
                &lt;P&gt;This Part 2 script focuses on &lt;STRONG&gt;removing orphaned rows from side tables&lt;/STRONG&gt; (and does &lt;EM&gt;not&lt;/EM&gt; touch sys.syscommittab), so cleanup logic can stabilize again.&lt;/P&gt;
                &lt;H2&gt;Important prerequisites &amp;amp; constraints (read this first)&lt;/H2&gt;
                &lt;H3&gt;1) Internal table access on Azure SQL Database&lt;/H3&gt;
                &lt;P&gt;In Azure SQL Database, customers may not be able to access certain internal CT artifacts directly (even when attempting DAC-style workflows). In the related case discussions, internal testing noted that &lt;STRONG&gt;self‑service cleanup against internal tables can be infeasible&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;H3&gt;2) CHECKPOINT note (why it’s in the script)&lt;/H3&gt;
                &lt;P&gt;sys.dm_tran_commit_table exposes commit-table data and is backed by sys.syscommittab. Microsoft Learn notes that &lt;STRONG&gt;read-only users may not see live changes until a CHECKPOINT occurs&lt;/STRONG&gt;. &lt;BR /&gt;That’s why your script includes the optional CHECKPOINT comment before reading commit-table state.&lt;/P&gt;
                &lt;H3&gt;3) Supported guidance vs. custom remediation&lt;/H3&gt;
                &lt;P&gt;Microsoft Learn provides official troubleshooting/mitigation guidance for CT cleanup issues (including checking dbo.MSChange_tracking_history, assessing stale rows, and using sp_flush_commit_table_on_demand for commit-table cleanup). &lt;BR /&gt;Your script is a &lt;STRONG&gt;targeted remediation pattern&lt;/STRONG&gt; for a specific failure mode (orphaned side-table rows). Use it carefully, test first, and follow organizational approval processes.&lt;/P&gt;
                &lt;H2&gt;What this script does (high-level)&lt;/H2&gt;
                &lt;P&gt;T-SQL script is essentially &lt;STRONG&gt;Part 1 detection + optional targeted delete generation&lt;/STRONG&gt;:&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Compute the “safe cleanup point”&lt;/STRONG&gt; from CT retention (wall-clock → CSN) using sp_changetracking_time_to_csn — the same concept used in Part 1.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;Enumerate &lt;STRONG&gt;CT side tables&lt;/STRONG&gt; via sys.internal_tables where internal_type = 209 (CT side tables).&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;For each side table, identify &lt;STRONG&gt;candidate orphaned transaction IDs&lt;/STRONG&gt; (sys_change_xdes_id) that:
                &lt;UL&gt;
                &lt;LI&gt;are older than a computed boundary (@minXdesId derived from sys.dm_tran_commit_table), and&lt;/LI&gt;
                &lt;LI&gt;have &lt;STRONG&gt;no matching&lt;/STRONG&gt; xdes_id in sys.syscommittab at/before the cleanup point&amp;nbsp;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;/LI&gt;
                &lt;LI&gt;Print orphan counts per side table using RAISERROR … WITH NOWAIT (operator-friendly, streaming output).&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Safety cross-check:&lt;/STRONG&gt; abort if any “orphan” unexpectedly exists in sys.syscommittab (defensive sanity gate)&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Generate a DELETE statement&lt;/STRONG&gt; for the current side table (execution is commented out)&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;H2&gt;The script (Part 2) — “detect + generate delete”&lt;/H2&gt;
                &lt;P&gt;Below is T-SQL script. I kept the &lt;STRONG&gt;delete step disabled by default,&lt;/STRONG&gt; so it remains safe to share. (You can enable execution only after approvals/testing.)&lt;/P&gt;
                &lt;DIV&gt;&lt;LI-CODE lang="sql"&gt;-- use &amp;lt;[DBName]&amp;gt; -- switch to the right database


                -- run checkpoint first to ensure all in-memory commit table data is persisted to disk (syscommittab)
                -- checkpoint


                SET NOCOUNT ON


                -- find the invalid clean version based on configured retention
                DECLARE &lt;a href="javascript:void(0)" data-lia-user-mentions="" data-lia-user-uid="2625139" data-lia-user-login="time" class="lia-mention lia-mention-user"&gt;time&lt;/a&gt; DATETIME, @csn BIGINT = 0, @minCleanupPoint BIGINT = 0
                DECLARE @retention_period INT, @retention_period_units NVARCHAR(10)
                SELECT @retention_period = retention_period,
                @retention_period_units = retention_period_units
                FROM sys.change_tracking_databases where database_id = DB_ID()
                SELECT &lt;a href="javascript:void(0)" data-lia-user-mentions="" data-lia-user-uid="2625139" data-lia-user-login="time" class="lia-mention lia-mention-user"&gt;time&lt;/a&gt; = CASE WHEN @retention_period_units = 1 then DATEADD(minute, (-1 * @retention_period), GETUTCDATE())
                WHEN @retention_period_units = 2 then DATEADD(hour, (-1 * @retention_period), GETUTCDATE())
                ELSE DATEADD(day, (-1 * @retention_period), GETUTCDATE()) END

                EXEC sp_changetracking_time_to_csn &lt;a href="javascript:void(0)" data-lia-user-mentions="" data-lia-user-uid="2625139" data-lia-user-login="time" class="lia-mention lia-mention-user"&gt;time&lt;/a&gt; = &lt;a href="javascript:void(0)" data-lia-user-mentions="" data-lia-user-uid="2625139" data-lia-user-login="time" class="lia-mention lia-mention-user"&gt;time&lt;/a&gt;, @csn = @csn OUTPUT


                SELECT @minCleanupPoint = @csn
                SELECT @minCleanupPoint as minCsn -- 688118


                -- iterate over all the change tracking side tables
                DECLARE @sideTable SYSNAME;
                DECLARE ct_cursor CURSOR FAST_FORWARD FOR
                SELECT name FROM sys.internal_tables WHERE internal_type = 209; -- internal_type = 209 is for change tracking side tables


                OPEN ct_cursor;
                FETCH NEXT FROM ct_cursor INTO @sideTable;


                WHILE @@FETCH_STATUS = 0
                BEGIN
                -- find the minimum expired xdes id
                declare @minXdesId BIGINT
                SELECT @minXdesId = min(xdes_id) FROM sys.dm_tran_commit_table where commit_ts &amp;lt;= @minCleanupPoint
                -- SELECT @minXdesId as minXdes

                -- create temp table for storing orphaned xdes id
                DROP TABLE IF EXISTS #OrphanedXdes;
                CREATE TABLE #OrphanedXdes
                (
                sys_change_xdes_id BIGINT NOT NULL
                );


                DECLARE @sql NVARCHAR(MAX);
                SET @sql = N'
                INSERT INTO #OrphanedXdes(sys_change_xdes_id)
                SELECT ct.sys_change_xdes_id
                FROM sys.' + QUOTENAME(@sideTable) + N' AS ct
                WHERE ct.sys_change_xdes_id &amp;lt; @minXdesId
                AND NOT EXISTS
                (
                SELECT 1
                FROM sys.syscommittab AS s
                WHERE s.xdes_id = ct.sys_change_xdes_id AND s.commit_ts &amp;lt;= @minCleanupPoint
                );';


                EXEC sys.sp_executesql
                @sql,
                N'@minXdesId BIGINT, @minCleanupPoint BIGINT',
                @minXdesId = @minXdesId,
                @minCleanupPoint = @minCleanupPoint;


                DECLARE @orphanedIdsCount BIGINT;
                SET @sql = N'
                SELECT @cnt = COUNT_BIG(sys_change_xdes_id)
                FROM #OrphanedXdes;
                ';


                EXEC sys.sp_executesql
                @sql,
                N'@cnt BIGINT OUTPUT',
                @cnt = @orphanedIdsCount OUTPUT;


                -- Raise error if any orphaned xdes exists
                IF (@orphanedIdsCount &amp;gt; 0)
                BEGIN
                DECLARE @msg NVARCHAR(4000) =
                @sideTable + N' : ' + CONVERT(NVARCHAR(30), @orphanedIdsCount);
                RAISERROR (@msg, 16, 1) WITH NOWAIT;

                DECLARE @newLine NVARCHAR(10) = CHAR(13) + CHAR(10)
                PRINT (@newLine)
                END




                -- Cross-check that no xdes should exist in syscommittab
                -- !!!IMPORTANT!!! RAISE an error and stop the cleanup if it does
                SET @sql = N'
                DECLARE @nonMatchingXdesCount BIGINT;


                SELECT @nonMatchingXdesCount = COUNT_BIG(*)
                FROM #OrphanedXdes AS ct
                WHERE EXISTS (
                SELECT 1
                FROM sys.syscommittab AS s
                WHERE s.xdes_id = ct.sys_change_xdes_id
                );


                -- SELECT @nonMatchingXdesCount as nonMatchingXdesCount

                IF (COALESCE(@nonMatchingXdesCount, 0)  &amp;gt; 0)
                BEGIN TRY
                DECLARE @msg NVARCHAR(1024);
                SET @msg = N''Cleanup aborted: orphan cross-check failed for side table [' + @sideTable + N'].'';
                RAISERROR(@msg, 16, 1) WITH NOWAIT;
                RETURN;
                END TRY
                BEGIN CATCH
                THROW;
                END CATCH
                ';


                EXEC sys.sp_executesql @sql;


                IF (@orphanedIdsCount &amp;gt; 0)
                BEGIN
                -- Prepare the query to delete the orphaned rows from the side table
                SET @sql = N'DELETE ct FROM sys.' + @sideTable + N' ct WHERE EXISTS (SELECT 1 FROM #OrphanedXdes AS o WHERE o.sys_change_xdes_id = ct.sys_change_xdes_id);';


                SELECT @sql -- validate the delete query is correctly generated
                -- Sample delete statement: DELETE ct FROM sys.change_tracking_1221579390 ct WHERE EXISTS (SELECT 1 FROM #OrphanedXdes AS o WHERE o.sys_change_xdes_id = ct.sys_change_xdes_id);


                -- NOTE: Uncomment the below query to execute the delete statement and remove the orphaned records
                -- EXEC sys.sp_executesql @sql;
                END


                DROP TABLE IF EXISTS #OrphanedXdes;


                FETCH NEXT FROM ct_cursor INTO @sideTable;
                END


                CLOSE ct_cursor;
                DEALLOCATE ct_cursor;


                SET NOCOUNT OFF&lt;/LI-CODE&gt;
                &lt;H2&gt;Why the “cross-check abort” is a good idea&lt;/H2&gt;
                &lt;P&gt;Notice the safety gate:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;You first define orphans as those &lt;STRONG&gt;not existing&lt;/STRONG&gt; in sys.syscommittab (for the cleanup horizon).&lt;/LI&gt;
                &lt;LI&gt;Then you re-check: “If any of these appear in syscommittab, abort.”&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;This prevents an accidental delete if:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;the cleanup horizon math is wrong,&lt;/LI&gt;
                &lt;LI&gt;the environment has unexpected visibility differences, or&lt;/LI&gt;
                &lt;LI&gt;the temp-table contents are not what you expect.&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;That defensive posture aligns well with the general principle documented in Microsoft Learn: &lt;STRONG&gt;commit-table cleanup should only occur after side-table cleanup&lt;/STRONG&gt;, and troubleshooting should be data-driven and cautious.&lt;/P&gt;
                &lt;H2&gt;How to interpret the output&lt;/H2&gt;
                &lt;UL&gt;
                &lt;LI&gt;If you see &lt;STRONG&gt;no RAISERROR lines&lt;/STRONG&gt;, the script did not find orphaned rows under the defined criteria.&lt;/LI&gt;
                &lt;LI&gt;If you see:
                &lt;UL&gt;
                &lt;LI&gt;change_tracking_&amp;lt;id&amp;gt; : &amp;lt;count&amp;gt;&lt;/LI&gt;
                &lt;/UL&gt;
                that indicates &amp;lt;count&amp;gt; orphaned transaction references in that CT side table. This is the same style used in Part 1 for long-running, streaming progress.&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H2&gt;Next steps (recommended order)&lt;/H2&gt;
                &lt;OL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Confirm CT configuration&lt;/STRONG&gt; (retention + AUTO_CLEANUP status) using official guidance.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Run Part 1 / Part 2 detection&lt;/STRONG&gt; to quantify scope (which side tables, how many).&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;If you need to remediate:
                &lt;UL&gt;
                &lt;LI&gt;Prefer &lt;STRONG&gt;supported mitigations&lt;/STRONG&gt; where possible (for example, disable/enable CT on a table to purge tracking metadata for that table is listed as a “quickest remedy” in Microsoft Learn for certain cleanup lock conflict scenarios).&lt;/LI&gt;
                &lt;LI&gt;If table-level disable/enable isn’t acceptable, use an approval-driven approach for targeted cleanup.&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;/LI&gt;
                &lt;/OL&gt;
                &lt;H2&gt;Closing&lt;/H2&gt;
                &lt;P&gt;Orphaned CT side-table records are one of those “silent growth” conditions that can be easy to miss until storage or CHANGETABLE performance becomes painful. Part 1 helps you &lt;STRONG&gt;spot&lt;/STRONG&gt; the issue early; Part 2 helps you &lt;STRONG&gt;prepare a safe, targeted cleanup&lt;/STRONG&gt; workflow — with explicit safety gates and a delete step that remains disabled by default.&lt;/P&gt;
                &lt;H3&gt;References&lt;/H3&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;A href="https://techcommunity.microsoft.com/blog/azuredbsupport/identifying-orphaned-records-in-change-tracking-side-tables-read%E2%80%91only-health-che/4495617" data-tabster="{&amp;quot;restorer&amp;quot;:{&amp;quot;type&amp;quot;:1}}" target="_blank"&gt;Identifying Orphaned Records in Change Tracking Side Tables (Read‑Only Health Check)&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://learn.microsoft.com/en-us/sql/relational-databases/track-changes/cleanup-and-troubleshoot-change-tracking-sql-server?view=sql-server-ver17" data-tabster="{&amp;quot;restorer&amp;quot;:{&amp;quot;type&amp;quot;:1}}" target="_blank"&gt;Troubleshoot change tracking auto cleanup issues&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://learn.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/change-tracking-sys-dm-tran-commit-table?view=sql-server-ver17" data-tabster="{&amp;quot;restorer&amp;quot;:{&amp;quot;type&amp;quot;:1}}" target="_blank"&gt;sys.dm_tran_commit_table (Change Tracking)&lt;/A&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;/DIV&gt;</description>
            <pubDate>Sat, 28 Feb 2026 02:11:17 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/azure-database-support-blog/part-2-safely-cleaning-orphaned-records-in-change-tracking-side/ba-p/4497998</guid>
            <dc:creator>Mohamed_Baioumy_MSFT</dc:creator>
            <dc:date>2026-02-28T02:11:17Z</dc:date>
        </item>
        <item>
            <title>Troubleshooting Change Tracking cleanup growth and orphaned rows in Azure SQL Database</title>
            <link>https://techcommunity.microsoft.com/t5/azure-database-support-blog/troubleshooting-change-tracking-cleanup-growth-and-orphaned-rows/ba-p/4497997</link>
            <description>&lt;P&gt;&lt;STRONG&gt;Applies to:&lt;/STRONG&gt; Azure SQL Database&lt;BR /&gt;&lt;STRONG&gt;Scenario:&lt;/STRONG&gt; Change Tracking (CT) side tables grow unexpectedly, and “orphaned” rows appear after switching between auto-cleanup and custom/scheduled manual cleanup.&lt;/P&gt;
                &lt;H2&gt;The problem (what we observed)&lt;/H2&gt;
                &lt;P&gt;In the case tracked, the discussion focused on &lt;STRONG&gt;Change Tracking cleanup behavior&lt;/STRONG&gt;—including &lt;STRONG&gt;unexpected growth in CT side tables&lt;/STRONG&gt; and &lt;STRONG&gt;orphaned records&lt;/STRONG&gt;. The customer also referenced earlier guidance to move away from auto-cleanup due to locking concerns during upgrades, and the team needed to propose safe next steps quickly.&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;A parallel concern was that &lt;STRONG&gt;CT auto-cleanup could block DDL during upgrades&lt;/STRONG&gt; (schema lock behavior), which triggered work to deploy a fix and validate it in a lab before broader rollout.&lt;/P&gt;
                &lt;H2&gt;Why this is tricky&lt;/H2&gt;
                &lt;P&gt;The engagement highlighted that &lt;STRONG&gt;manual cleanup&lt;/STRONG&gt; and &lt;STRONG&gt;auto-cleanup&lt;/STRONG&gt; can behave differently in real-world, high-scale environments (large number of CT-enabled tables, heavy activity, and operational constraints like access and auditing). Investigation efforts included:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;validating where orphaned rows exist and how many CT side tables are affected,&lt;/LI&gt;
                &lt;LI&gt;checking whether auto-cleanup is enabled/disabled, and&lt;/LI&gt;
                &lt;LI&gt;using auditing / Extended Events to identify who/what is dropping related history objects.&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;Additionally, &lt;STRONG&gt;Snapshot Isolation&lt;/STRONG&gt; can prevent cleanup from progressing in some cases. it was noted that long-running snapshot transactions can prevent a safe cleanup point from advancing, which can block removal of expired entries from internal commit tracking tables until those transactions complete.&lt;/P&gt;
                &lt;H2&gt;Practical troubleshooting steps (what helped)&lt;/H2&gt;
                &lt;H3&gt;1) Confirm CT configuration (retention + auto-cleanup)&lt;/H3&gt;
                &lt;P&gt;Use the Change Tracking configuration options to validate retention and whether auto-cleanup is enabled. Microsoft Learn documents enabling CT at the database level (including CHANGE_RETENTION and AUTO_CLEANUP). &lt;A href="https://learn.microsoft.com/en-us/sql/relational-databases/track-changes/enable-and-disable-change-tracking-sql-server?view=sql-server-ver17" target="_blank"&gt;Enable and Disable Change Tracking - SQL Server | Microsoft Learn&lt;/A&gt;&lt;/P&gt;
                &lt;H3&gt;2) Quick backlog signal: commit table “oldest commit_time”&lt;/H3&gt;
                &lt;P&gt;During the investigation, the team used a lightweight query to sanity-check backlog in the commit table:&lt;/P&gt;
                &lt;LI-CODE lang="sql"&gt;SELECT TOP (1) *
                FROM sys.dm_tran_commit_table
                ORDER BY commit_time ASC;&lt;/LI-CODE&gt;
                &lt;P&gt;if the returned commit_time is close to the retention horizon,&amp;nbsp;&lt;STRONG&gt;auto-cleanup is likely keeping up&lt;/STRONG&gt; (this query doesn’t require DAC).&lt;/P&gt;
                &lt;H3&gt;3) Detect orphaned rows in CT side tables (read-only script)&lt;/H3&gt;
                &lt;P&gt;A key artifact from this case is the following T-SQL script, which calculates a cleanup point based on configured retention and then &lt;STRONG&gt;iterates over CT side tables&lt;/STRONG&gt; (sys.internal_tables where internal_type = 209) to identify rows whose sys_change_xdes_id no longer has a matching entry in sys.syscommittab at/below the cleanup point.&amp;nbsp;&lt;/P&gt;
                &lt;DIV&gt;&lt;LI-CODE lang="sql"&gt;-- use &amp;lt;[DBName]&amp;gt; -- switch to the right database


                SET NOCOUNT ON


                -- find the invalid clean version based on configured retention
                DECLARE &lt;a href="javascript:void(0)" data-lia-user-mentions="" data-lia-user-uid="2625139" data-lia-user-login="time" class="lia-mention lia-mention-user"&gt;time&lt;/a&gt; DATETIME, @csn BIGINT = 0, @minCleanupPoint BIGINT = 0
                DECLARE @retention_period INT, @retention_period_units NVARCHAR(10)
                SELECT @retention_period = retention_period,
                @retention_period_units = retention_period_units
                FROM sys.change_tracking_databases where database_id = DB_ID()
                SELECT &lt;a href="javascript:void(0)" data-lia-user-mentions="" data-lia-user-uid="2625139" data-lia-user-login="time" class="lia-mention lia-mention-user"&gt;time&lt;/a&gt; = CASE WHEN @retention_period_units = 1 then DATEADD(minute, (-1 * @retention_period), GETUTCDATE())
                WHEN @retention_period_units = 2 then DATEADD(hour, (-1 * @retention_period), GETUTCDATE())
                ELSE DATEADD(day, (-1 * @retention_period), GETUTCDATE()) END

                EXEC sp_changetracking_time_to_csn &lt;a href="javascript:void(0)" data-lia-user-mentions="" data-lia-user-uid="2625139" data-lia-user-login="time" class="lia-mention lia-mention-user"&gt;time&lt;/a&gt; = &lt;a href="javascript:void(0)" data-lia-user-mentions="" data-lia-user-uid="2625139" data-lia-user-login="time" class="lia-mention lia-mention-user"&gt;time&lt;/a&gt;, @csn = @csn OUTPUT


                SELECT @minCleanupPoint = @csn
                SELECT @minCleanupPoint as minCsn -- 688118


                -- iterate over all the change tracking side tables
                DECLARE @sideTable SYSNAME;
                DECLARE ct_cursor CURSOR FAST_FORWARD FOR
                SELECT name FROM sys.internal_tables WHERE internal_type = 209; -- internal_type = 209 is for change tracking side tables


                OPEN ct_cursor;
                FETCH NEXT FROM ct_cursor INTO @sideTable;


                WHILE @@FETCH_STATUS = 0
                BEGIN
                -- find the minimum expired xdes id
                declare @minXdesId BIGINT
                SELECT @minXdesId = min(xdes_id) FROM sys.dm_tran_commit_table where commit_ts &amp;lt;= @minCleanupPoint
                -- SELECT @minXdesId as minXdes

                -- create temp table for storing orphaned xdes id
                DROP TABLE IF EXISTS #OrphanedXdes;
                CREATE TABLE #OrphanedXdes
                (
                sys_change_xdes_id BIGINT NOT NULL
                );


                DECLARE @sql NVARCHAR(MAX);
                SET @sql = N'
                INSERT INTO #OrphanedXdes(sys_change_xdes_id)
                SELECT ct.sys_change_xdes_id
                FROM sys.' + QUOTENAME(@sideTable) + N' AS ct
                WHERE ct.sys_change_xdes_id &amp;lt; @minXdesId
                AND NOT EXISTS
                (
                SELECT 1
                FROM sys.syscommittab AS s
                WHERE s.xdes_id = ct.sys_change_xdes_id AND s.commit_ts &amp;lt;= @minCleanupPoint
                );';


                EXEC sys.sp_executesql
                @sql,
                N'@minXdesId BIGINT, @minCleanupPoint BIGINT',
                @minXdesId = @minXdesId,
                @minCleanupPoint = @minCleanupPoint;


                DECLARE @orphanedIdsCount BIGINT;
                SET @sql = N'
                SELECT @cnt = COUNT_BIG(sys_change_xdes_id)
                FROM #OrphanedXdes;
                ';


                EXEC sys.sp_executesql
                @sql,
                N'@cnt BIGINT OUTPUT',
                @cnt = @orphanedIdsCount OUTPUT;


                -- Raise error if any orphaned xdes exists
                IF (@orphanedIdsCount &amp;gt; 0)
                BEGIN
                DECLARE @msg NVARCHAR(4000) =
                @sideTable + N' : ' + CONVERT(NVARCHAR(30), @orphanedIdsCount);
                RAISERROR (@msg, 16, 1) WITH NOWAIT;

                DECLARE @newLine NVARCHAR(10) = CHAR(13) + CHAR(10)
                PRINT (@newLine)
                END


                DROP TABLE IF EXISTS #OrphanedXdes;


                FETCH NEXT FROM ct_cursor INTO @sideTable;
                END


                CLOSE ct_cursor;
                DEALLOCATE ct_cursor;


                SET NOCOUNT OFF&lt;/LI-CODE&gt;&lt;/DIV&gt;
                &lt;P&gt;Here’s the high-level logic (excerpted/annotated from the script):&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Read retention settings from sys.change_tracking_databases&lt;/LI&gt;
                &lt;LI&gt;Convert “retention window” to a cleanup CSN using sp_changetracking_time_to_csn&lt;/LI&gt;
                &lt;LI&gt;For each CT side table (sys.internal_tables internal_type = 209):
                &lt;UL&gt;
                &lt;LI&gt;compare side-table sys_change_xdes_id vs. sys.syscommittab and count “orphaned” xdes ids&lt;/LI&gt;
                &lt;LI&gt;emit a message when orphaned counts are present&amp;nbsp;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;/LI&gt;
                &lt;/UL&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;&lt;STRONG&gt;Tip:&lt;/STRONG&gt; This is &lt;STRONG&gt;read-only&lt;/STRONG&gt; diagnostic logic. In your environment, validate permissions and impact before running in production.&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;H3&gt;4) If auto-cleanup is unexpectedly disabled, re-enable and monitor&lt;/H3&gt;
                &lt;P&gt;In the email thread, the team observed auto-cleanup was disabled in at least one environment and recommended re-enabling it, then monitoring the CT history table to confirm cleanup activity resumes.&amp;nbsp;&lt;/P&gt;
                &lt;H3&gt;5) Use auditing / Extended Events to identify unexpected object drops&lt;/H3&gt;
                &lt;P&gt;When investigating why a “history table” disappeared, the team reviewed extended event data and noted evidence of a specific application context associated with the drop (shared in the meeting discussion).&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;This is a key lesson: &lt;STRONG&gt;without auditing&lt;/STRONG&gt;, it can be difficult to determine who/what disabled auto-cleanup or dropped relevant objects; the email thread explicitly called this out.&lt;/P&gt;
                &lt;H2&gt;Mitigation options discussed&lt;/H2&gt;
                &lt;H3&gt;(often safest): disable &amp;amp; re-enable Change Tracking on affected tables&lt;/H3&gt;
                &lt;P&gt;As an alternative to running manual deletion scripts, the troubleshooting recommended &lt;STRONG&gt;disabling and re-enabling Change Tracking&lt;/STRONG&gt; on the set of tables containing orphaned rows—described as a well-established and safer cleanup method that avoids needing elevated access to run cleanup scripts directly.&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Trade-off:&lt;/STRONG&gt; disabling CT on a table removes existing change data from the corresponding side tables for that table.&amp;nbsp;&lt;/P&gt;
                &lt;H2&gt;About auto-cleanup performance improvements (why “stay on auto” may be preferred)&lt;/H2&gt;
                &lt;P&gt;The troubleshooting included discussion that&amp;nbsp;&lt;STRONG&gt;auto-cleanup is the area that continues to receive improvements&lt;/STRONG&gt; and that performance enhancements exist (for example, improved adaptive behavior in newer SQL Server versions). Microsoft Learn describes that SQL Server 2025 introduces an “adaptive shallow cleanup approach” for large side tables, enabled by default, and explains how cleanup behavior changes compared to prior versions.&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;While Azure SQL Database implementation details differ from boxed SQL Server, the key operational takeaway from the discussion was: if possible, &lt;STRONG&gt;prefer auto-cleanup&lt;/STRONG&gt; and avoid manual cleanup unless you have a strong reason, because manual cleanup may lack telemetry and can be harder to reason about at scale.&lt;/P&gt;
                &lt;H2&gt;Key takeaways&lt;/H2&gt;
                &lt;OL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Start with read-only validation&lt;/STRONG&gt;: use a backlog signal query and an orphan-detection script to quantify scope before making changes.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Auditability matters&lt;/STRONG&gt;: without auditing/trace evidence, identifying who disabled auto-cleanup or dropped related objects is difficult.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Snapshot Isolation can block cleanup progress&lt;/STRONG&gt;: long-running snapshot transactions may prevent safe cleanup from advancing. Keep snapshot transactions short where possible.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;A safe mitigation exists&lt;/STRONG&gt;&amp;nbsp;disable/re-enable Change Tracking on affected tables (with awareness of change data loss) can be safer than running deletion scripts.&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;H2&gt;References&lt;/H2&gt;
                &lt;UL&gt;
                &lt;LI&gt;Microsoft Learn: Change Tracking management overview (permissions, internal tables, behavior considerations). &lt;A href="https://learn.microsoft.com/en-us/sql/relational-databases/track-changes/manage-change-tracking-sql-server?view=sql-server-ver17" target="_blank"&gt;Manage Change Tracking - SQL Server | Microsoft Learn&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;Microsoft Learn: Enable and Disable Change Tracking (retention + auto-cleanup configuration). &lt;A href="https://learn.microsoft.com/en-us/sql/relational-databases/track-changes/enable-and-disable-change-tracking-sql-server?view=sql-server-ver17" target="_blank"&gt;Enable and Disable Change Tracking - SQL Server | Microsoft Learn&lt;/A&gt;&lt;/LI&gt;
                &lt;/UL&gt;</description>
            <pubDate>Sat, 28 Feb 2026 01:49:00 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/azure-database-support-blog/troubleshooting-change-tracking-cleanup-growth-and-orphaned-rows/ba-p/4497997</guid>
            <dc:creator>Mohamed_Baioumy_MSFT</dc:creator>
            <dc:date>2026-02-28T01:49:00Z</dc:date>
        </item>
        <item>
            <title>Cannot enable Change Data Capture (CDC) on Azure SQL Database: Msg 22830 + Error 40529 (SUSER_SNAME)</title>
            <link>https://techcommunity.microsoft.com/t5/azure-database-support-blog/cannot-enable-change-data-capture-cdc-on-azure-sql-database-msg/ba-p/4497995</link>
            <description>&lt;H2&gt;Issue&lt;/H2&gt;
                &lt;P&gt;While enabling CDC at the database level on Azure SQL Database using:&lt;/P&gt;
                &lt;LI-CODE lang="sql"&gt;EXEC sys.sp_cdc_enable_db;
                GO&lt;/LI-CODE&gt;
                &lt;P&gt;the operation fails.&lt;/P&gt;
                &lt;H2&gt;Error&lt;/H2&gt;
                &lt;P&gt;The customer observed the following failure when running sys.sp_cdc_enable_db:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Msg 22830&lt;/STRONG&gt;: Could not update the metadata that indicates the database is enabled for Change Data Capture.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;Failure occurred when executing &lt;STRONG&gt;drop user cdc&lt;/STRONG&gt;&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Error 40529&lt;/STRONG&gt;: &lt;EM&gt;"Built-in function 'SUSER_SNAME' in impersonation context is not supported in this version of SQL Server."&lt;/EM&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H2&gt;What we checked (quick validation)&lt;/H2&gt;
                &lt;P&gt;Before applying any changes, we confirmed CDC wasn’t partially enabled and no CDC artifacts were created:&lt;/P&gt;
                &lt;LI-CODE lang="sql"&gt;-- Is CDC enabled for this database?
                SELECT name, is_cdc_enabled
                FROM sys.databases
                WHERE name = DB_NAME();&lt;/LI-CODE&gt;&lt;LI-CODE lang="sql"&gt;-- Does CDC schema exist?
                SELECT name
                FROM sys.schemas
                WHERE name = 'cdc';&lt;/LI-CODE&gt;&lt;LI-CODE lang="sql"&gt;-- Does CDC user exist?
                SELECT name
                FROM sys.database_principals
                WHERE name = 'cdc';&lt;/LI-CODE&gt;
                &lt;P&gt;These checks were used during troubleshooting in the SR.&amp;nbsp;&lt;BR /&gt;(Also note: Microsoft Learn documents that enabling CDC creates the cdc schema/user and requires exclusive use of that schema/user.)&lt;/P&gt;
                &lt;H2&gt;Cause&lt;/H2&gt;
                &lt;P&gt;In this case, the failure aligned with a known Azure SQL Database CDC scenario: &lt;STRONG&gt;enabling CDC can fail if there is an active database-level trigger that calls SUSER_SNAME()&lt;/STRONG&gt;.&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;To identify active database-level triggers, we used:&lt;/P&gt;
                &lt;LI-CODE lang="sql"&gt;SELECT name, object_id
                FROM sys.triggers
                WHERE parent_class_desc = 'DATABASE'
                AND is_disabled = 0;&lt;/LI-CODE&gt;
                &lt;H2&gt;Resolution / Workaround&lt;/H2&gt;
                &lt;P&gt;The customer resolved the issue by:&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;Identifying the active &lt;STRONG&gt;database-level trigger&lt;/STRONG&gt;.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Disabling&lt;/STRONG&gt; the trigger temporarily.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;Enabling CDC at the &lt;STRONG&gt;database&lt;/STRONG&gt; level and then enabling CDC on the required &lt;STRONG&gt;tables&lt;/STRONG&gt;.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Re-enabling&lt;/STRONG&gt; the trigger after CDC was successfully enabled.&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;H2&gt;Post-resolution verification&lt;/H2&gt;
                &lt;P&gt;After enabling CDC, you can validate the state using:&lt;/P&gt;
                &lt;LI-CODE lang="sql"&gt;-- Confirm CDC enabled at DB level
                SELECT name, is_cdc_enabled
                FROM sys.databases
                WHERE name = DB_NAME();&lt;/LI-CODE&gt;
                &lt;P&gt;And for table-level tracking, Microsoft Learn recommends checking the is_tracked_by_cdc column in sys.tables.&lt;/P&gt;
                &lt;H2&gt;Notes / Requirements&lt;/H2&gt;
                &lt;UL&gt;
                &lt;LI&gt;To enable CDC for Azure SQL Database, &lt;STRONG&gt;db_owner&lt;/STRONG&gt; is required.&lt;/LI&gt;
                &lt;LI&gt;Azure SQL Database uses a &lt;STRONG&gt;CDC scheduler&lt;/STRONG&gt; (instead of SQL Server Agent jobs) for capture/cleanup.&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;</description>
            <pubDate>Sat, 28 Feb 2026 01:25:09 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/azure-database-support-blog/cannot-enable-change-data-capture-cdc-on-azure-sql-database-msg/ba-p/4497995</guid>
            <dc:creator>Mohamed_Baioumy_MSFT</dc:creator>
            <dc:date>2026-02-28T01:25:09Z</dc:date>
        </item>
        <item>
            <title>DORA exit planning for Azure SQL Database: a practical, “general guidance” blueprint</title>
            <link>https://techcommunity.microsoft.com/t5/azure-database-support-blog/dora-exit-planning-for-azure-sql-database-a-practical-general/ba-p/4497992</link>
            <description>&lt;P&gt;&lt;STRONG&gt;Why this matters:&lt;/STRONG&gt; Under the EU &lt;STRONG&gt;Digital Operational Resilience Act (DORA)&lt;/STRONG&gt;, many financial entities are strengthening requirements around &lt;STRONG&gt;ICT risk management&lt;/STRONG&gt;, &lt;STRONG&gt;third‑party risk oversight&lt;/STRONG&gt;, and—critically—&lt;STRONG&gt;exit planning / substitutability&lt;/STRONG&gt;. Microsoft provides resources to help customers navigate DORA, including a DORA compliance hub in the Microsoft Trust Center.&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;This post distills &lt;STRONG&gt;general guidance&lt;/STRONG&gt; based on a real-world support thread where a customer requested a &lt;STRONG&gt;formal advisory&lt;/STRONG&gt; describing an exit strategy for an Azure SQL Database workload (including a large database scenario).&lt;/P&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;&amp;nbsp;&lt;EM&gt;(Note: The content here is intentionally generalized and not legal advice—always align with your compliance team and regulators.)&lt;/EM&gt;&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;P&gt;The customer asked Microsoft Support for a &lt;STRONG&gt;formal response&lt;/STRONG&gt; to support DORA regulatory expectations, focusing on &lt;STRONG&gt;data portability&lt;/STRONG&gt;, &lt;STRONG&gt;exit planning&lt;/STRONG&gt;, and &lt;STRONG&gt;substitution capabilities&lt;/STRONG&gt; for workloads running on &lt;STRONG&gt;Azure SQL Database&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;P&gt;The support response framed the need as:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;a &lt;STRONG&gt;regulatory submission&lt;/STRONG&gt; use case under DORA,&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;where Microsoft can provide &lt;STRONG&gt;official references&lt;/STRONG&gt; and describe the &lt;STRONG&gt;technical capabilities&lt;/STRONG&gt; enabling portability and exit.&lt;/LI&gt;
                &lt;LI&gt;while &lt;STRONG&gt;customers remain responsible&lt;/STRONG&gt; for defining, documenting, testing, and periodically validating their &lt;STRONG&gt;exit procedures&lt;/STRONG&gt;.&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;STRONG&gt;Microsoft’s DORA resources: where to pull “regulatory artifacts” from&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;A key part of the Support Request response was pointing to Microsoft’s formal compliance resources:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Microsoft publishes DORA-related guidance and operational resilience materials via the &lt;STRONG&gt;Microsoft Trust Center &lt;/STRONG&gt;and&amp;nbsp;makes compliance documentation available via the &lt;STRONG&gt;Service Trust Portal&lt;/STRONG&gt; for supervisory/audit processes.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;Microsoft also maintains a &lt;STRONG&gt;DORA compliance hub&lt;/STRONG&gt; in the Trust Center aimed at helping financial institutions meet DORA requirements.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;Microsoft Learn provides an overview of DORA, scope, and key areas for customer consideration. &lt;A href="https://www.microsoft.com/en-us/trust-center/compliance/dora-compliance" target="_blank"&gt;Navigating DORA compliance | Microsoft Trust Center&lt;/A&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;STRONG&gt;Practical takeaway:&lt;/STRONG&gt; For DORA evidence packs, align your narrative to the regulator’s questions, and use &lt;STRONG&gt;Trust Center / Service Trust Portal&lt;/STRONG&gt; materials as the “Microsoft-published” backbone, then attach your &lt;STRONG&gt;customer-owned exit runbooks and test evidence&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Data ownership and portability: the foundation of an exit plan&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;In the ticket’s advisory, Microsoft Support emphasized:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Azure SQL Database is built on the SQL Server engine, and &lt;STRONG&gt;customers retain ownership of their data&lt;/STRONG&gt;.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;The service supports portability through &lt;STRONG&gt;SQL Server–compatible schemas, T‑SQL&lt;/STRONG&gt;, and &lt;STRONG&gt;documented export/restore mechanisms&lt;/STRONG&gt;, reducing dependency on proprietary formats.&amp;nbsp;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;STRONG&gt;How to use this in a DORA exit narrative:&lt;/STRONG&gt;&lt;BR /&gt;Frame “reversibility” as &lt;STRONG&gt;standards-based data and schema portability&lt;/STRONG&gt; (SQL/T‑SQL + documented export/import). That’s exactly the type of substitutability narrative many regulators want to see.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Supported exit strategy building blocks (Azure SQL Database → on‑prem SQL Server)&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;The Support Request response described the exit approach at a&amp;nbsp;&lt;STRONG&gt;high level&lt;/STRONG&gt;, using supported, documented capabilities:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Exporting database schema and data&lt;/STRONG&gt; using SQL Server–compatible formats&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Restoring or importing&lt;/STRONG&gt; into an on‑prem SQL Server environment with functional equivalence&lt;/LI&gt;
                &lt;LI&gt;Maintaining &lt;STRONG&gt;security controls&lt;/STRONG&gt; (auth, encryption in transit/at rest, integrity protections) during transition&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Validating restored data and application functionality&lt;/STRONG&gt; as part of exit testing&amp;nbsp;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;One concrete, Microsoft-documented portability method for Azure SQL Database is &lt;STRONG&gt;exporting to a BACPAC&lt;/STRONG&gt; (schema + data), which can later be imported into &lt;STRONG&gt;SQL Server&lt;/STRONG&gt;.&amp;nbsp;&lt;/P&gt;
                &lt;H3&gt;BACPAC: what Microsoft documentation explicitly calls out (and why it matters for “exit planning”)&lt;/H3&gt;
                &lt;P&gt;Microsoft Learn documents:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;A &lt;STRONG&gt;BACPAC&lt;/STRONG&gt; contains &lt;EM&gt;metadata and data&lt;/EM&gt; and can be stored in Azure Blob storage or local storage and later imported into Azure SQL Database, Azure SQL Managed Instance, or &lt;STRONG&gt;SQL Server&lt;/STRONG&gt;. &lt;A href="https://learn.microsoft.com/en-us/sql/tools/sql-database-projects/concepts/data-tier-applications/export-bacpac-file?view=sql-server-ver17" target="_blank"&gt;Export a BACPAC File - SQL Server | Microsoft Learn&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;For transactional consistency, ensure no write activity during export or export from a transactionally consistent copy.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;Blob-storage exports have a &lt;STRONG&gt;maximum BACPAC size of 200 GB&lt;/STRONG&gt;; larger exports should go to &lt;STRONG&gt;local storage using SqlPackage&lt;/STRONG&gt;.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;BACPAC is &lt;STRONG&gt;not intended as a backup/restore&lt;/STRONG&gt; mechanism; Azure SQL has built-in automated backups.&amp;nbsp;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;STRONG&gt;DORA relevance:&lt;/STRONG&gt; BACPAC is a strong “portability evidence” artifact because it is explicitly positioned for “archiving” or “moving to another platform,” including SQL Server. &lt;A href="https://github.com/MicrosoftDocs/sql-docs/blob/live/azure-sql/database/database-export.md" target="_blank"&gt;sql-docs/azure-sql/database/database-export.md at live · MicrosoftDocs/sql-docs&lt;/A&gt;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Large databases: why “one-button export” may not be your plan&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;The Support Request thread highlighted a “large database” scenario and referenced that Microsoft documentation describes &lt;STRONG&gt;high-level migration patterns&lt;/STRONG&gt; such as &lt;STRONG&gt;offline export/import&lt;/STRONG&gt; and &lt;STRONG&gt;staged validation&lt;/STRONG&gt; for large databases.&lt;/P&gt;
                &lt;P&gt;In practice, if your database is far beyond BACPAC’s typical constraints (for example, BACPAC export to blob capped at 200 GB), your exit plan should explicitly describe:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;a &lt;STRONG&gt;staged approach&lt;/STRONG&gt; (e.g., dry-run validation environment, phased cutover planning),&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;capacity planning&lt;/STRONG&gt; (network bandwidth, validation windows),&lt;/LI&gt;
                &lt;LI&gt;and a testing cadence that produces regulator-friendly evidence.&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;The ticket response also emphasized that customers should plan for &lt;STRONG&gt;sufficient time and capacity for transfer and validation&lt;/STRONG&gt; (especially for large databases).&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Customer responsibilities under DORA (the part regulators care about most)&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;A key statement from the Support Request advisory is worth repeating as general guidance:&lt;/P&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;Microsoft provides the technical capabilities enabling data portability and exit, but &lt;STRONG&gt;customers remain responsible&lt;/STRONG&gt; for defining, documenting, testing, and periodically validating exit procedures—including planning timelines, allocating sufficient capacity, executing test exits, and maintaining evidence for regulatory review.&amp;nbsp;&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;P&gt;This aligns well with DORA’s intent and Microsoft’s broader DORA guidance narrative: DORA requires operational resilience outcomes, and organizations must integrate cloud capabilities into their governance and controls.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;A simple DORA-ready “exit plan checklist” you can adapt&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;Below is a&amp;nbsp;&lt;STRONG&gt;general&lt;/STRONG&gt; checklist you can use to structure your exit plan documentation and evidence pack—aligned with what was emphasized in the Support Request:&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Scope &amp;amp; dependencies&lt;/STRONG&gt;&lt;BR /&gt;Identify the Azure SQL Database workloads, dependent applications, and data flows to be included in the exit plan. &lt;EM&gt;(Customer-owned documentation and evidence)&lt;/EM&gt;&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Portability mechanism(s)&lt;/STRONG&gt;&lt;BR /&gt;Reference documented portability options such as schema+data export mechanisms (e.g., BACPAC) where applicable.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Security controls during transition&lt;/STRONG&gt;&lt;BR /&gt;Document how auth and encryption controls are maintained during transfer and restoration validation.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Validation plan&lt;/STRONG&gt;&lt;BR /&gt;Define how you will validate data integrity and application functionality in the target environment.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Scale planning (large DBs)&lt;/STRONG&gt;&lt;BR /&gt;Document transfer capacity planning, timelines, and staged validation where needed.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Evidence &amp;amp; audit trail&lt;/STRONG&gt;&lt;BR /&gt;Store test outputs, run logs, and references to Microsoft Trust Center / Service Trust Portal materials used in submissions.&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;P&gt;From the SR’s formal advisory perspective, the message is consistent:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Azure SQL Database supports &lt;STRONG&gt;data portability&lt;/STRONG&gt; and &lt;STRONG&gt;exits planning&lt;/STRONG&gt; via &lt;STRONG&gt;SQL Server–compatible&lt;/STRONG&gt; design and &lt;STRONG&gt;documented export/import mechanisms&lt;/STRONG&gt;,&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;Microsoft provides DORA-oriented compliance materials via the &lt;STRONG&gt;Trust Center&lt;/STRONG&gt; and &lt;STRONG&gt;Service Trust Portal.&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;LI&gt;and customers should own the &lt;STRONG&gt;exit runbook&lt;/STRONG&gt;, &lt;STRONG&gt;testing&lt;/STRONG&gt;, and &lt;STRONG&gt;evidence&lt;/STRONG&gt; required for regulatory review.&lt;/LI&gt;
                &lt;/UL&gt;</description>
            <pubDate>Sat, 28 Feb 2026 01:12:22 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/azure-database-support-blog/dora-exit-planning-for-azure-sql-database-a-practical-general/ba-p/4497992</guid>
            <dc:creator>Mohamed_Baioumy_MSFT</dc:creator>
            <dc:date>2026-02-28T01:12:22Z</dc:date>
        </item>
        <item>
            <title>Offline vs. Immutable Backups for Azure SQL Database (General Guidance)</title>
            <link>https://techcommunity.microsoft.com/t5/azure-database-support-blog/offline-vs-immutable-backups-for-azure-sql-database-general/ba-p/4497990</link>
            <description>&lt;P&gt;Security and compliance teams often ask for&amp;nbsp;&lt;STRONG&gt;“offline backups”&lt;/STRONG&gt; and &lt;STRONG&gt;“immutable backups”&lt;/STRONG&gt; as part of ransomware resilience, audit readiness, and recovery strategy. In Azure SQL Database, these terms map to &lt;STRONG&gt;different capabilities and operating models&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Immutable backups (WORM)&lt;/STRONG&gt; are supported &lt;STRONG&gt;natively for Long-Term Retention (LTR) backups&lt;/STRONG&gt; in Azure SQL Database, using &lt;STRONG&gt;time-based&lt;/STRONG&gt; and &lt;STRONG&gt;legal hold&lt;/STRONG&gt; immutability modes.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Offline backups&lt;/STRONG&gt; (customer-controlled copies stored under your own governance) typically require a &lt;STRONG&gt;customer-managed export/copy process&lt;/STRONG&gt;, because platform-managed backups (including LTR) are retained within Azure’s managed backup system.&amp;nbsp;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;This post explains the difference, what’s supported today, and practical design considerations to help you choose the right approach.&lt;/P&gt;
                &lt;H2&gt;1) Start by clarifying the requirement: “offline” vs. “immutable”&lt;/H2&gt;
                &lt;H3&gt;What “immutable backup” means in practice&lt;/H3&gt;
                &lt;P&gt;An immutable backup is stored in a &lt;STRONG&gt;Write Once, Read Many (WORM)&lt;/STRONG&gt; state—&lt;STRONG&gt;non-modifiable and non-erasable&lt;/STRONG&gt; for a user-defined retention period, providing protection against accidental or malicious deletion or modification (including by privileged administrators).&lt;/P&gt;
                &lt;P&gt;Azure SQL Database supports&amp;nbsp;&lt;STRONG&gt;backup immutability for LTR backups&lt;/STRONG&gt;, written to &lt;STRONG&gt;Azure immutable storage&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;H3&gt;What “offline backup” usually implies&lt;/H3&gt;
                &lt;P&gt;“Offline” is commonly used to mean &lt;STRONG&gt;customer-controlled copies&lt;/STRONG&gt; stored separately (often under separate access controls and retention governance). Azure SQL Database’s built-in backups are platform-managed; if your policy explicitly requires “offline/customer-controlled” artifacts, you typically implement an &lt;STRONG&gt;export/copy&lt;/STRONG&gt; process in addition to platform-managed backups.&lt;/P&gt;
                &lt;H2&gt;2) What Azure SQL Database supports natively: LTR + immutability (WORM)&lt;/H2&gt;
                &lt;H3&gt;Long-Term Retention (LTR) basics&lt;/H3&gt;
                &lt;P&gt;LTR exists to retain backups beyond the short-term retention window. It relies on the &lt;STRONG&gt;full database backups automatically created by the Azure SQL service&lt;/STRONG&gt; and stores specified full backups in &lt;STRONG&gt;redundant Azure Blob storage&lt;/STRONG&gt; with a retention policy of &lt;STRONG&gt;up to 10 years&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;P&gt;If an LTR policy is configured, automated backups are&amp;nbsp;&lt;STRONG&gt;copied to different blobs for long-term storage&lt;/STRONG&gt;. The copy process is a &lt;STRONG&gt;background job that has no performance impact&lt;/STRONG&gt; on the database workload.&lt;/P&gt;
                &lt;H3&gt;Immutability modes for LTR backups&lt;/H3&gt;
                &lt;P&gt;Azure SQL Database LTR backups support both:&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Time-based immutability&lt;/STRONG&gt; (policy-driven) — enabled at the LTR policy level; once &lt;STRONG&gt;enabled and locked&lt;/STRONG&gt;, new LTR backups taken from that point forward inherit the settings and remain immutable until the retention period ends.&amp;nbsp;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Legal hold immutability&lt;/STRONG&gt; — enabled/disabled on a &lt;STRONG&gt;specific existing backup&lt;/STRONG&gt;, independent of time-based settings; backups remain immutable until legal hold is explicitly removed.&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;H2&gt;3) Key operational constraint to plan for (important!)&lt;/H2&gt;
                &lt;P&gt;Microsoft documentation notes that when you configure immutability for an Azure SQL Database with an LTR policy, the associated &lt;STRONG&gt;logical server can be blocked from deletion&lt;/STRONG&gt; until all immutable backups are removed (time-based and/or legal hold).&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;This is a &lt;STRONG&gt;big lifecycle-management consideration&lt;/STRONG&gt; (especially for non-prod environments or automation that deletes/recreates servers).&lt;/P&gt;
                &lt;H2&gt;4) Cost model: what changes when you enable immutability?&lt;/H2&gt;
                &lt;P&gt;According to the documentation, there’s &lt;STRONG&gt;no additional cost&lt;/STRONG&gt; for enabling immutability on LTR backups; however, &lt;STRONG&gt;backup storage charges continue to accrue as long as the immutable backup file exists&lt;/STRONG&gt;, even if it’s past the configured LTR expiration date (while it remains immutable).&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;For broader spend governance, Microsoft recommends using &lt;STRONG&gt;Cost Management features&lt;/STRONG&gt; to set budgets, monitor costs, and review forecasted costs and trends.&lt;/P&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;Practical interpretation (design guidance): immutability changes the&amp;nbsp;&lt;STRONG&gt;delete/modify behavior&lt;/STRONG&gt; and therefore can affect &lt;STRONG&gt;how long backups remain stored&lt;/STRONG&gt;, which can influence total backup storage cost over time. This aligns with the “charges continue to accrue as long as the immutable backup file exists” note.&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;H2&gt;5) How to enable LTR and immutability (high-level, supported steps)&lt;/H2&gt;
                &lt;H3&gt;Configure LTR retention (Azure portal)&lt;/H3&gt;
                &lt;P&gt;Microsoft’s guidance for LTR policy management includes navigate to your &lt;STRONG&gt;server → Backups → Retention policies&lt;/STRONG&gt;, select the database(s), and set weekly/monthly/yearly retention periods (or 0 for none).&amp;nbsp;&lt;/P&gt;
                &lt;H3&gt;Enable time-based immutability (Azure portal)&lt;/H3&gt;
                &lt;P&gt;The time-based immutability article describes enabling it through the server’s &lt;STRONG&gt;Backups → Retention Policies → Configure Policies&lt;/STRONG&gt;, then checking &lt;STRONG&gt;Enable time-based immutability policy&lt;/STRONG&gt; and &lt;STRONG&gt;lock the time-based immutable policy&lt;/STRONG&gt; (backups aren’t immutable until locked).&lt;/P&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;Note: The documentation also highlights that only backups taken&amp;nbsp;&lt;STRONG&gt;after enabling and locking&lt;/STRONG&gt; time-based immutability become immutable; for existing backups, use &lt;STRONG&gt;legal hold&lt;/STRONG&gt; immutability instead.&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;H2&gt;6) If you truly need “offline” (customer-controlled) backups&lt;/H2&gt;
                &lt;P&gt;Azure SQL Database platform-managed backups (including LTR) are retained within Azure’s managed backup system. If your requirement explicitly mandates customer-controlled “offline” copies, you typically implement a &lt;STRONG&gt;customer-managed export/backup approach&lt;/STRONG&gt; and store exported artifacts under your own governance and retention controls.&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;This is commonly positioned as &lt;STRONG&gt;complementary&lt;/STRONG&gt; to platform-managed backups—use platform features for operational recovery plus LTR immutability for tamper-proof retention and add customer-managed exports only if “offline custody” is a strict requirement.&lt;/P&gt;
                &lt;H2&gt;7) Compliance notes you can cite internally&lt;/H2&gt;
                &lt;P&gt;The immutability documentation states Azure SQL Database backup immutability helps meet stringent regulatory requirements (examples listed include &lt;STRONG&gt;SEC Rule 17a-4(f), FINRA Rule 4511(c), and CFTC Rule 1.31(c)-(d)&lt;/STRONG&gt;). It also notes that the Cohasset report is available in the Microsoft Service Trust Center, and you can request a letter of attestation via Azure Support.&lt;/P&gt;
                &lt;H2&gt;8) Decision checklist (quick guidance)&lt;/H2&gt;
                &lt;P&gt;Use this to decide what to implement:&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Choose native LTR immutability if you need:&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Tamper-proof backups (WORM) for compliance/audit/ransomware resilience.&lt;/LI&gt;
                &lt;LI&gt;A solution integrated into Azure SQL Database backup retention (LTR).&amp;nbsp;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;STRONG&gt;Add customer-managed exports if you need:&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Customer-controlled “offline” custody of backup artifacts under your own storage governance/retention controls.&amp;nbsp;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;STRONG&gt;Plan carefully for lifecycle automation if you enable immutability:&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Logical server deletion can be blocked while immutable backups exist.&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H2&gt;References (Microsoft documentation)&lt;/H2&gt;
                &lt;UL&gt;
                &lt;LI&gt;Backup immutability for LTR backups: &lt;A href="https://learn.microsoft.com/en-us/azure/azure-sql/database/backup-immutability?view=azuresql" target="_blank"&gt;Backup Immutability for Long-Term Retention Backups - Azure SQL Database | Microsoft Learn&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;Time-based immutability configuration: &lt;A href="https://learn.microsoft.com/en-us/azure/azure-sql/database/backup-immutability-time-based?view=azuresql&amp;amp;tabs=azure-portal" target="_blank"&gt;Configure Time Based Backup Immutability for Long-Term Retention Backups - Azure SQL Database | Microsoft Learn&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;Legal hold immutability configuration: &lt;A href="https://www.sqlshack.com/managing-retention-period-of-azure-sql-database-backup/" target="_blank"&gt;Managing Retention period of Azure SQL Database Backup&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;LTR overview (how it works, background copy/no perf impact): &lt;A href="https://learn.microsoft.com/en-us/azure/azure-sql/database/long-term-retention-overview?view=azuresql" target="_blank"&gt;Long-Term Retention Backups - Azure SQL Database &amp;amp; Azure SQL Managed Instance | Microsoft Learn&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;Manage LTR retention policies: &lt;A href="https://learn.microsoft.com/en-us/azure/azure-sql/database/long-term-backup-retention-configure?view=azuresql&amp;amp;tabs=portal" target="_blank"&gt;Azure SQL Database: Manage long-term backup retention - Azure SQL Database | Microsoft Learn&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;Plan and manage Azure SQL Database costs: &lt;A href="https://learn.microsoft.com/en-us/azure/azure-sql/database/cost-management?view=azuresql" target="_blank"&gt;Plan and Manage Costs - Azure SQL Database | Microsoft Learn&lt;/A&gt;&lt;/LI&gt;
                &lt;/UL&gt;</description>
            <pubDate>Sat, 28 Feb 2026 00:48:26 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/azure-database-support-blog/offline-vs-immutable-backups-for-azure-sql-database-general/ba-p/4497990</guid>
            <dc:creator>Mohamed_Baioumy_MSFT</dc:creator>
            <dc:date>2026-02-28T00:48:26Z</dc:date>
        </item>
        <item>
            <title>Running Text to Image and Text to Video with ComfyUI and Nvidia H100 GPU</title>
            <link>https://techcommunity.microsoft.com/t5/core-infrastructure-and-security/running-text-to-image-and-text-to-video-with-comfyui-and-nvidia/ba-p/4497978</link>
            <description>&lt;P&gt;This guide provides instructions on how to set up and run&amp;nbsp;&lt;STRONG&gt;Text to Image&lt;/STRONG&gt; and &lt;STRONG&gt;Text to Video&lt;/STRONG&gt;&amp;nbsp;generation using &lt;STRONG&gt;ComfyUI&lt;/STRONG&gt; with an &lt;STRONG&gt;Nvidia H100 GPU&lt;/STRONG&gt; on Azure VMs.&lt;/P&gt;
                &lt;P&gt;&lt;A class="lia-external-url" href="https://www.comfy.org/" target="_blank" rel="noopener"&gt;ComfyUI&lt;/A&gt; is a node-based user interface for Stable Diffusion and other AI models. It allows users to create complex workflows for image and video generation using a visual interface. With the power of GPUs, you can significantly speed up the generation process for high-quality images and videos.&lt;/P&gt;
                &lt;H3&gt;Steps to create the infrastructure&lt;/H3&gt;
                &lt;H4&gt;Option 1. Using Terraform (Recommended)&lt;/H4&gt;
                &lt;P&gt;In this guide, the provided Terraform template available here: &lt;A href="https://github.com/HoussemDellai/ai-course/tree/main/550_comfyui_on_vm" target="_blank" rel="noopener"&gt;ai-course/550_comfyui_on_vm at main · HoussemDellai/ai-course&lt;/A&gt; will create the following:&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;Create the infrastructure for &lt;STRONG&gt;Ubuntu VM&lt;/STRONG&gt; with&amp;nbsp;&lt;STRONG&gt;Nvidia H100 GPU&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;LI&gt;Install &lt;STRONG&gt;CUDA drivers&lt;/STRONG&gt; on the VM&lt;/LI&gt;
                &lt;LI&gt;Install&amp;nbsp;&lt;STRONG&gt;ComfyUI&lt;/STRONG&gt;&amp;nbsp;on the VM&lt;/LI&gt;
                &lt;LI&gt;Download the models for Text to Image (&lt;STRONG&gt;Z-Image-Turbo&lt;/STRONG&gt;) and Text to Video generation (&lt;STRONG&gt;Wan 2.2&lt;/STRONG&gt; and &lt;STRONG&gt;LTX-2&lt;/STRONG&gt;)&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;P&gt;Deploy the Terraform template using the following commands:&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;# Initialize Terraform
                terraform init
                # Review the Terraform plan
                terraform plan tfplan
                # Apply the Terraform configuration to create resources
                terraform apply tfplan&lt;/LI-CODE&gt;
                &lt;P&gt;This should take about 15 minutes to create all the resources with the configuration defined in the Terraform files. The following resources will be created:&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;If you choose to use Terraform, after the deployment is complete, you can access the ComfyUI portal using the output link shown in the Terraform output. It should look like this&amp;nbsp;&lt;STRONG&gt;http://&amp;lt;VM_IP_ADDRESS&amp;gt;:8188&lt;/STRONG&gt;. And that should be the end of the setup. You can then proceed to use ComfyUI for Text to Image and Text to Video generation as described in the later sections.&lt;/P&gt;
                &lt;H4&gt;Option 2. Manual Setup&lt;/H4&gt;
                &lt;H5&gt;0. Create a Virtual Machine with Nvidia H100 GPU&lt;/H5&gt;
                &lt;P&gt;Create an Azure virtual machine with&amp;nbsp;&lt;STRONG&gt;Nvidia H100&lt;/STRONG&gt;&amp;nbsp;GPUs like sku:&amp;nbsp;&lt;STRONG&gt;Standard NC40ads H100 v5&lt;/STRONG&gt;. Choose a Linux distribution of your choice like&amp;nbsp;&lt;STRONG&gt;Ubuntu Pro 24.04 LTS&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;H5&gt;1. Install Nvidia GPU and CUDA Drivers&lt;/H5&gt;
                &lt;P&gt;SSH into the Ubuntu VM and install the CUDA drivers by following the official Microsoft documentation: &lt;A class="lia-external-url" href="https://learn.microsoft.com/en-us/azure/virtual-machines/linux/n-series-driver-setup#install-cuda-drivers-on-n-series-vms" target="_blank" rel="noopener"&gt;Install CUDA drivers on N-series VMs&lt;/A&gt;.&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;# 1. Install ubuntu-drivers utility:
                sudo apt-get update
                sudo apt-get install ubuntu-drivers-common -y

                # 2. Install the latest NVIDIA drivers:
                sudo ubuntu-drivers install

                # 3. Download and install the CUDA toolkit from NVIDIA:
                wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb
                sudo dpkg -i cuda-keyring_1.1-1_all.deb
                sudo apt-get update
                sudo apt-get -y install cuda-toolkit-13-1

                # 4. Reboot the system to apply changes
                sudo reboot&lt;/LI-CODE&gt;
                &lt;P&gt;The machine will now reboot. After rebooting, you can verify the installation of the NVIDIA drivers and CUDA toolkit.&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;# 5. Verify that the GPU is correctly recognized (after reboot):
                nvidia-smi

                # 6. We recommend that you periodically update NVIDIA drivers after deployment.
                sudo apt-get update
                sudo apt-get full-upgrade -y&lt;/LI-CODE&gt;
                &lt;H4&gt;2. Install ComfyUI on Ubuntu&lt;/H4&gt;
                &lt;P&gt;Follow the instructions from the ComfyUI Wiki to install ComfyUI on your Ubuntu VM using Comfy CLI: &lt;A class="lia-external-url" href="https://comfyui-wiki.com/en/install/install-comfyui/install-comfyui-on-linux" target="_blank" rel="noopener"&gt;Install ComfyUI using Comfy CLI&lt;/A&gt;.&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;# Step 1: System Environment Preparation
                # ComfyUI requires Python 3.12 or higher (Python 3.13 is recommended). Check your Python version:
                python3 --version

                # If Python is not installed or the version is too low, install it following these steps:
                sudo apt-get update
                sudo apt-get install python3 python3-pip python3-venv -y

                # Create Virtual Environment
                # Using a virtual environment can avoid package conflict issues
                python3 -m venv comfy-env

                # Activate the virtual environment
                source comfy-env/bin/activate

                # Note: You need to activate the virtual environment each time before using ComfyUI. To exit the virtual environment, use the deactivate command.
                # Step 2: Install Comfy CLI
                # Install comfy-cli in the activated virtual environment:
                pip install comfy-cli

                # Step 3: Install ComfyUI using Comfy CLI with NVIDIA GPU Support
                # use 'yes' to accept all prompts
                yes | comfy install --nvidia

                # Step 4: Install GPU Support for PyTorch
                pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu130

                # Note: Please choose the corresponding PyTorch version based on your CUDA version. Visit the PyTorch website for the latest installation commands.

                # Step 5. Launch ComfyUI
                # By default, ComfyUI will run on http://localhost:8188.
                # and don't forget the double --
                comfy launch --background -- --listen 0.0.0.0 --port 8188&lt;/LI-CODE&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;Note that you can run ComfyUI with different modes based on your hardware capabilities:&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;--cpu&lt;/STRONG&gt;: Use CPU mode, if you don't have a compatible GPU&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;--lowvram&lt;/STRONG&gt;: Low VRAM mode&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;--novram&lt;/STRONG&gt;: Ultra-low VRAM mode&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;H4&gt;3. Using ComfyUI for Text to Image&lt;/H4&gt;
                &lt;P&gt;Once ComfyUI is running, you can access the web interface via your browser at&amp;nbsp;&lt;STRONG&gt;http://&amp;lt;VM_IP_ADDRESS&amp;gt;:8188&lt;/STRONG&gt; (replace &amp;lt;VM_IP_ADDRESS&amp;gt; with the actual IP address of your VM).&lt;/P&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;Note that you should ensure that the VM's network security group (NSG) allows inbound traffic on port&amp;nbsp;&lt;STRONG&gt;8188&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;P&gt;You can create Text to Image generation workflows using the templates available in ComfyUI.&lt;/P&gt;
                &lt;P&gt;Go to Workflows and select a Text to Image template to get started. Choose&amp;nbsp;&lt;STRONG&gt;Z-Image-Turbo Text to Image&lt;/STRONG&gt; as an example.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;After that, ComfyUI will detect that there are some missing models to download.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;You will need to download each model into its corresponding folder. For example, the Stable Diffusion model should be placed in the&amp;nbsp;&lt;STRONG&gt;models/Stable-diffusion&lt;/STRONG&gt; folder. The models download links and their corresponding folders are shown in the ComfyUI interface. Let's download the required models for &lt;STRONG&gt;Z-Image-Turbo&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;cd comfy/ComfyUI/
                wget -P models/text_encoders/ https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors
                wget -P models/vae/ https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors
                wget -P models/diffusion_models/ https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/diffusion_models/z_image_turbo_bf16.safetensors
                wget -P models/loras/ https://huggingface.co/tarn59/pixel_art_style_lora_z_image_turbo/resolve/main/pixel_art_style_z_image_turbo.safetensors&lt;/LI-CODE&gt;&lt;img /&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;Note that here you can either use &lt;STRONG&gt;comfy model download&lt;/STRONG&gt; command or &lt;STRONG&gt;wget&lt;/STRONG&gt; to download the models into their corresponding folders.&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;P&gt;Once the models are downloaded, you can run the Text to Image workflow in ComfyUI. You can also change the parameters as needed like the prompt.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;When ready, click the Run blue button at the top right to start generating the image. It will take some time depending on the size of the image and the complexity of the prompt. Then you should see the generated image in the output node.&lt;/P&gt;
                &lt;H4&gt;5. Using ComfyUI for Text to Video&lt;/H4&gt;
                &lt;P&gt;To use ComfyUI for &lt;STRONG&gt;Text to Video&lt;/STRONG&gt; generation, you can select a Text to Video template from the Workflows section. Choose&amp;nbsp;&lt;STRONG&gt;Wan 2.2 Text to Video&lt;/STRONG&gt; as an example. Then you will need to install the required models.&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;wget -P models/text_encoders/ https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors

                wget -P models/vae/ https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors

                wget -P models/diffusion_models/ https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_t2v_low_noise_14B_fp8_scaled.safetensors

                wget -P models/diffusion_models/ https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors

                wget -P models/loras/ https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_t2v_lightx2v_4steps_lora_v1.1_high_noise.safetensors

                wget -P models/loras/ https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_t2v_lightx2v_4steps_lora_v1.1_low_noise.safetensors&lt;/LI-CODE&gt;
                &lt;P&gt;Models for &lt;STRONG&gt;LTX-2&lt;/STRONG&gt; &lt;STRONG&gt;Text to Video&lt;/STRONG&gt; can be downloaded similarly.&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;wget -P models/checkpoints/ https://huggingface.co/Lightricks/LTX-2/resolve/main/ltx-2-19b-dev-fp8.safetensors

                wget -P models/text_encoders/ https://huggingface.co/Comfy-Org/ltx-2/resolve/main/split_files/text_encoders/gemma_3_12B_it_fp4_mixed.safetensors

                wget -P models/latent_upscale_models/ https://huggingface.co/Lightricks/LTX-2/resolve/main/ltx-2-spatial-upscaler-x2-1.0.safetensors

                wget -P models/loras/ https://huggingface.co/Lightricks/LTX-2/resolve/main/ltx-2-19b-distilled-lora-384.safetensors

                wget -P models/loras/ https://huggingface.co/Lightricks/LTX-2-19b-LoRA-Camera-Control-Dolly-Left/resolve/main/ltx-2-19b-lora-camera-control-dolly-left.safetensors&lt;/LI-CODE&gt;
                &lt;P&gt;Models for&amp;nbsp;&lt;STRONG&gt;Qwen Image 2512&lt;/STRONG&gt; Text to Image can be downloaded similarly.&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;wget -P models/text_encoders/ https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors

                wget -P models/vae/ https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors

                wget -P models/diffusion_models/ https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_2512_fp8_e4m3fn.safetensors

                wget -P models/loras/ https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors&lt;/LI-CODE&gt;
                &lt;P&gt;Models for &lt;STRONG&gt;Flux2 Klein Text to Image 9B&lt;/STRONG&gt; can be downloaded similarly.&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;wget -P models/text_encoders/ https://huggingface.co/Comfy-Org/flux2-klein-9B/resolve/main/split_files/text_encoders/qwen_3_8b_fp8mixed.safetensors

                wget -P models/vae/ https://huggingface.co/Comfy-Org/flux2-dev/resolve/main/split_files/vae/flux2-vae.safetensors

                wget -P models/diffusion_models/ https://huggingface.co/black-forest-labs/FLUX.2-klein-base-9b-fp8/resolve/main/flux-2-klein-base-9b-fp8.safetensors

                wget -P models/diffusion_models/ https://huggingface.co/black-forest-labs/FLUX.2-klein-9b-fp8/resolve/main/flux-2-klein-9b-fp8.safetensors&lt;/LI-CODE&gt;
                &lt;H2&gt;&amp;nbsp;Important notes&lt;/H2&gt;
                &lt;P&gt;Secure Boot is not supported using Windows or Linux extensions. For more information on manually installing GPU drivers with Secure Boot enabled, see Azure N-series GPU driver setup for Linux. Src: &lt;A class="lia-external-url" href="https://learn.microsoft.com/en-us/azure/virtual-machines/extensions/hpccompute-gpu-linux" target="_blank" rel="noopener"&gt;https://learn.microsoft.com/en-us/azure/virtual-machines/extensions/hpccompute-gpu-linux&lt;/A&gt;&lt;/P&gt;
                &lt;H4&gt;Sources&lt;/H4&gt;
                &lt;P&gt;- Install CUDA drivers on N-series VMs: &lt;A class="lia-external-url" href="https://learn.microsoft.com/en-us/azure/virtual-machines/extensions/hpccompute-gpu-linux" target="_blank" rel="noopener"&gt;https://learn.microsoft.com/en-us/azure/virtual-machines/linux/n-series-driver-setup#install-cuda-drivers-on-n-series-vms&lt;/A&gt;&lt;/P&gt;
                &lt;P&gt;- Install ComfyUI using Comfy CLI: &lt;A class="lia-external-url" href="https://comfyui-wiki.com/en/install/install-comfyui/install-comfyui-on-linux" target="_blank" rel="noopener"&gt;https://comfyui-wiki.com/en/install/install-comfyui/install-comfyui-on-linux&lt;/A&gt;&lt;/P&gt;
                &lt;H5&gt;Disclaimer&lt;/H5&gt;
                &lt;P&gt;The sample scripts are not supported under any Microsoft standard support program or service. The sample scripts are provided AS IS without warranty of any kind. Microsoft further disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a particular purpose. The entire risk arising out of the use or performance of the sample scripts and documentation remains with you. In no event shall Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility of such damages.&lt;/P&gt;</description>
            <pubDate>Fri, 27 Feb 2026 23:35:57 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/core-infrastructure-and-security/running-text-to-image-and-text-to-video-with-comfyui-and-nvidia/ba-p/4497978</guid>
            <dc:creator>HoussemDellai</dc:creator>
            <dc:date>2026-02-27T23:35:57Z</dc:date>
        </item>
        <item>
            <title>Title Plan Update - February 27, 2026</title>
            <link>https://techcommunity.microsoft.com/t5/ilt-communications-blog/title-plan-update-february-27-2026/ba-p/4497957</link>
            <description>&lt;img /&gt;
                &lt;H4&gt;📁&lt;STRONG&gt;February 27, 2026 - Title Plan Now Available&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;H4&gt;Access the latest Instructor-Led Training (ILT) updates anytime at&amp;nbsp;&lt;A href="https://nam06.safelinks.protection.outlook.com/?url=http%3A%2F%2Faka.ms%2FCourseware_Title_Plan&amp;amp;data=05%7C02%7Cv-aslyman%40microsoft.com%7C17dfe1a6ad1f49c1839208de4a304d49%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C639029768499335587%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&amp;amp;sdata=T0XSvelxN%2BvWJR1Q%2F%2B791m03a4Trajflams4GR2%2FlK4%3D&amp;amp;reserved=0" target="_blank" rel="noopener"&gt;http://aka.ms/Courseware_Title_Plan&lt;/A&gt;&amp;nbsp;to ensure you're always working from the most current version.&lt;/H4&gt;
                &lt;P&gt;📌&amp;nbsp;&lt;EM&gt;Reminder: To help you stay informed more quickly and consistently, we’ve moved to a weekly publishing cadence for the title plan. This means each update may include fewer changes but ensures you’re always up to date.&lt;/EM&gt;&lt;/P&gt;</description>
            <pubDate>Fri, 27 Feb 2026 20:42:00 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/ilt-communications-blog/title-plan-update-february-27-2026/ba-p/4497957</guid>
            <dc:creator>AshleeLyman</dc:creator>
            <dc:date>2026-02-27T20:42:00Z</dc:date>
        </item>
        <item>
            <title>Agent mode in Excel now works with your local files</title>
            <link>https://techcommunity.microsoft.com/t5/microsoft-365-insider-blog/agent-mode-in-excel-now-works-with-your-local-files/ba-p/4497675</link>
            <description>&lt;P&gt;Hello Insiders! I am Prash Shirolkar, a Product Manager on the Excel team. I am thrilled to announce that Agent mode in Microsoft 365 Copilot Chat now enables you to query modern (.xlsx, .xlsb, .xlsm) locally stored Excel workbooks on Windows and Mac desktop.&lt;/P&gt;
                &lt;H3&gt;Agent mode in Excel now works with your local files&lt;/H3&gt;
                &lt;P&gt;Previously, insights and analysis from Excel Agent mode were limited to Excel workbooks stored in the cloud. With this new feature, analyzing your locally saved Excel workbooks with Excel Agent mode makes it possible to stay productive even when you’re offline.&lt;/P&gt;
                &lt;H3&gt;How it works&lt;/H3&gt;
                &lt;OL&gt;
                &lt;LI&gt;In Excel for Windows or Excel for Mac, open a local file saved on your computer or network share.&lt;/LI&gt;
                &lt;LI&gt;In the ribbon, click the&amp;nbsp;&lt;STRONG&gt;Copilot &lt;/STRONG&gt;icon. In the Copilot pane, if you don’t see Agent mode in the input box, then select &lt;STRONG&gt;Tools&lt;/STRONG&gt;. Choose &lt;STRONG&gt;Agent mode&lt;/STRONG&gt; and then type your query or data modifications. &amp;nbsp;&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;img /&gt;
                &lt;H3&gt;Availability&lt;/H3&gt;
                &lt;P&gt;This feature is rolling out to Excel for Windows and Excel for Mac users with a Copilot Chat-eligible Microsoft 365 subscription running:&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Windows: Version 2601 (Build 19628.20204) or later&lt;/LI&gt;
                &lt;LI&gt;Mac: Version 16.105 (Build 26011018) or later&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;Feedback&lt;/H3&gt;
                &lt;P&gt;We’d love to hear from you! Let us know what you think by selecting Help &amp;gt; Feedback and including #LocalFilesAgent in your comments so we can easily find them!&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Learn about the&amp;nbsp;&lt;A href="https://aka.ms/MSFT365InsiderProgram" target="_blank" rel="noopener"&gt;Microsoft 365 Insider program&lt;/A&gt;&amp;nbsp;and sign up for the&amp;nbsp;&lt;A href="https://aka.ms/msft365insidernews" target="_blank" rel="noopener"&gt;Microsoft 365 Insider newsletter&lt;/A&gt;&amp;nbsp;to get the latest information about Insider features in your inbox once a month!&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;</description>
            <pubDate>Fri, 27 Feb 2026 22:00:10 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/microsoft-365-insider-blog/agent-mode-in-excel-now-works-with-your-local-files/ba-p/4497675</guid>
            <dc:creator>Prash_MSFT</dc:creator>
            <dc:date>2026-02-27T22:00:10Z</dc:date>
        </item>
        <item>
            <title>Unlocking High-Performance Inference for DeepSeek with NVFP4 on NVIDIA Blackwell</title>
            <link>https://techcommunity.microsoft.com/t5/microsoft-foundry-blog/unlocking-high-performance-inference-for-deepseek-with-nvfp4-on/ba-p/4497936</link>
            <description>&lt;H3&gt;&lt;STRONG&gt;Summary&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/H3&gt;
                &lt;P&gt;We partnered closely with NVIDIA to unlock high-performance single-node inference for DeepSeek-V3.2 on NVIDIA Blackwell. By leveraging NVIDIA’s new &lt;A href="https://huggingface.co/nvidia/DeepSeek-V3.2-NVFP4" target="_blank" rel="noopener"&gt;NVFP4 checkpoint for DeepSeek-V3.2&lt;/A&gt; combined with NVIDIA TensorRT LLM on NVIDIA Blackwell, we achieved breakthrough inference performance. These experiments were performed on a single node (2 Grace Blackwell superchips) of the NVIDIA GB200 NVL72 platform (hereafter referred to as an NVIDIA GB200 node), similar to the &lt;A href="https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/gpu-accelerated/nd-gb200-v6-series?tabs=sizebasic" target="_blank" rel="noopener"&gt;Standard_ND128isr_NDR_GB200_v6 VM&lt;/A&gt; available on Azure.&lt;/P&gt;
                &lt;P&gt;Using an aligned apples-to-apples benchmark methodology, single-node inference using&amp;nbsp;&amp;nbsp; NVIDIA GB200 nodes with NVFP4 and TensorRT LLM delivers up to &lt;STRONG&gt;2.5x lower per-user latency &lt;/STRONG&gt;than similar inference configurations with NVIDIA H200 GPUs. &amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Beyond increased performance, using NVIDIA GB200 nodes with NVFP4 dramatically increases the number of users which can be served from the same GPU footprint as an H200 deployment. While maintaining a consistent latency target across both GB200 and H200 deployments, our experiments demonstrated that single-node deployments of DeepSeek-V3.2 can serve up to &lt;STRONG&gt;16 times as many users per GPU when using NVIDIA GB200 nodes versus NVIDIA H200 nodes&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;P&gt;The results came from end-to-end co-optimization across three layers:&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Hardware&lt;/STRONG&gt;: Our experiments are performed on individual nodes of the NVIDIA GB200 NVL72, with each node consisting of 2 Grace CPUs and 4 Blackwell GPUs.&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Model weights&lt;/STRONG&gt;: NVFP4-quantized weights for DeepSeek-V3.2 are optimized to deliver high inference efficiency while preserving model quality&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Inference runtime&lt;/STRONG&gt;: TensorRT LLM used as the production-grade serving and execution engine, configured to optimize DeepSeek on Blackwell GPUs&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;P&gt;This post details how we achieved these results, including our serving and benchmarking setup.&lt;/P&gt;
                &lt;P&gt;This configuration is now used to serve DeepSeek-V3.2 on Microsoft Foundry. See &lt;A href="https://ai.azure.com/catalog/models/DeepSeek-V3.2" target="_blank" rel="noopener"&gt;here&lt;/A&gt; for information about DeepSeek-V3.2 on Microsoft Foundry.&lt;/P&gt;
                &lt;H3&gt;&lt;STRONG&gt;Unlocking Blackwell Performance&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/H3&gt;
                &lt;P&gt;DeepSeek-V3.2 offers strong reasoning performance and broad task coverage, making it well-suited for real-world production workloads. However, the sheer scale of this 690-billion-parameter Mixture-of-Experts (MoE) model presents an inherent challenge. Achieving efficient, cost-effective inference at this magnitude demands careful, end-to-end optimization across the entire stack—from model representation to runtime and system configuration—all while preserving output quality and predictable latency.&lt;/P&gt;
                &lt;P&gt;The NVIDIA GB200 NVL72 platform, integrated with NVFP4 quantization and the TensorRT LLM inference engine, offers a powerful solution for delivering high-performance, cost-effective inference for DeepSeek-V3.2.&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;NVIDIA GB200 NVL72&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/H4&gt;
                &lt;P&gt;The NVIDIA GB200 NVL72 is a rack-scale solution that leverages 72 NVIDIA Blackwell GPUs with 36 NVIDIA Grace CPUs to deliver high performance inference. Each of the 72 Blackwell GPUs contains 186 GB of high-bandwidth HBM3e memory, a 32% increase in per-GPU memory compared to NVIDIA H200 GPUs. NVIDIA Blackwell’s second-generation transformer engines provide 10 PFLOPS of dense NVFP4 performance per GPU, a 5x increase over 2 PFLOPS for dense FP8 on H200.&lt;/P&gt;
                &lt;P&gt;For MoE models like DeepSeekV3.2, Blackwell’s superior memory capacity and NVFP4 compute throughput enable higher inference performance.&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;NVFP4 Floating Point Precision&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/H4&gt;
                &lt;P&gt;NVFP4 is an innovative 4-bit floating point format introduced with the NVIDIA Blackwell architecture. By encoding quantized blocks with non-power-of-two scaling factors, NVFP4 simultaneously enables higher performance, reduced memory footprint, and preserved model accuracy when compared with FP8 and FP16 floating point formats. NVFP4 is optimized to take advantage of NVIDIA Blackwell’s native Tensor Core support.&lt;/P&gt;
                &lt;P&gt;For DeepSeek-V3.2, NVIDIA’s NVFP4 quantization reduced the memory footprint of the model by 1.7x compared to the model’s original FP8 format (415 GB vs. 690 GB), leading to significant boosts in throughput and cost savings. NVIDIA has published comprehensive quality benchmarking results for the DeepSeek-V3.2 NVFP4 model, showing that the quantized weights maintain accuracy closely aligned with the original FP8 model across a broad set of industry-standard benchmarks.&lt;/P&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table border="1" style="border-width: 1px;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Precision&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;MMLU Pro&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;GPQA Diamond&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;LiveCodeBench&amp;nbsp;V6&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;SciCode&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;AIME 2025&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;FP8&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.802&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.849&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.756&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.391&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.934&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;NVFP4&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.799&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.835&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.756&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.401&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.923&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 16.67%" /&gt;&lt;col style="width: 16.67%" /&gt;&lt;col style="width: 16.67%" /&gt;&lt;col style="width: 16.67%" /&gt;&lt;col style="width: 16.67%" /&gt;&lt;col style="width: 16.67%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;P class="lia-align-center"&gt;&lt;EM&gt;Table 1: Results of DeepSeek-V3.2’s Accuracy Benchmark Results Across FP8 and NVFP4 Checkpoints&lt;/EM&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Across reasoning, coding, and scientific benchmarks, NVFP4 delivers near-parity results relative to FP8, validating its suitability for production inference where memory efficiency and throughput are critical.&lt;/P&gt;
                &lt;P&gt;For detailed model quality metrics and benchmark comparisons, see the &lt;A href="https://huggingface.co/nvidia/DeepSeek-V3.2-NVFP4" target="_blank" rel="noopener"&gt;NVIDIA DeepSeek-V3.2-NVFP4 model card&lt;/A&gt;.&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;TensorRT LLM&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/H4&gt;
                &lt;P&gt;TensorRT LLM is an open-source library used for optimizing LLM inference. It provides high-performance optimizations for NVIDIA GPUs such as low-precision serving, in-flight batching, custom attention kernels, and much more. TensorRT-LLM's optimized support for sparse attention and large context windows enables DeepSeek-V3.2 to achieve breakthrough performance.&lt;/P&gt;
                &lt;H3&gt;&lt;STRONG&gt;Benchmark Methodology&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/H3&gt;
                &lt;P&gt;We utilized a fair and practical benchmark methodology, reflecting production-style inference patterns. Although multi-node inference is anticipated to deliver higher per-GPU performance by leveraging features like&lt;A href="https://www.nvidia.com/en-us/glossary/disaggregated-serving/" target="_blank" rel="noopener"&gt; &lt;/A&gt;&lt;A href="https://www.nvidia.com/en-us/glossary/disaggregated-serving/" target="_blank" rel="noopener"&gt;disaggregated serving&lt;/A&gt; and&lt;A href="https://developer.nvidia.com/blog/scaling-large-moe-models-with-wide-expert-parallelism-on-nvl72-rack-scale-systems/" target="_blank" rel="noopener"&gt; &lt;/A&gt;&lt;A href="https://developer.nvidia.com/blog/scaling-large-moe-models-with-wide-expert-parallelism-on-nvl72-rack-scale-systems/" target="_blank" rel="noopener"&gt;Wide EP&lt;/A&gt;, we focused on isolating our experiments to single-node performance to ensure a clear comparison between the two platforms.&lt;/P&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table border="1" style="border-width: 1px;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Parameter&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Value&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Input length&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;2,400 tokens&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Output length&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;1,600 tokens&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Concurrent Requests&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;1, 2, 4, 8, 16, 32, 64&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Dataset&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;A href="https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/blob/main/ShareGPT_V3_unfiltered_cleaned_split.json" target="_blank" rel="noopener"&gt;ShareGPT_V3_unfiltered_cleaned_split&lt;/A&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Target Metrics&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Output Throughput (tokens/sec), End-to-End Latency (ms)&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 50.00%" /&gt;&lt;col style="width: 50.00%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;P class="lia-align-center"&gt;&lt;EM&gt;Table 2: Load Profile for Performance Benchmarks&lt;/EM&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;As real-world inference performance varies with the quantity of active requests, our experiments measured system performance under different loads, as shown in the "Concurrent Requests" parameter in Table 2. This is sometimes referred to as “concurrency”.&lt;/P&gt;
                &lt;P&gt;Our two targeted metrics are output throughput and end-to-end latency. Output throughput measures the cumulative number of tokens produced by the model per second across all concurrent requests. End-to-end latency is a measure of the total time taken by the model to complete a request. It is measured from the time the request is sent to the model, to the time the response’s final token is generated.&lt;/P&gt;
                &lt;P&gt;The following script was used to benchmark performance at multiple request concurrencies using SGLang’s sglang.bench_serving tool. The script sends prompt requests to a provided inference endpoint, then gathers performance data such as throughput, time-to-first-token, and end-to-end latency. Read more about the sglang.bench_serving tool &lt;A href="https://github.com/sgl-project/sglang/blob/main/docs/developer_guide/bench_serving.md" target="_blank" rel="noopener"&gt;here&lt;/A&gt;.&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;#!/usr/bin/env bash
                set -euo pipefail
                CONCURRENCY_LIST=(1 2 4 8 16 32 64)
                for max_concurrency in "${CONCURRENCY_LIST[@]}"; do
                echo "==&amp;gt; Running benchmark with --max-concurrency ${max_concurrency}"
                python3 -m sglang.bench_serving \
                --backend sglang-oai \
                --model ./DeepSeek-V3.2-NVFP4/ \
                --num-prompts 500 \
                --max-concurrency "${max_concurrency}" \
                --tokenizer ./DeepSeek-V3.2-NVFP4/ \
                --dataset-path ./ShareGPT_V3_unfiltered_cleaned_split.json \
                --sharegpt-output-len 1600 \
                --sharegpt-context-len 2400
                done  &lt;/LI-CODE&gt;
                &lt;H3&gt;&lt;STRONG&gt;Results: NVIDIA GB200 Node with NVFP4 Achieves Best Performance&lt;/STRONG&gt;&lt;/H3&gt;
                &lt;img /&gt;
                &lt;P class="lia-align-center"&gt;&lt;EM&gt;Figure 1: Single-Node Inference: Throughput (output tokens per second) vs Median End-to-End Latency (ms)&lt;/EM&gt;&lt;/P&gt;
                &lt;P&gt;Figure 1 plots throughput (output tokens per second) against median end-to-end latency (ms). The annotations on the graph denoted “cX:Y” outline the request concurrency at which the data point was gathered, where X is the request concurrency, and Y is the throughput observed at that request concurrency, measured in tokens per second. Higher and further left indicates better efficiency. Across all concurrencies, the configuration using GB200, NVFP4, and TensorRT LLM consistently achieves the best efficiency. &amp;nbsp;&lt;/P&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table border="1" style="border-width: 1px;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Configuration&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Concurrency&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Throughput (tks/s)&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Median E2E Latency (ms)&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Throughput/Latency&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;GB200 with NVFP4&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;1&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;272&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;5,801&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;0.047&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;GB200 with FP8&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;1&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;228&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;7,015&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.033&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;H200 with FP8&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;1&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;109&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;14,716&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;0.007&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 20.00%" /&gt;&lt;col style="width: 20.00%" /&gt;&lt;col style="width: 20.00%" /&gt;&lt;col style="width: 20.00%" /&gt;&lt;col style="width: 20.00%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;P class="lia-align-center"&gt;&lt;EM&gt;Table 3: Single-concurrency requests&lt;/EM&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Key findings:&lt;/STRONG&gt;&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Up to 2.5x lower end-to-end latency&lt;/STRONG&gt;: A GB200 node with NVFP4 delivers 5801 ms median latency vs. 14716 ms median latency on an H200 node at concurrency 1, a 2.5x improvement.&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Best efficiency curve&lt;/STRONG&gt;: Figure 1 shows that at each concurrency, a GB200 node with NVFP4 has the highest throughput and lowest latency compared to both a GB200 node&amp;nbsp; with FP8 and an H200 node with FP8.&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Serve up to 16x more users per GPU&lt;/STRONG&gt;: Given an end-to-end latency target of 15,000 milliseconds, single-node inference for DeepSeek-V3.2 with NVFP4 on an NVIDIA GB200 node&amp;nbsp; yields 8x the throughput and can serve up to 8 concurrent users, while an NVIDIA H200 node can serve only 1 user. Since our GB200 NVL72 nodes contain 4 GPUs, and our H200 nodes contain 8 GPUs, this translates to 16x higher performance per GPU.&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;H3&gt;&lt;STRONG&gt;Serving Configuration Reference&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/H3&gt;
                &lt;P&gt;This section shows how we served DeepSeek-V3.2 in our experiments. Depending on the hardware and software configurations used, replicated results may vary.&lt;/P&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table border="1" style="width: 957px; border-width: 1px;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;Parameter&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;Blackwell NVFP4&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;Blackwell FP8&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;Hopper FP8&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;GPUs&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;4x GB200&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;4x GB200&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;8x H200&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Nodes&lt;/P&gt;
                &lt;/td&gt;&lt;td colspan="3"&gt;
                &lt;P class="lia-align-center"&gt;1&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Tensor Parallelism&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;4&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;4&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;8&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Max Batch Size&lt;/P&gt;
                &lt;/td&gt;&lt;td colspan="3"&gt;
                &lt;P class="lia-align-center"&gt;64&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;MTP Enabled&lt;/P&gt;
                &lt;/td&gt;&lt;td colspan="3"&gt;
                &lt;P class="lia-align-center"&gt;Yes&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P class="lia-align-left"&gt;Inference Engine&amp;nbsp;&lt;/P&gt;
                &lt;/td&gt;&lt;td colspan="3"&gt;
                &lt;P class="lia-align-center"&gt;&lt;A href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tensorrt-llm/containers/release?version=1.2.0rc8" target="_blank" rel="noopener"&gt;TensorRT LLM v1.2.0rc8&lt;/A&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Model Checkpoint&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;A href="https://huggingface.co/nvidia/DeepSeek-V3.2-NVFP4" target="_blank" rel="noopener"&gt;nvidia/DeepSeek-V3.2-NVFP4&lt;/A&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;A href="https://huggingface.co/deepseek-ai/DeepSeek-V3.2" target="_blank" rel="noopener"&gt;deepseek-ai/DeepSeek-V3.2&lt;/A&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;A href="https://huggingface.co/deepseek-ai/DeepSeek-V3.2" target="_blank" rel="noopener"&gt;deepseek-ai/DeepSeek-V3.2&lt;/A&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 25.00%" /&gt;&lt;col style="width: 25.00%" /&gt;&lt;col style="width: 25.00%" /&gt;&lt;col style="width: 25.00%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;P class="lia-align-center"&gt;&lt;EM&gt;Table 4: Serving Configuration Parameters&lt;/EM&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Config File&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;cuda_graph_config:
                enable_padding: true
                batch_sizes: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,32,64]
                kv_cache_config:
                free_gpu_memory_fraction: 0.8
                dtype: fp8
                moe_config:
                backend: TRTLLM
                speculative_config:
                decoding_type: MTP
                num_nextn_predict_layers: 3  &lt;/LI-CODE&gt;
                &lt;P&gt;&lt;EM&gt;Note: While model weights use NVFP4, the KV cache&amp;nbsp;remains&amp;nbsp;FP8 to balance memory efficiency with numerical stability during decode.&lt;/EM&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Serving the Model&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;The following command launches the TensorRT LLM inference server for the DeepSeek-V3.2 model, using the preceding configuration file and exposing the service on port 30000 for high-throughput serving.&lt;/P&gt;
                &lt;LI-CODE lang="shell"&gt;trtllm-serve serve ./DeepSeek-V3.2-NVFP4/ \
                --tp_size 4 \
                --max_batch_size 64 \
                --trust_remote_code \
                --extra_llm_api_options ./config.yaml \
                --host 0.0.0.0 \
                --port 30000&lt;/LI-CODE&gt;
                &lt;H3&gt;&lt;STRONG&gt;What’s Next&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/H3&gt;
                &lt;P&gt;&lt;STRONG&gt;Rack-Scale Inference&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;This blog post focuses on single-node inference (2 Grace CPUs and 4 Blackwell GPUs and 8 GPUs for H200). We anticipate even greater performance improvements with multi-node serving configurations, including those leveraging disaggregated serving, TensorRT LLM’s Wide EP capabilities, and all 72 GPUs on the NVIDIA GB200 NVL72 rack system&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Apply Approach to New Models&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;We plan to apply the same approach of introducing Blackwell, NVFP4, TensorRT LLM, and kernel tuning to additional model families.&lt;/P&gt;
                &lt;H3&gt;&lt;STRONG&gt;Acknowledgements&lt;/STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/H3&gt;
                &lt;P&gt;This work was enabled by close collaboration between engineering teams from&amp;nbsp; Microsoft and NVIDIA. Key contributors include Xiaoran Li, Tao Wang, and Vivek Ramaswamy from Microsoft; and Stephen McCullough, Anurag Mukkara, and Nikhar Maheshwari from NVIDIA.&lt;/P&gt;</description>
            <pubDate>Fri, 27 Feb 2026 23:22:36 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/microsoft-foundry-blog/unlocking-high-performance-inference-for-deepseek-with-nvfp4-on/ba-p/4497936</guid>
            <dc:creator>xiaoranli</dc:creator>
            <dc:date>2026-02-27T23:22:36Z</dc:date>
        </item>
        <item>
            <title>Ask Microsoft Anything: Data &amp; AI Security in the Real World</title>
            <link>https://techcommunity.microsoft.com/t5/microsoft-security-community/ask-microsoft-anything-data-ai-security-in-the-real-world/ba-p/4497679</link>
            <description>&lt;P&gt;&lt;SPAN data-contrast="auto"&gt;At RSA this year,&amp;nbsp;we’re&amp;nbsp;hosting Ask the Experts: Data &amp;amp; AI Security in the Real&amp;nbsp;World&amp;nbsp;a live, unscripted conversation with Microsoft Security engineers and product leaders who are actively building and securing AI&amp;nbsp;systems on a&amp;nbsp;scale.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;And if&amp;nbsp;you’re&amp;nbsp;not attending in person, you can join the conversation online through Tech Community.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;What to Expect&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;This is not a traditional conference session.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;There are no slide decks.&lt;/SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;SPAN data-contrast="auto"&gt;There’s no product pitch.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;Instead,&amp;nbsp;we’ll&amp;nbsp;host an open AMA-style discussion where security practitioners can ask:&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Implementation questions&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Architecture questions&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Lessons learned from early deployments&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;You’ll&amp;nbsp;hear directly from the engineers and security leaders responsible for securing Microsoft AI systems and customer environments.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Topics&amp;nbsp;We’ll&amp;nbsp;Cover&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;While the format is open, we expect to dive into areas like:&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Data protection strategies for AI workloads&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Securing copilots and generative AI integrations&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Identity and access controls for AI services&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;UL&gt;
                &lt;LI aria-setsize="-1" data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;multilevel&amp;quot;}" data-aria-posinset="4" data-aria-level="1"&gt;&lt;SPAN data-contrast="auto"&gt;Monitoring, logging, and anomaly detection&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H4&gt;&lt;STRONG&gt;&lt;SPAN data-contrast="auto"&gt;Join Us at RSA or Online&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/H4&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;If&amp;nbsp;you’re&amp;nbsp;attending RSA, join us live and bring your toughest questions.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-contrast="auto"&gt;If&amp;nbsp;you’re&amp;nbsp;remote,&amp;nbsp;participate&amp;nbsp;through Tech&amp;nbsp;Community;&amp;nbsp;where you can post questions in advance or engage during the live discussion. The conversation will remain open&amp;nbsp;afterward&amp;nbsp;so practitioners across time zones can continue the dialogue.&lt;/SPAN&gt;&lt;SPAN data-ccp-props="{}"&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;SPAN data-ccp-props="{}"&gt;Hope to see you there!&lt;/SPAN&gt;&lt;/P&gt;
                &lt;P&gt;&lt;A class="lia-internal-link lia-internal-url lia-internal-url-content-type-occasion" href="https://techcommunity.microsoft.com/event/microsoft-security-events/ask-microsoft-anything-data--ai-security-in-the-real-world/4488610" data-lia-auto-title="Tech Community Event Link" data-lia-auto-title-active="0" target="_blank"&gt;&lt;SPAN data-ccp-props="{}"&gt;Tech Community Event Link&lt;/SPAN&gt;&lt;/A&gt;&lt;/P&gt;</description>
            <pubDate>Fri, 27 Feb 2026 17:00:00 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/microsoft-security-community/ask-microsoft-anything-data-ai-security-in-the-real-world/ba-p/4497679</guid>
            <dc:creator>BrookeLynnWeenig</dc:creator>
            <dc:date>2026-02-27T17:00:00Z</dc:date>
        </item>
        <item>
            <title>Microsoft Foundry: An End-to-End Platform for Building, Governing, and Scaling AI</title>
            <link>https://techcommunity.microsoft.com/t5/microsoft-foundry-blog/microsoft-foundry-an-end-to-end-platform-for-building-governing/ba-p/4496736</link>
            <description>&lt;H1&gt;Microsoft Foundry: What It Is and How to Get Started&lt;/H1&gt;
                &lt;P&gt;As organizations accelerate their adoption of AI, one challenge consistently emerges: how to move from experimentation to production at scale in a secure, responsible, and efficient way. Microsoft Foundry exists to address exactly that challenge.&lt;/P&gt;
                &lt;H2&gt;What Is Microsoft Foundry?&lt;/H2&gt;
                &lt;P&gt;Microsoft Foundry is an end-to-end platform experience that brings together Microsoft’s AI development, deployment, and governance capabilities into a unified environment. It enables developers, data scientists, and enterprises to build, customize, deploy, and operate AI solutions, including generative AI, using Microsoft and partner models, tools, and services.&lt;/P&gt;
                &lt;P&gt;Rather than being a single product, Foundry is a curated and integrated experience that spans model access, tooling, orchestration, evaluation, and enterprise-grade controls.&lt;/P&gt;
                &lt;img /&gt;
                &lt;H2&gt;Why Microsoft Foundry Exists&lt;/H2&gt;
                &lt;P&gt;AI innovation is moving fast, but enterprise adoption requires more than just access to models. Customers need:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;A consistent way to work with multiple models, including Microsoft, OpenAI, and open-source models&lt;/LI&gt;
                &lt;LI&gt;Built-in security, compliance, and responsible AI capabilities&lt;/LI&gt;
                &lt;LI&gt;Tooling that supports the full AI lifecycle, not just prototyping&lt;/LI&gt;
                &lt;LI&gt;Seamless integration with existing data platforms, applications, and cloud operations&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;Microsoft Foundry was created to reduce friction between experimentation and real-world deployment while aligning AI development with enterprise standards, governance, and scale.&lt;/P&gt;
                &lt;H2&gt;What’s Included in Microsoft Foundry?&lt;/H2&gt;
                &lt;P&gt;Microsoft Foundry brings together several key capabilities:&lt;/P&gt;
                &lt;H3&gt;1. Model Choice and Flexibility&lt;/H3&gt;
                &lt;UL&gt;
                &lt;LI&gt;Access to leading foundation models, including Azure OpenAI models and selected open-source models&lt;/LI&gt;
                &lt;LI&gt;Ability to evaluate and select models based on performance, cost, and use case&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table class="lia-border-color-22" border="1" style="width: 100%; height: 464px; border-width: 1px;"&gt;&lt;colgroup&gt;&lt;col style="width: 50.0463%" /&gt;&lt;col style="width: 49.9537%" /&gt;&lt;/colgroup&gt;&lt;tbody&gt;&lt;tr style="height: 464px;"&gt;&lt;td class="lia-border-color-22" style="height: 464px;"&gt;&lt;img /&gt;&lt;/td&gt;&lt;td class="lia-border-color-22" style="height: 464px;"&gt;&lt;img /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;H3&gt;2. AI Development and Orchestration Tools&lt;/H3&gt;
                &lt;UL&gt;
                &lt;LI&gt;Prompt engineering, fine-tuning, and grounding with enterprise data&lt;/LI&gt;
                &lt;LI&gt;Tools for building copilots, chat experiences, and AI-powered applications&lt;/LI&gt;
                &lt;LI&gt;Orchestration across tools, APIs, and workflows&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;img /&gt;
                &lt;H3&gt;3. Evaluation, Safety, and Responsible AI&lt;/H3&gt;
                &lt;UL&gt;
                &lt;LI&gt;Built-in evaluation for quality, latency, and cost&lt;/LI&gt;
                &lt;LI&gt;Content safety, monitoring, and governance controls&lt;/LI&gt;
                &lt;LI&gt;Alignment with Microsoft’s Responsible AI principles&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;img /&gt;
                &lt;H3&gt;4. Enterprise-Grade Platform Integration&lt;/H3&gt;
                &lt;UL&gt;
                &lt;LI&gt;Native integration with Azure, Microsoft Fabric, Power Platform, and developer tools&lt;/LI&gt;
                &lt;LI&gt;Identity, security, and compliance through Microsoft Entra and Azure controls&lt;/LI&gt;
                &lt;LI&gt;Observability and lifecycle management for production workloads&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;img /&gt;
                &lt;H2&gt;How to Get Started&lt;/H2&gt;
                &lt;P&gt;Getting started with Microsoft Foundry is straightforward:&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;&lt;STRONG&gt;&lt;A class="lia-external-url" href="https://ai.azure.com/" target="_blank" rel="noopener"&gt;Start in Azure&lt;/A&gt; &lt;/STRONG&gt;- Use Azure as the control plane to access Foundry experiences and services.&lt;/LI&gt;
                &lt;LI&gt;&lt;A class="lia-external-url" href="https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/foundry-models-overview?view=foundry-classic" target="_blank" rel="noopener"&gt;&lt;STRONG&gt;Explore models and tools&lt;/STRONG&gt;&lt;/A&gt; - Experiment with available models, build prompts, and prototype AI workflows.&lt;/LI&gt;
                &lt;LI&gt;&lt;A class="lia-external-url" href="https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/retrieval-augmented-generation?view=foundry-classic" target="_blank" rel="noopener"&gt;&lt;STRONG&gt;Ground with your data&lt;/STRONG&gt;&lt;/A&gt; - Connect enterprise data securely to create more relevant and contextual AI experiences.&lt;/LI&gt;
                &lt;LI&gt;&lt;A class="lia-external-url" href="https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/deployments-overview?view=foundry-classic" target="_blank" rel="noopener"&gt;&lt;STRONG&gt;Evaluate and deploy&lt;/STRONG&gt;&lt;/A&gt; - Use built-in evaluation and safety tools, then deploy AI solutions into production with confidence.&lt;/LI&gt;
                &lt;LI&gt;&lt;A class="lia-external-url" href="https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/endpoints?view=foundry-classic&amp;amp;tabs=python" target="_blank" rel="noopener"&gt;&lt;STRONG&gt;Scale responsibly&lt;/STRONG&gt;&lt;/A&gt; - Apply governance, monitoring, and cost controls as adoption grows.&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;H2&gt;Final Thoughts&lt;/H2&gt;
                &lt;P&gt;Microsoft Foundry represents Microsoft’s vision for enterprise AI done right. It offers flexible model choice, strong development tooling, and built-in trust. By unifying AI development and operations into a single experience, Foundry helps organizations move faster while staying secure, compliant, and future-ready.&lt;/P&gt;
                &lt;P&gt;Whether you are just starting with generative AI or scaling existing solutions, Microsoft Foundry provides a practical foundation to build on.&lt;/P&gt;</description>
            <pubDate>Fri, 27 Feb 2026 17:00:00 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/microsoft-foundry-blog/microsoft-foundry-an-end-to-end-platform-for-building-governing/ba-p/4496736</guid>
            <dc:creator>DivyaPaduvalli</dc:creator>
            <dc:date>2026-02-27T17:00:00Z</dc:date>
        </item>
        <item>
            <title>Microsoft at NVIDIA GTC 2026</title>
            <link>https://techcommunity.microsoft.com/t5/azure-high-performance-computing/microsoft-at-nvidia-gtc-2026/ba-p/4497670</link>
            <description>&lt;DIV style="font-family: 'Segoe UI', Arial, sans-serif; color: #242424; line-height: 1.6; max-width: 1000px; margin: 0; text-align: left; background-color: #ffffff;"&gt;
                &lt;P&gt;Microsoft returns to NVIDIA GTC 2026 in San Jose with a strong presence across conference sessions, in‑booth theater talks, live demos, and executive‑level ancillary events. Together with NVIDIA and our partner ecosystem, Microsoft is showcasing how Azure AI infrastructure enables AI training, inference, and production at global scale. Visit us at &lt;STRONG&gt;Booth #521&lt;/STRONG&gt; to see the latest innovations in action and connect with Azure and NVIDIA experts.&lt;/P&gt;
                &lt;H2 style="margin-top: 48px; color: #0078d4;"&gt;Exclusive GTC Experiences&lt;/H2&gt;
                &lt;DIV style="display: flex; flex-wrap: wrap; gap: 20px; margin: 24px 0;"&gt;
                &lt;DIV style="flex: 1; min-width: 230px; border: 1px solid #e1e8f0; border-radius: 12px; overflow: hidden; background: #ffffff;"&gt;
                &lt;DIV style="height: 140px; background: #f0f4f8; border-bottom: 1px solid #e1e8f0;"&gt;&lt;IMG style="width: 100%; height: 100%; object-fit: cover;" src="https://iili.io/qfiPP3v.th.jpg" /&gt;&lt;/DIV&gt;
                &lt;DIV style="padding: 15px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; color: #0078d4; font-size: 16px;"&gt;LEGO® Datacenter Model&lt;/H3&gt;
                &lt;P style="margin: 0; font-size: 13px;"&gt;Explore Azure AI infrastructure at the &lt;STRONG&gt;Park Container&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 1; min-width: 230px; border: 1px solid #e1e8f0; border-radius: 12px; overflow: hidden; background: #ffffff;"&gt;
                &lt;DIV style="height: 140px; background: #fdf6f0; border-bottom: 1px solid #e1e8f0;"&gt;&lt;IMG style="width: 100%; height: 100%; object-fit: cover;" src="https://iili.io/qfiPThX.th.png" /&gt;&lt;/DIV&gt;
                &lt;DIV style="padding: 15px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; color: #d83b01; font-size: 16px;"&gt;Candy Lounge&lt;/H3&gt;
                &lt;P style="margin: 0; font-size: 13px;"&gt;Visit the high-traffic candy wall for co-branded treats all day long.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 1; min-width: 230px; border: 1px solid #e1e8f0; border-radius: 12px; overflow: hidden; background: #ffffff;"&gt;
                &lt;DIV style="height: 140px; background: #fcfaff; border-bottom: 1px solid #e1e8f0;"&gt;&lt;IMG style="width: 100%; height: 100%; object-fit: cover;" src="https://iili.io/qfi6QLu.th.png" /&gt;&lt;/DIV&gt;
                &lt;DIV style="padding: 15px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; color: #5c2d91; font-size: 16px;"&gt;Networking Lounge&lt;/H3&gt;
                &lt;P style="margin: 0; font-size: 13px;"&gt;Relax and recharge with comfy seating and vital charging options.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 1; min-width: 230px; border: 1px solid #e1e8f0; border-radius: 12px; overflow: hidden; background: #ffffff;"&gt;
                &lt;DIV style="height: 140px; background: #f5fcf5; border-bottom: 1px solid #e1e8f0;"&gt;&lt;IMG style="width: 100%; height: 100%; object-fit: cover;" src="https://iili.io/qfi6BO7.png" /&gt;&lt;/DIV&gt;
                &lt;DIV style="padding: 15px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; color: #107c10; font-size: 16px;"&gt;Outdoor Juice Truck&lt;/H3&gt;
                &lt;P style="margin: 0; font-size: 13px;"&gt;Free, refreshing beverages served during outdoor park hours.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;H2 style="margin-top: 48px; color: #0078d4;"&gt;Sponsored Breakout Sessions&lt;/H2&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 16px; padding: 24px; margin-bottom: 24px; background: #ffffff;"&gt;
                &lt;DIV style="display: inline-block; background: #0078d4; color: white; padding: 4px 12px; border-radius: 4px; font-size: 11px; font-weight: bold; margin-bottom: 15px; text-transform: uppercase;"&gt;Microsoft Featured&lt;/DIV&gt;
                &lt;H3 style="margin-top: 0; color: #0078d4; font-size: 20px;"&gt;Reinventing Semiconductor Design with Microsoft Discovery&lt;/H3&gt;
                &lt;P style="font-size: 14px; margin-bottom: 20px;"&gt;&lt;STRONG&gt;S82398&lt;/STRONG&gt; · Mon, Mar 16 · 4:00 PM&lt;/P&gt;
                &lt;DIV style="display: flex; align-items: center; gap: 15px; border-top: 1px solid #f0f0f0; padding: 15px 0;"&gt;
                &lt;DIV style="width: 54px; height: 54px; border-radius: 50%; border: 3px solid #0078d4; overflow: hidden; background: #f0f4f8; flex-shrink: 0;"&gt;&lt;IMG style="width: 100%; height: 100%; object-fit: cover;" src="https://iili.io/qfiQDJf.th.jpg" alt="Prashant Varshney" /&gt;&lt;/DIV&gt;
                &lt;DIV&gt;
                &lt;DIV style="font-weight: 600; font-size: 15px;"&gt;Prashant Varshney&lt;/DIV&gt;
                &lt;DIV style="font-size: 13px; color: #555;"&gt;Microsoft · Semiconductor &amp;amp; AI Engineering&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border-top: 1px solid #f0f0f0; padding-top: 15px;"&gt;
                &lt;P style="font-size: 14px; line-height: 1.6; color: #444; margin: 0;"&gt;&lt;STRONG&gt;Abstract:&lt;/STRONG&gt; Semiconductor teams face exploding design complexity and shrinking verification windows. This session shows how the Microsoft Discovery AI for Science platform, combined with Synopsys Agent Engineers, introduces an agentic approach to EDA that automates routine steps and accelerates expert decision-making on Azure.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 16px; padding: 24px; margin-bottom: 24px; background: #ffffff;"&gt;
                &lt;DIV style="display: inline-block; background: #0078d4; color: white; padding: 4px 12px; border-radius: 4px; font-size: 11px; font-weight: bold; margin-bottom: 15px; text-transform: uppercase;"&gt;Microsoft Featured&lt;/DIV&gt;
                &lt;H3 style="margin-top: 0; color: #0078d4; font-size: 20px;"&gt;Operationalizing Agentic AI at Hyperscale&lt;/H3&gt;
                &lt;P style="font-size: 14px; margin-bottom: 20px;"&gt;&lt;STRONG&gt;S82399&lt;/STRONG&gt; · Tue, Mar 17 · 1:00 PM&lt;/P&gt;
                &lt;DIV style="display: grid; grid-template-columns: repeat(auto-fit, minmax(240px, 1fr)); gap: 20px; border-top: 1px solid #f0f0f0; padding: 15px 0;"&gt;
                &lt;DIV style="display: flex; align-items: center; gap: 12px;"&gt;
                &lt;DIV style="width: 50px; height: 50px; border-radius: 50%; border: 3px solid #0078d4; overflow: hidden; background: #f0f4f8; flex-shrink: 0;"&gt;&lt;IMG style="width: 100%; height: 100%; object-fit: cover;" src="https://iili.io/qfiLmn1.th.jpg" alt="Nitin Nagarkatte" /&gt;&lt;/DIV&gt;
                &lt;DIV&gt;
                &lt;DIV style="font-weight: 600; font-size: 14px;"&gt;Nitin Nagarkatte&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; color: #555;"&gt;Microsoft · Azure AI Infrastructure&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="display: flex; align-items: center; gap: 12px;"&gt;
                &lt;DIV style="width: 50px; height: 50px; border-radius: 50%; border: 3px solid #0078d4; overflow: hidden; background: #f0f4f8; flex-shrink: 0;"&gt;&lt;IMG style="width: 100%; height: 100%; object-fit: cover;" src="https://iili.io/qfiskLF.th.jpg" alt="Anand Raman" /&gt;&lt;/DIV&gt;
                &lt;DIV&gt;
                &lt;DIV style="font-weight: 600; font-size: 14px;"&gt;Anand Raman&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; color: #555;"&gt;Microsoft · Azure AI&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="display: flex; align-items: center; gap: 12px;"&gt;
                &lt;DIV style="width: 50px; height: 50px; border-radius: 50%; border: 3px solid #0078d4; overflow: hidden; background: #f0f4f8; flex-shrink: 0;"&gt;&lt;IMG style="width: 100%; height: 100%; object-fit: cover;" src="https://iili.io/qfiiPVe.th.jpg" alt="Vipul Modi" /&gt;&lt;/DIV&gt;
                &lt;DIV&gt;
                &lt;DIV style="font-weight: 600; font-size: 14px;"&gt;Vipul Modi&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; color: #555;"&gt;Microsoft · AI Systems&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border-top: 1px solid #f0f0f0; padding-top: 15px;"&gt;
                &lt;P style="font-size: 14px; line-height: 1.6; color: #444; margin: 0;"&gt;&lt;STRONG&gt;Abstract:&lt;/STRONG&gt; As enterprises move to agentic systems, the challenge shifts to operating intelligent agents reliably at scale. This session demonstrates how Microsoft builds AI Factories on Azure using NVIDIA technology and explores Microsoft Foundry as the control plane for deploying and operating coordinated AI agents.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;H2 style="margin-top: 48px; color: #0078d4;"&gt;Live from GTC: AI Podcast&lt;/H2&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 16px; padding: 32px; margin-bottom: 24px; background: #ffffff; display: flex; flex-wrap: wrap; gap: 30px; align-items: center;"&gt;
                &lt;DIV style="flex: 0 0 auto; display: flex; gap: 20px; align-items: center;"&gt;
                &lt;DIV style="text-align: center;"&gt;
                &lt;DIV style="width: 120px; height: 120px; border-radius: 50%; border: 4px solid #0078d4; overflow: hidden; background: #f0f4f8; margin-bottom: 10px;"&gt;&lt;IMG style="width: 100%; height: 100%; object-fit: cover;" src="https://iili.io/qfiSw2S.md.jpg" alt="Speaker Name" /&gt;&lt;/DIV&gt;
                &lt;DIV style="font-weight: bold; font-size: 14px; color: #242424;"&gt;Dayan Rodriguez&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; color: #555;"&gt;
                &lt;P&gt;Corporate Vice President&lt;BR /&gt;Global Manufacturing &lt;BR /&gt;and Mobility&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="text-align: center;"&gt;
                &lt;DIV style="width: 120px; height: 120px; border-radius: 50%; border: 4px solid #0078d4; overflow: hidden; background: #f0f4f8; margin-bottom: 10px;"&gt;&lt;IMG style="width: 100%; height: 100%; object-fit: cover;" src="https://iili.io/qfivTyg.jpg" alt="Speaker Name" /&gt;&lt;/DIV&gt;
                &lt;DIV style="font-weight: bold; font-size: 14px; color: #242424;"&gt;Alistair Spiers&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; color: #555;"&gt;
                &lt;P&gt;General Manager&lt;BR /&gt;Azure Infrastructure&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 2; min-width: 250px;"&gt;
                &lt;DIV style="display: inline-block; background: #5c2d91; color: white; padding: 4px 12px; border-radius: 4px; font-size: 11px; font-weight: bold; margin-bottom: 12px; text-transform: uppercase;"&gt;Live Special Feature&lt;/DIV&gt;
                &lt;H3 style="margin-top: 0; color: #0078d4; font-size: 24px; margin-bottom: 8px;"&gt;A conversation with Microsoft Azure&lt;/H3&gt;
                &lt;P style="font-size: 16px; color: #d83b01; font-weight: bold; margin: 0 0 20px 0;"&gt;Monday, March 16&amp;nbsp; @ 2PM&lt;/P&gt;
                &lt;DIV style="background: #f8f9fa; padding: 15px; border-radius: 8px; border-left: 4px solid #0078d4;"&gt;
                &lt;DIV style="font-weight: 600; font-size: 13px; margin-bottom: 5px; color: #666;"&gt;Listen &amp;amp; Subscribe:&lt;/DIV&gt;
                &lt;A style="color: #0078d4; text-decoration: none; font-weight: bold; font-size: 18px;" href="https://aka.ms/YourPodcastLink" target="_blank" rel="noopener"&gt;aka.ms/GTC2026Podcast&lt;/A&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 0 0 140px; text-align: center; border: 1px solid #e1e8f0; border-radius: 12px; padding: 15px; background: #ffffff;"&gt;&lt;IMG style="width: 110px; height: 110px; margin-bottom: 10px;" src="https://iili.io/qfiUDH7.png" alt="Scan to Listen" /&gt;
                &lt;DIV style="font-size: 10px; color: #666; font-weight: bold; text-transform: uppercase; letter-spacing: 0.5px;"&gt;Scan to Listen&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;H2 style="margin-top: 48px; color: #0078d4;"&gt;Earned Conference Sessions&lt;/H2&gt;
                &lt;P style="margin-bottom: 24px;"&gt;Don't miss these high-impact sessions where Microsoft and NVIDIA leaders discuss the future of AI factories and infrastructure.&lt;/P&gt;
                &lt;DIV style="display: flex; flex-wrap: wrap; gap: 20px; margin: 24px 0;"&gt;
                &lt;DIV style="flex: 1; min-width: 450px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 100px; display: flex; flex-direction: column; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; text-align: center; padding: 10px;"&gt;
                &lt;DIV style="font-size: 11px; font-weight: bold; color: #0078d4; text-transform: uppercase;"&gt;Mon · Mar 16&lt;/DIV&gt;
                &lt;DIV style="font-size: 16px; font-weight: bold; color: #0078d4; margin-top: 4px;"&gt;5:00 PM&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 17px; color: #0078d4; line-height: 1.4;"&gt;Drive Optimal Tokens per Watt on AI Infrastructure Using Benchmarking Recipes&lt;/H3&gt;
                &lt;DIV style="font-size: 13px; color: #242424; margin-bottom: 4px;"&gt;&lt;STRONG&gt;Speakers:&lt;/STRONG&gt; Paul Edwards, Emily Potyraj&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; color: #666; font-style: italic;"&gt;Microsoft, NVIDIA&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 1; min-width: 450px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 100px; display: flex; flex-direction: column; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; text-align: center; padding: 10px;"&gt;
                &lt;DIV style="font-size: 11px; font-weight: bold; color: #0078d4; text-transform: uppercase;"&gt;Tue · Mar 17&lt;/DIV&gt;
                &lt;DIV style="font-size: 16px; font-weight: bold; color: #0078d4; margin-top: 4px;"&gt;9:00 AM&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 17px; color: #0078d4; line-height: 1.4;"&gt;Autonomous AI Factories: Technical Preview of Agent-Native Production&lt;/H3&gt;
                &lt;DIV style="font-size: 13px; color: #242424; margin-bottom: 4px;"&gt;&lt;STRONG&gt;Speakers:&lt;/STRONG&gt; JP Vasseur, César Martinez Spessot&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; color: #666; font-style: italic;"&gt;NVIDIA, Microsoft Research&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 1; min-width: 450px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 100px; display: flex; flex-direction: column; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; text-align: center; padding: 10px;"&gt;
                &lt;DIV style="font-size: 11px; font-weight: bold; color: #0078d4; text-transform: uppercase;"&gt;Tue · Mar 17&lt;/DIV&gt;
                &lt;DIV style="font-size: 16px; font-weight: bold; color: #0078d4; margin-top: 4px;"&gt;4:00 PM&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 17px; color: #0078d4; line-height: 1.4;"&gt;The Road to Intelligent Mobility: Vehicle GenAI&lt;/H3&gt;
                &lt;DIV style="font-size: 13px; color: #242424; margin-bottom: 4px;"&gt;&lt;STRONG&gt;Speakers:&lt;/STRONG&gt; Raj Paul, Thomas Evans, Bryan Goodman&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; color: #666; font-style: italic;"&gt;Microsoft, NVIDIA, Bosch&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 1; min-width: 450px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 100px; display: flex; flex-direction: column; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; text-align: center; padding: 10px;"&gt;
                &lt;DIV style="font-size: 11px; font-weight: bold; color: #0078d4; text-transform: uppercase;"&gt;Wed · Mar 18&lt;/DIV&gt;
                &lt;DIV style="font-size: 16px; font-weight: bold; color: #0078d4; margin-top: 4px;"&gt;9:00 AM&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 17px; color: #0078d4; line-height: 1.4;"&gt;Supercharging AI with Multi-Gigawatt AI Factories&lt;/H3&gt;
                &lt;DIV style="font-size: 13px; color: #242424; margin-bottom: 4px;"&gt;&lt;STRONG&gt;Speakers:&lt;/STRONG&gt; Gilad Shainer, Peter Salanki, Evan Burness&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; color: #666; font-style: italic;"&gt;NVIDIA, CoreWeave, Meta, Microsoft&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;H2 style="margin-top: 48px; color: #0078d4;"&gt;Daily Booth Theater Schedule&lt;/H2&gt;
                &lt;P style="margin-bottom: 24px;"&gt;Visit the Microsoft Theater for lightning talks from engineering leaders and partners.&lt;/P&gt;
                &lt;H3 style="color: #0078d4; margin-bottom: 15px; border-left: 4px solid #0078d4; padding-left: 10px;"&gt;Monday, March 16&lt;/H3&gt;
                &lt;DIV style="display: flex; flex-direction: column; gap: 12px; margin-bottom: 40px;"&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;2:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH208 · NVIDIA&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Accelerate AI Innovation on Azure with NVIDIA Run:ai &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Rob Magno&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;2:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH202 · General Robotics&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Models to Machines: Deploying Agentic AI in Real-World Robotics &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Dinesh Narayanan&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;3:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH200 · Fractal Analytics&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;From Generalist to Enterprise-Ready: Fractal Builds Domain AI &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— C. Chaudhuri, S. Chakraborty&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;3:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH109 · Microsoft&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Agentic cloud ops - Smarter Operations with Azure Copilot &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Jyoti Sharma&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;4:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH103 · Microsoft&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Build a Deep Research Agent for Enterprise Data &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— D. Casati, A. Slutsky, H. Alkemade&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;4:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH205 · NetApp&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Azure NetApp Files: Powering Your Data for AI Capabilities &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Andy Chan&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;5:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH207 · NVIDIA&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;The Agentic Commerce Stack: Open Models on Azure &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Antonio Martinez&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;5:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH217 · OPAQUE&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Confidential AI on Azure Unlocks Sovereign AI at Scale &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Aaron Fulkerson&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;6:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH218 · Simplismart&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Making BYOC work at scale with modular inference &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Amritanshu Jain&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #fcfcfc; display: flex; overflow: hidden; min-height: 50px;"&gt;
                &lt;DIV style="background: #eee; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #666; font-size: 13px;"&gt;6:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1; display: flex; align-items: center;"&gt;
                &lt;DIV style="font-size: 15px; font-weight: bold; color: #666; text-transform: uppercase; letter-spacing: 1px;"&gt;Expo Reception&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;H3 style="color: #0078d4; margin-bottom: 15px; border-left: 4px solid #0078d4; padding-left: 10px;"&gt;Tuesday, March 17&lt;/H3&gt;
                &lt;DIV style="display: flex; flex-direction: column; gap: 12px; margin-bottom: 40px;"&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;1:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH100 · Microsoft&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;From Open Weights to Enterprise Scale: Open-Source Models &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Sharmila Chockalingam&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;2:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH212 · Personal AI&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Unlocking the power of memory in Teams with Personal AI &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Sam Harkness&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;2:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH111 · Microsoft / NVIDIA&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Scalable LLM Inference on AKS Using NVIDIA Dynamo &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Mohamad Al jazaery, Anton Slutsky&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;3:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH204 · Mistral AI&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Innovate with Mistral AI on Microsoft Foundry &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Ian Mathew&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;3:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH104 · Microsoft&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;GPU-Accelerated CFD at Scale: Star-CCM+ on Azure &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Jason Scheffelmaer&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;4:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH206 · NeuBird AI&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Agentic AI for Incident Response on Microsoft Azure &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Grant Griffiths&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;4:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH101 · GitHub&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Agentic DevOps: Evolving software with GitHub Copilot &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Glenn Wester&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;5:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH209 · Rescale&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Real-World AI Physics: GM &amp;amp; NVIDIA on Rescale &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Dinal Perera&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;5:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH107 · Microsoft&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Intro to LoRA Fine-Tuning on Azure &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Christin Pohl&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #fcfcfc; display: flex; overflow: hidden; min-height: 50px;"&gt;
                &lt;DIV style="background: #eee; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #666; font-size: 13px;"&gt;6:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1; display: flex; align-items: center;"&gt;
                &lt;DIV style="font-size: 15px; font-weight: bold; color: #666; text-transform: uppercase; letter-spacing: 1px;"&gt;Raffle&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;H3 style="color: #0078d4; margin-bottom: 15px; border-left: 4px solid #0078d4; padding-left: 10px;"&gt;Wednesday, March 18&lt;/H3&gt;
                &lt;DIV style="display: flex; flex-direction: column; gap: 12px; margin-bottom: 40px;"&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;1:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH219 · VAST Data&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Scaling AI Infrastructure on Azure with VAST Data &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Jason Vallery&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;1:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH110 · Microsoft&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Physical AI and Robotics: The Next Frontier &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— F. Miller, C. Souche, D. Narayanan&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;2:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH105 · Microsoft&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Sovereign AI options with Azure Local &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Kim Lam&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;2:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH108 · Microsoft&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Automating HPC Workflows with Copilot Agents &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Param Shah&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;3:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH102 · Microsoft&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Trustworthy Multi-Agent Workflows with Microsoft Foundry &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Brian Benz&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;4:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH106 · Microsoft&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Scaling Enterprise AI on ARO with NVIDIA H100 &amp;amp; H200 &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Lachie Evenson&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;4:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH211 · WEKA&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Hybrid AI Data Orchestration with WEKA NeuralMesh™ &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Desiree Campbell&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;5:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH202 · Hammerspace&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;NVIDIA AI Enterprise Software with NIM &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Mike Bloom&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;5:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH203 · Kinaxis&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Reimagining Global Supply Planning with Azure &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Dane Henshall&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;6:00 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH214 · AT&amp;amp;T&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Connected AI on Azure for Manufacturing &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Brad Pritchett&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #fcfcfc; display: flex; overflow: hidden; min-height: 50px;"&gt;
                &lt;DIV style="background: #eee; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #666; font-size: 13px;"&gt;6:30 PM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1; display: flex; align-items: center;"&gt;
                &lt;DIV style="font-size: 15px; font-weight: bold; color: #666; text-transform: uppercase; letter-spacing: 1px;"&gt;Raffle&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;H3 style="color: #0078d4; margin-bottom: 15px; border-left: 4px solid #0078d4; padding-left: 10px;"&gt;Thursday, March 19&lt;/H3&gt;
                &lt;DIV style="display: flex; flex-direction: column; gap: 12px; margin-bottom: 40px;"&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden; min-height: 70px;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #0078d4; font-size: 13px;"&gt;11:00 AM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1;"&gt;
                &lt;DIV style="font-size: 11px; color: #666; font-weight: 600; text-transform: uppercase; margin-bottom: 2px;"&gt;BTH210 · Wandelbots&lt;/DIV&gt;
                &lt;DIV style="font-size: 15px; font-weight: 600; color: #242424;"&gt;Physical AI: Powering Software-Defined Automation in Robotics &lt;SPAN style="font-weight: 400; color: #666; font-size: 13px;"&gt;— Marwin Kunz, Martin George&lt;/SPAN&gt;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="border: 1px solid #e1e8f0; border-radius: 12px; background: #fcfcfc; display: flex; overflow: hidden; min-height: 50px;"&gt;
                &lt;DIV style="background: #eee; width: 90px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0; font-weight: bold; color: #666; font-size: 13px;"&gt;11:30 AM&lt;/DIV&gt;
                &lt;DIV style="padding: 12px 20px; flex-grow: 1; display: flex; align-items: center;"&gt;
                &lt;DIV style="font-size: 15px; font-weight: bold; color: #666; text-transform: uppercase; letter-spacing: 1px;"&gt;Raffle&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;H2 style="margin-top: 48px; color: #0078d4;"&gt;Explore Our Demo Pods&lt;/H2&gt;
                &lt;P style="margin-bottom: 24px;"&gt;Visit the Microsoft booth to see our technology in action with live demonstrations across four dedicated pod areas.&lt;/P&gt;
                &lt;DIV style="display: flex; flex-wrap: wrap; gap: 20px; margin: 24px 0;"&gt;
                &lt;DIV style="flex: 1; min-width: 450px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 80px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0;"&gt;
                &lt;DIV style="font-weight: bold; color: #0078d4; font-size: 14px;"&gt;POD 1&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 18px; color: #0078d4;"&gt;Azure AI Infrastructure&lt;/H3&gt;
                &lt;P style="margin: 0; font-size: 14px; color: #444; line-height: 1.5;"&gt;End‑to‑end AI infrastructure for training and inference at scale, featuring the latest NVIDIA GPU integrations on Azure.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 1; min-width: 450px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 80px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0;"&gt;
                &lt;DIV style="font-weight: bold; color: #0078d4; font-size: 14px;"&gt;POD 2&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 18px; color: #0078d4;"&gt;Microsoft Foundry&lt;/H3&gt;
                &lt;P style="margin: 0; font-size: 14px; color: #444; line-height: 1.5;"&gt;Our comprehensive platform for building, deploying, and operating agentic AI systems with enterprise reliability.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 1; min-width: 450px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 80px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0;"&gt;
                &lt;DIV style="font-weight: bold; color: #0078d4; font-size: 14px;"&gt;POD 3&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 18px; color: #0078d4;"&gt;Building AI Together&lt;/H3&gt;
                &lt;P style="margin: 0; font-size: 14px; color: #444; line-height: 1.5;"&gt;Showcasing joint Microsoft and NVIDIA solutions across diverse industries, from manufacturing to retail.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="flex: 1; min-width: 450px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; display: flex; overflow: hidden;"&gt;
                &lt;DIV style="background: #f5f9fd; width: 80px; display: flex; align-items: center; justify-content: center; border-right: 1px solid #e1e8f0; flex-shrink: 0;"&gt;
                &lt;DIV style="font-weight: bold; color: #0078d4; font-size: 14px;"&gt;POD 4&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 18px; color: #0078d4;"&gt;Startups Powering AI&lt;/H3&gt;
                &lt;P style="margin: 0; font-size: 14px; color: #444; line-height: 1.5;"&gt;Discover how innovative startups are running next‑generation AI workloads on the Azure platform.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;H2 style="margin-top: 48px; color: #0078d4;"&gt;Ancillary Events &amp;amp; Networking&lt;/H2&gt;
                &lt;P style="margin-bottom: 32px; color: #444;"&gt;Join Microsoft leadership and our partner ecosystem at these curated networking experiences. Click the location to view on Bing Maps.&lt;/P&gt;
                &lt;DIV style="max-width: 900px;"&gt;
                &lt;DIV style="display: flex; gap: 20px; margin-bottom: 24px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; overflow: hidden;"&gt;
                &lt;DIV style="background: #0078d4; color: #ffffff; width: 120px; display: flex; flex-direction: column; align-items: center; justify-content: center; text-align: center; padding: 15px; flex-shrink: 0;"&gt;
                &lt;DIV style="font-size: 12px; font-weight: 600; text-transform: uppercase; opacity: 0.9;"&gt;Sun · Mar 15&lt;/DIV&gt;
                &lt;DIV style="font-size: 20px; font-weight: bold;"&gt;6:00&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; font-weight: 600;"&gt;PM&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px; flex-grow: 1;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 18px; color: #0078d4;"&gt;Microsoft for Startups Executive Leadership Dinner&lt;/H3&gt;
                &lt;DIV style="display: flex; align-items: center; gap: 8px; font-size: 14px; color: #444;"&gt;&lt;SPAN style="font-size: 16px;"&gt;📍&lt;/SPAN&gt; &lt;A style="color: #0078d4; text-decoration: none; font-weight: 600;" href="https://www.bing.com/maps?q=Morton%27s+The+Steakhouse+San+Jose" target="_blank" rel="noopener"&gt; Morton’s Steakhouse, San Jose &lt;/A&gt;&lt;/DIV&gt;
                &lt;DIV style="font-size: 13px; color: #666; margin-top: 6px;"&gt;Exclusive gathering for startup leaders and Microsoft executives.&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="display: flex; gap: 20px; margin-bottom: 24px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; overflow: hidden;"&gt;
                &lt;DIV style="background: #0078d4; color: #ffffff; width: 120px; display: flex; flex-direction: column; align-items: center; justify-content: center; text-align: center; padding: 15px; flex-shrink: 0;"&gt;
                &lt;DIV style="font-size: 12px; font-weight: 600; text-transform: uppercase; opacity: 0.9;"&gt;Mon · Mar 16&lt;/DIV&gt;
                &lt;DIV style="font-size: 20px; font-weight: bold;"&gt;1:30&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; font-weight: 600;"&gt;PM&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px; flex-grow: 1;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 18px; color: #0078d4;"&gt;Microsoft × NVIDIA Open Meet&lt;/H3&gt;
                &lt;DIV style="display: flex; align-items: center; gap: 8px; font-size: 14px; color: #444;"&gt;&lt;SPAN style="font-size: 16px;"&gt;📍&lt;/SPAN&gt; &lt;A style="color: #0078d4; text-decoration: none; font-weight: 600;" href="https://www.bing.com/maps?q=Signia+by+Hilton+San+Jose" target="_blank" rel="noopener"&gt; Signia by Hilton · International Suite &lt;/A&gt;&lt;/DIV&gt;
                &lt;DIV style="font-size: 13px; color: #666; margin-top: 6px;"&gt;Strategic alignment session for Microsoft and NVIDIA executives.&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="display: flex; gap: 20px; margin-bottom: 24px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; overflow: hidden;"&gt;
                &lt;DIV style="background: #0078d4; color: #ffffff; width: 120px; display: flex; flex-direction: column; align-items: center; justify-content: center; text-align: center; padding: 15px; flex-shrink: 0;"&gt;
                &lt;DIV style="font-size: 12px; font-weight: 600; text-transform: uppercase; opacity: 0.9;"&gt;Mon · Mar 16&lt;/DIV&gt;
                &lt;DIV style="font-size: 20px; font-weight: bold;"&gt;7:30&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; font-weight: 600;"&gt;PM&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px; flex-grow: 1;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 18px; color: #0078d4;"&gt;Microsoft + NVIDIA Executive Dinner&lt;/H3&gt;
                &lt;DIV style="display: flex; align-items: center; gap: 8px; font-size: 14px; color: #444;"&gt;&lt;SPAN style="font-size: 16px;"&gt;📍&lt;/SPAN&gt; &lt;A style="color: #0078d4; text-decoration: none; font-weight: 600;" href="https://www.bing.com/maps?q=Il+Fornaio+San+Jose" target="_blank" rel="noopener"&gt; Il Fornaio, San Jose &lt;/A&gt;&lt;/DIV&gt;
                &lt;DIV style="font-size: 13px; color: #666; margin-top: 6px;"&gt;Executive dinner for key customers and leadership teams.&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="display: flex; gap: 20px; margin-bottom: 24px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; overflow: hidden;"&gt;
                &lt;DIV style="background: #0078d4; color: #ffffff; width: 120px; display: flex; flex-direction: column; align-items: center; justify-content: center; text-align: center; padding: 15px; flex-shrink: 0;"&gt;
                &lt;DIV style="font-size: 12px; font-weight: 600; text-transform: uppercase; opacity: 0.9;"&gt;Tue · Mar 17&lt;/DIV&gt;
                &lt;DIV style="font-size: 20px; font-weight: bold;"&gt;7:30&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; font-weight: 600;"&gt;PM&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px; flex-grow: 1;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 18px; color: #0078d4;"&gt;Networking in AI &amp;amp; Tech&lt;/H3&gt;
                &lt;DIV style="display: flex; align-items: center; gap: 8px; font-size: 14px; color: #444;"&gt;&lt;SPAN style="font-size: 16px;"&gt;📍&lt;/SPAN&gt; &lt;A style="color: #0078d4; text-decoration: none; font-weight: 600;" href="https://www.bing.com/maps?q=San+Pedro+Square+Market+San+Jose" target="_blank" rel="noopener"&gt; San Pedro Square Market &lt;/A&gt;&lt;/DIV&gt;
                &lt;DIV style="font-size: 13px; color: #666; margin-top: 6px;"&gt;Community networking mixer for Microsoft teams, partners, and customers.&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="display: flex; gap: 20px; margin-bottom: 24px; border: 1px solid #e1e8f0; border-radius: 12px; background: #ffffff; overflow: hidden;"&gt;
                &lt;DIV style="background: #0078d4; color: #ffffff; width: 120px; display: flex; flex-direction: column; align-items: center; justify-content: center; text-align: center; padding: 15px; flex-shrink: 0;"&gt;
                &lt;DIV style="font-size: 12px; font-weight: 600; text-transform: uppercase; opacity: 0.9;"&gt;Wed · Mar 18&lt;/DIV&gt;
                &lt;DIV style="font-size: 18px; font-weight: bold;"&gt;10:00 AM&lt;/DIV&gt;
                &lt;DIV style="font-size: 12px; font-weight: 600;"&gt;to 1:00 PM&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV style="padding: 20px; flex-grow: 1;"&gt;
                &lt;H3 style="margin: 0 0 8px 0; font-size: 18px; color: #0078d4;"&gt;AI Innovator’s Circle Brunch: Powering Intelligent Systems Across the Ecosystem&lt;/H3&gt;
                &lt;DIV style="display: flex; align-items: center; gap: 8px; font-size: 14px; color: #444;"&gt;&lt;SPAN style="font-size: 16px;"&gt;📍&lt;/SPAN&gt; &lt;A style="color: #0078d4; text-decoration: none; font-weight: 600;" href="https://www.bing.com/maps?q=Il+Fornaio+San+Jose" target="_blank" rel="noopener"&gt; Il Fornaio, San Jose &lt;/A&gt;&lt;/DIV&gt;
                &lt;DIV style="font-size: 13px; color: #666; margin-top: 6px;"&gt;Hosted by Microsoft &amp;amp; NVIDIA at GTC. Join us for an exclusive brunch and discussion on the intelligent ecosystem.&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;/DIV&gt;</description>
            <pubDate>Fri, 27 Feb 2026 21:05:36 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/azure-high-performance-computing/microsoft-at-nvidia-gtc-2026/ba-p/4497670</guid>
            <dc:creator>Fernando_Aznar</dc:creator>
            <dc:date>2026-02-27T21:05:36Z</dc:date>
        </item>
        <item>
            <title>Copilot can reschedule conflicting events in Outlook</title>
            <link>https://techcommunity.microsoft.com/t5/microsoft-365-insider-blog/copilot-can-reschedule-conflicting-events-in-outlook/ba-p/4471514</link>
            <description>&lt;P&gt;Hi, Insiders! I’m Julia Foran, a Principal Product Manager on the Microsoft Time and Places team. I’m excited to share with you a new Microsoft 365 Copilot capability in new Outlook for Windows and Outlook for the web that can help you manage conflicting meetings and appointments in your busy calendar.&lt;/P&gt;
                &lt;H3&gt;Copilot can reschedule conflicting events in Outlook&lt;/H3&gt;
                &lt;P&gt;You can now have Copilot in Outlook reschedule personal appointments and one-on-one meetings if a conflicting event arises that takes priority.&lt;/P&gt;
                &lt;P&gt;Imagine you have a recurring check-in meeting, but it doesn’t have to be at the exact same time each week. Just ask Copilot to manage the meeting: It will keep an eye on your calendar and reschedule the event if you schedule or accept another meeting at the same time.&lt;/P&gt;
                &lt;P&gt;This feature offers numerous benefits:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Resolve conflicts fast&lt;/STRONG&gt;:&lt;STRONG&gt; &lt;/STRONG&gt;You can easily fix overlapping meetings and avoid double-booking.&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Save time&lt;/STRONG&gt;: Managing your schedule no longer requires manual intervention.&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Improve productivity and collaboration&lt;/STRONG&gt;: Copilot provides seamless scheduling and a well-organized calendar.&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Remain in control&lt;/STRONG&gt;: You decide the dates and times that are acceptable if Copilot needs to reschedule for you, and you can check what Copilot has rescheduled in the Outlook notifications pane and change your settings at any time.&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;How it works&lt;/H3&gt;
                &lt;OL&gt;
                &lt;LI&gt;Open new Outlook for Windows or Outlook for the web.&lt;/LI&gt;
                &lt;LI&gt;Select &lt;STRONG&gt;New &lt;/STRONG&gt;&amp;gt; &lt;STRONG&gt;Event&lt;/STRONG&gt; to create an event or a series, or open an existing event or series.&lt;/LI&gt;
                &lt;LI&gt;Toggle on&lt;STRONG&gt; If conflicts arise, let Copilot reschedule this event&lt;/STRONG&gt;.&lt;img /&gt;&lt;/LI&gt;
                &lt;LI&gt;Under &lt;STRONG&gt;Acceptable times&lt;/STRONG&gt;, select the day(s) and timeframe(s) you’re available to find the best alternatives if Copilot needs to reschedule the event or series for you.&lt;img /&gt;&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;P&gt;&lt;STRONG&gt;NOTE&lt;/STRONG&gt;: This step is optional, but you’ll get better results if you choose specific days and times.&lt;/P&gt;
                &lt;H3&gt;Tips and tricks&lt;/H3&gt;
                &lt;UL&gt;
                &lt;LI&gt;Copilot will automatically reschedule your event based on your acceptable days and times only if:
                &lt;UL&gt;
                &lt;LI&gt;You accept a new event that occurs at the same time.&lt;/LI&gt;
                &lt;LI&gt;Schedule or reschedule a new event to occur at the same time.&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;/LI&gt;
                &lt;LI&gt;Only events with status of&amp;nbsp;&lt;STRONG style="color: rgb(30, 30, 30);"&gt;Busy&lt;/STRONG&gt;&lt;SPAN style="color: rgb(30, 30, 30);"&gt; or &lt;/SPAN&gt;&lt;STRONG style="color: rgb(30, 30, 30);"&gt;Out of office&lt;/STRONG&gt;&lt;SPAN style="color: rgb(30, 30, 30);"&gt; will be considered when evaluating conflicts. This means that if there’s a conflict on your calendar with an event that has automatic rescheduling with Copilot turned on, but your status for the conflicting meeting is set to &lt;/SPAN&gt;&lt;STRONG style="color: rgb(30, 30, 30);"&gt;Tentative&lt;/STRONG&gt;&lt;SPAN style="color: rgb(30, 30, 30);"&gt;, Copilot won’t reschedule it.&lt;/SPAN&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;Known limitations&lt;/H3&gt;
                &lt;UL&gt;
                &lt;LI&gt;This feature does not yet support delegates creating or updating meetings on shared calendars.&lt;/LI&gt;
                &lt;LI&gt;If you create a series and automatic rescheduling with Copilot is turned off, you can’t turn it on for a single instance of the series later. If you create a new series and turn on automatic rescheduling with Copilot, the option can be turned off for a single instance later, but you can’t change your acceptable day(s) and time(s) for a single instance.&lt;/LI&gt;
                &lt;LI&gt;For more information on this feature, visit our &lt;A class="lia-external-url" href="https://support.microsoft.com/en-us/topic/automatically-reschedule-events-with-copilot-in-microsoft-outlook-and-microsoft-teams-b07da559-387e-4b95-92eb-8c8f0be065a7" target="_blank"&gt;Support page&lt;/A&gt;.&amp;nbsp;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;Availability&lt;/H3&gt;
                &lt;P&gt;This feature is rolling out to Teams, Outlook for the web, and new Outlook for Windows (&lt;A href="https://techcommunity.microsoft.com/blog/microsoft365insiderblog/experience-the-future-switch-to-new-outlook-for-windows-today/4453061" target="_blank" rel="noopener"&gt;learn more&lt;/A&gt;) users with a Microsoft 365 Copilot Enterprise license.&lt;/P&gt;
                &lt;H3&gt;Feedback&lt;/H3&gt;
                &lt;P&gt;Tell us what you think of this feature by going to &lt;STRONG&gt;Help&lt;/STRONG&gt; &amp;gt; &lt;STRONG&gt;Feedback&lt;/STRONG&gt; in Outlook. You can also send feedback on a specific meeting by selecting the thumbs up or down button on the update that appears in your Outlook notifications pane (&lt;A href="https://support.microsoft.com/en-us/office/contact-support-and-provide-feedback-in-new-outlook-for-windows-4a4bcc80-c71e-4e44-97c1-d0e62452ef4a" target="_blank" rel="noopener"&gt;learn more&lt;/A&gt;).&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Learn about the&amp;nbsp;&lt;A href="https://aka.ms/MSFT365InsiderProgram" target="_blank" rel="noopener"&gt;Microsoft 365 Insider program&lt;/A&gt;&amp;nbsp;and sign up for the&amp;nbsp;&lt;A href="https://aka.ms/msft365insidernews" target="_blank" rel="noopener"&gt;Microsoft 365 Insider newsletter&lt;/A&gt; to get the latest information about Insider features in your inbox once a month!&lt;/P&gt;</description>
            <pubDate>Fri, 27 Feb 2026 16:33:04 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/microsoft-365-insider-blog/copilot-can-reschedule-conflicting-events-in-outlook/ba-p/4471514</guid>
            <dc:creator>Julia Foran</dc:creator>
            <dc:date>2026-02-27T16:33:04Z</dc:date>
        </item>
        <item>
            <title>What’s New in Microsoft 365 Copilot | February 2026</title>
            <link>https://techcommunity.microsoft.com/t5/microsoft-365-copilot-blog/what-s-new-in-microsoft-365-copilot-february-2026/ba-p/4496489</link>
            <description>&lt;img /&gt;
                &lt;P&gt;Welcome to the February 2026 edition of What's New in Microsoft 365 Copilot! Every month, we highlight new features and enhancements to keep Microsoft 365 admins up to date with Copilot features that help your users be more productive and efficient in the apps they use every day.&lt;/P&gt;
                &lt;P&gt;Also new this month—the &lt;A href="https://aka.ms/a365blog" target="_blank" rel="noopener"&gt;&lt;STRONG&gt;Microsoft Agent 365 blog and discussion space&lt;/STRONG&gt;&lt;/A&gt; on Microsoft Tech Community. We recommend following it for the latest product news and insights on observability, security, and governance of agents in your organization.&lt;/P&gt;
                &lt;P&gt;Let’s take a closer look at what’s new this month:&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;User capabilities:&lt;/STRONG&gt;&amp;nbsp;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;A href="#community--1-Text" target="_self" rel="noopener" aria-label="Jump to Text selection and expanded grounding for Copilot Chat"&gt;Text selection and expanded grounding for Copilot Chat&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="#community--1-integrations" target="_self" rel="noopener" aria-label="Jump to Agents, integrations, and access points for the Copilot app"&gt;Agents, integrations, and access points for the Copilot app&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="#community--1-communities" target="_self" rel="noopener" aria-label="Jump to Agents in communities and updated recaps for Copilot in Teams"&gt;Agents in communities and updated recaps for Copilot in Teams&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="#community--1-Outlook" target="_self" rel="noopener" aria-label="Jump to Meeting scheduling and preparation for Copilot in Outlook"&gt;Meeting scheduling and preparation for Copilot in Outlook&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="#community--1-Edits" target="_self" rel="noopener" aria-label="Jump to Edits documents by default with Copilot in Word"&gt;Edits documents by default with Copilot in Word&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="#community--1-agentic" target="_self" rel="noopener" aria-label="Jump to Copilot is agentic in PowerPoint"&gt;Copilot is agentic in PowerPoint&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="#community--1-OneDrive" target="_self" rel="noopener" aria-label="Jump to Agents in OneDrive"&gt;Agents in OneDrive&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="#community--1-Expanded" target="_self" rel="noopener" aria-label="Jump to Expanded grounding, access, and coordination for agents"&gt;Expanded grounding, access, and coordination for agents&lt;/A&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;STRONG&gt;IT admin capabilities:&lt;/STRONG&gt;&amp;nbsp;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;A href="#community--1-Power" target="_self" rel="noopener" aria-label="Jump to Power user report and intelligent summaries for Copilot Dashboard"&gt;Power user report and intelligent summaries for Copilot Dashboard&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="#community--1-readiness" target="_self" rel="noopener" aria-label="Jump to Copilot access and readiness with Microsoft 365 admin center"&gt;Copilot access and readiness with Microsoft 365 admin center&lt;/A&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="#community--1-inventory" target="_self" rel="noopener" aria-label="Jump to Risk-based inventory of AI agents for Microsoft Defender"&gt;Risk-based inventory of AI agents for Microsoft Defender&lt;/A&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H2&gt;User capabilities&lt;/H2&gt;
                &lt;H4 id="Text"&gt;Text selection and expanded grounding for Copilot Chat&lt;/H4&gt;
                &lt;P&gt;Users can now &lt;STRONG&gt;select specific text from Copilot responses&lt;/STRONG&gt; and ask about it for focused follow-up questions. Simply highlight the text and an “Ask Copilot” button will appear. This precision targeting eliminates overly broad answers by letting users drill into exactly the content they need. Your users get faster, more controlled assistance for explanations, summaries, translations, and next steps. This feature is &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=522616" target="_blank" rel="noopener"&gt;rolling out in March&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Users can now &lt;STRONG&gt;ground their Copilot prompts on SharePoint lists or sites&lt;/STRONG&gt; when using Copilot Chat in work mode. To include a SharePoint list or site in a prompt, simply type forward slash “/” and either start typing the name or find the SharePoint list or site under the “Sites” tab. This integration brings your organization's structured data directly into the AI conversation context. Your users can get more accurate, relevant responses by grounding prompts on specific SharePoint List data. This feature is &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=422308" target="_blank" rel="noopener"&gt;rolling out in March&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;When users without a Microsoft 365 Copilot license use Copilot Chat in Outlook alongside an open email,&amp;nbsp;&lt;STRONG&gt;Copilot will ground the conversation in the open email&lt;/STRONG&gt;, which is visually indicated in the prompt box by displaying the subject line of the email. Additionally, if a user highlights just a part of the email, &lt;STRONG&gt;Copilot can ground the conversation only on that highlighted text&lt;/STRONG&gt;. These features help users by visually indicating when Copilot is grounded on an email, or part of it. These features rolled out in February.&lt;/P&gt;
                &lt;img /&gt;
                &lt;H4 id="integrations"&gt;Agents, integrations, and access points for the Copilot app&lt;/H4&gt;
                &lt;P&gt;&lt;STRONG&gt;Project Manager Agent&lt;/STRONG&gt; helps users plan, organize, and manage work through AI-assisted project tracking. Starting with core task management, this agent simplifies project coordination with advanced capabilities coming over time. Deploy this feature to give your organization AI-powered task management assistance. This feature is &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=516576" target="_blank" rel="noopener"&gt;rolling out to Public Preview in March and is rolling out worldwide in April&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Copilot Chat integrated with Copilot Search&lt;/STRONG&gt; lets users explore their search results and interact with Copilot in the chat pane at the same time, so they can ask more detailed questions about those results. By keeping Copilot Chat available during the search process, users can avoid switching between tools, so they can easily find information and get AI support simultaneously, boosting productivity. This feature is &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=537281" target="_blank" rel="noopener"&gt;rolling out in March&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Copilot mobile widgets and action button&lt;/STRONG&gt; enable users to chat with Copilot while they’re on the go. The widgets bring Microsoft 365 Copilot features right to a mobile device’s Home and Lock screens. With just one tap of the Copilot widget or Copilot action button, users can start a chat with Copilot, activate a voice conversation, or open the camera to attach a photo to Copilot Chat. This makes it easier to catch up, ask questions, and brainstorm with Copilot on a mobile device. Mobile widgets on iOS and Android, and action button on iOS rolled out in February.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Users can now&amp;nbsp;&lt;STRONG&gt;create brand kits&lt;/STRONG&gt; &lt;STRONG&gt;within the Create experience&lt;/STRONG&gt; by uploading their organization's brand guidelines document. This streamlines brand asset management by extracting colors, fonts, and style elements automatically. Now teams can ensure brand consistency across Copilot-generated content in the Create experience with minimal manual setup. This feature rolled out in February.&lt;/P&gt;
                &lt;DIV style="position: relative; width: 100%; padding-bottom: 56.25%; height: 0; overflow: hidden;"&gt;&lt;IFRAME src="https://medius.microsoft.com/Embed/video-nc/765a4731-f771-4325-809e-0087e85d0583?r=951859140623" title="Brand Guidelines Extraction" allowfullscreen="allowfullscreen" frameborder="0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" sandbox="allow-scripts allow-same-origin allow-forms"&gt;&lt;/IFRAME&gt;&lt;/DIV&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Email attachment search&lt;/STRONG&gt; enables users to find email attachments through Copilot, surfacing results in full search and when Outlook or SharePoint filters are selected. This improves file discovery by making email attachments searchable alongside other content, and users can locate important documents faster regardless of where they're stored. This feature rolled out in February.&lt;/P&gt;
                &lt;H4 id="communities"&gt;Agents in communities and updated recaps for Copilot in Teams&lt;/H4&gt;
                &lt;P&gt;Communities in Microsoft Teams bring community conversations and leadership engagement to a user’s existing Teams collaboration, so they can discover and participate in communities directly within Teams without switching apps. Now &lt;STRONG&gt;a&lt;/STRONG&gt;&lt;STRONG&gt;gents in communities&lt;/STRONG&gt; are also available in Teams. The agent helps turn community conversations into shared organizational knowledge by drafting suggested responses to unanswered questions using existing discussions and specified SharePoint sites. This feature &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=499898" target="_blank" rel="noopener"&gt;rolled out to Public Preview in February and is rolling out worldwide in April&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;AI summaries in meeting recaps now &lt;STRONG&gt;include the visuals that shaped the conversation&lt;/STRONG&gt;. When a screen is shared during a recorded meeting, key on-screen moments are captured and placed directly alongside the relevant sections of the meeting summary, so users can see the screen as it appeared in the discussion. The notes themselves remain focused on the conversation, but now they’re paired with the visual context that brought those ideas to life. The result is a more intuitive, scannable recap that helps teams quickly reconnect decisions to what was presented, without scrubbing through the recording. This feature rolled out in February.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;Staying aligned after a meeting shouldn’t mean settling for a one-size-fits-all recap. With new &lt;STRONG&gt;customizable recap templates&lt;/STRONG&gt;, users can shape their AI-generated notes to match exactly how their team works. They can choose from two ready-made templates, a Speaker Summary that organizes insights by participant, or an Executive Summary that highlights key takeaways. Users can also design custom templates using a simple free-text prompt to describe the structure they want—even paste in a format they’ve used before—and their AI notes will instantly adapt. Users can also save custom templates for future reuse, giving every meeting the same level of clarity, consistency, and efficiency. Available across all languages that support AI summaries, this feature rolled out to public preview in December and rolled out worldwide in February.&lt;/P&gt;
                &lt;DIV style="position: relative; width: 100%; padding-bottom: 56.25%; height: 0; overflow: hidden;"&gt;&lt;IFRAME src="https://medius.microsoft.com/Embed/video-nc/2273293d-fc6d-4a51-a81b-933aab1a9408?r=749849637283" title="Product Roadmap Discussion" allowfullscreen="allowfullscreen" frameborder="0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" sandbox="allow-scripts allow-same-origin allow-forms"&gt;&lt;/IFRAME&gt;&lt;/DIV&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;The &lt;STRONG&gt;Copilot experience in Teams meeting is updating to Copilot Chat&lt;/STRONG&gt;, matching the unified experience across Teams chats and channels, the Microsoft 365 Copilot app, and other Microsoft 365 apps. Now Copilot in Teams meetings can analyze chat history, meeting transcripts, and calendar content to generate smart recaps, rewrite messages, and surface relevant insights. Whether reviewing a thread or following up after a call, Copilot in Teams meetings will now deliver context-aware summaries and suggestions based on your activity and goals. This feature &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=501107" target="_blank" rel="noopener"&gt;rolled out in February&lt;/A&gt;.&lt;/P&gt;
                &lt;H4 id="Outlook"&gt;Meeting scheduling and preparation for Copilot in Outlook&lt;/H4&gt;
                &lt;P&gt;When scheduling meetings with multiple attendees via Copilot Chat, &lt;STRONG&gt;Copilot can now recommend time slots that maximize availability across attendees&lt;/STRONG&gt;. When no suitable times are found, Copilot widens the search range to suggest alternatives and clearly explains why specific options are recommended. Copilot can also visually display each option in the context of a broader schedule, and respects personalized time settings like working hours, time zones, and meeting preferences. This feature &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=542185" target="_blank" rel="noopener"&gt;rolled out in February for new Outlook and will roll out in March for classic Outlook&lt;/A&gt;.&amp;nbsp;&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;Similarly, it's now easier for users to &lt;STRONG&gt;schedule meetings with Copilot directly from an email thread&lt;/STRONG&gt;. From an open email or email thread, users can simply click "Schedule with Copilot," and Copilot takes it from there by finding available times to meet, booking meeting rooms, drafting agendas and sending invites, all in one guided chat flow. This feature began rolling out in February for new Outlook and will roll out in March for classic Outlook.&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;In classic Outlook, Copilot now brings &lt;STRONG&gt;real-time insights, context summaries, and relevant documents to meeting prep&lt;/STRONG&gt;. Users can chat with Copilot for deeper preparation on upcoming meetings, enabling them to arrive at meetings fully prepared. This feature &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=542186" target="_blank" rel="noopener"&gt;rolled out for Classic Outlook in Public Preview in January and is rolling out worldwide in March&lt;/A&gt;.&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Copilot now provides &lt;STRONG&gt;meeting time analytics&lt;/STRONG&gt; that let users query and visualize how much time they spend in meetings, including breakdowns by category and month over month comparisons. Users can ask Copilot questions like,&amp;nbsp;&lt;EM&gt;“How much time did I spend in meetings last month?”, “How much time did I spend in meetings last month, split by category—and how does that compare to previous months?”, &amp;nbsp;or “Create a month‑by‑month bar chart comparing my meeting time.” &lt;/EM&gt;This enables users to make more intentional scheduling decisions without additional reporting tools. This feature rolled out in February.&lt;/P&gt;
                &lt;H4 id="Edits"&gt;Edits documents by default with Copilot in Word&lt;/H4&gt;
                &lt;P&gt;The &lt;STRONG&gt;default Copilot chat experience in Word now allows Copilot to directly edit documents&lt;/STRONG&gt;. All changes made by Copilot are fully reviewable and reversible, and users can turn this experience off if needed. This helps users work faster without choosing modes or tools, so Copilot is simply ready when they are. This feature started rolling out in February.&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Users can now prompt Copilot on a blank document&lt;STRONG&gt; &lt;/STRONG&gt;to get started, and &lt;STRONG&gt;"Edit with Copilot” will automatically turn on in Word&lt;/STRONG&gt;. This reduces the work of getting started and keeps users in a continuous AI-assisted flow where they can keep iterating. This feature started rolling out in February.&lt;/P&gt;
                &lt;P&gt;&lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=543241" target="_blank" rel="noopener"&gt;https://www.microsoft.com/en-us/microsoft-365/roadmap?id=543241&lt;/A&gt;&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H4 id="agentic"&gt;Copilot is agentic in PowerPoint&lt;/H4&gt;
                &lt;P&gt;&lt;STRONG&gt;Copilot is now agentic in PowerPoint on the Web, &lt;/STRONG&gt;letting users create, edit, and refine presentations through natural conversation directly in a presentation. Users can start a new presentation or build on an existing one, using ‘Edit with Copilot’ to generate slides, update content, improve layouts, and polish design—while preserving formatting, structure, and branding. Copilot uses files, meetings, emails, and more to help shape content and iterate quickly, and it connects to brand kits so users can apply branded templates, insert brand‑approved images, and check for brand compliance. This feature started &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=548520" target="_blank" rel="noopener"&gt;rolling out to the Web in February&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H4 id="OneDrive"&gt;Agents in OneDrive&lt;/H4&gt;
                &lt;P&gt;&lt;A href="https://techcommunity.microsoft.com/blog/onedriveblog/agents-in-onedrive-now-generally-available-your-ai-assistant-built-with-your-own/4490929" target="_blank" rel="noopener"&gt;&lt;STRONG&gt;Agents in OneDrive&lt;/STRONG&gt;&lt;/A&gt;&lt;STRONG&gt; &lt;/STRONG&gt;help users stay grounded in the full context of work. Instead of asking the same questions for each file, users can create an agent that understands an entire set of related documents, plans, specs, meeting notes, research, or decks. The agent responds with answers based on that shared content, functioning as an AI teammate built from chosen files and folders. This feature rolled out in February.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H4 id="Expanded"&gt;Expanded grounding, access, and coordination for agents&lt;/H4&gt;
                &lt;P&gt;&lt;STRONG&gt;Agent Recommendations&lt;/STRONG&gt; proactively suggests helpful agents during Copilot conversations based on user context and needs. This feature connects users with the right specialized agent for their current task without manual searching. This helps your organization improve agent adoption and effectiveness by automatically surfacing relevant agents when users need them most. This feature rolled out in February.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Adaptive Card content can be refreshed &lt;/STRONG&gt;within custom engine agent experiences. This feature enhances the interactivity and real-time capabilities of custom-built agents. This enables an organization's custom agents to deliver more dynamic, up-to-date content to users. This feature is rolling out in March.&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;AI agents can coordinate with each other&lt;/STRONG&gt; on complex tasks by calling other agents as tools. This multi-agent architecture allows agents to leverage specialized capabilities from other agents, so organizations can build more sophisticated AI workflows through agent-to-agent collaboration. This feature is rolling out in March.&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Access to &lt;STRONG&gt;agents built with Copilot Studio and Foundry through Outlook&lt;/STRONG&gt; gives users access to their organization's custom-built agents directly within the Outlook experience. This integration extends agent capabilities to email workflows without requiring users to switch applications. Admins can deploy custom agents where users spend significant time managing communications. This feature is rolling out in March.&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Newly created &lt;STRONG&gt;declarative agents can now ground answers in scanned PDFs&lt;/STRONG&gt; and image-based documents from SharePoint. This unlocks a major class of enterprise content that was previously difficult for agents to process. This enables organizations to leverage AI assistance with document archives and legacy scanned materials. This feature rolled out in February.&lt;/P&gt;
                &lt;H2&gt;IT admin capabilities&lt;/H2&gt;
                &lt;H4 id="Power"&gt;Power user report and intelligent summaries for Copilot Dashboard&lt;/H4&gt;
                &lt;P&gt;Admins can now target their enablement efforts by identifying Copilot power users in the &lt;STRONG&gt;Power User Report in the Copilot Adoption PBI&lt;/STRONG&gt;. The report classifies users as power, habitual, novice, and non‑Copilot users based on usage frequency and consistency. This feature is rolling out in March.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Use &lt;STRONG&gt;intelligent summaries&lt;/STRONG&gt; to quickly surface what’s working and where targeted attention can accelerate Copilot adoption. Intelligent summaries highlight key adoption trends to focus on areas of success. Suggested prompts enable deeper exploration of underlying trends and drivers. This feature is rolling out in March.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H4 id="readiness"&gt;Copilot access and readiness with Microsoft 365 admin center&lt;/H4&gt;
                &lt;P&gt;When requesting a Microsoft 365 Copilot license, users can now &lt;STRONG&gt;include a business justification explaining why they need Copilot&lt;/STRONG&gt;. This information is surfaced to IT admins during review, helping them make faster, more informed approval decisions while supporting governance and audit requirements. By providing clear context upfront, organizations can streamline license approvals while maintaining control and visibility. This feature is &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=547731" target="_blank" rel="noopener"&gt;rolling out in March&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;The new &lt;STRONG&gt;Copilot readiness page in the Microsoft 365 admin center&lt;/STRONG&gt; brings structure and clarity to the configuration and rollout of Microsoft 365 Copilot. The readiness page organizes recommended settings into clear categories of deployment essentials, data security, and user experience. This makes it easier to understand scope, prioritize actions, and track progress. With completion status, user coverage insights, and guided recommendations surfaced in one place, IT teams can plan, sequence, and deploy Microsoft 365 Copilot more confidently and consistently. This feature &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=526793" target="_blank" rel="noopener"&gt;rolled out to Public Preview in February and is rolling out worldwide in March&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Federated Copilot connectors are now available in Public Preview&lt;/STRONG&gt; by default across all tenants, allowing users to authenticate and securely access live data from supported external services such as Canva, HubSpot, Notion, Linear, Intercom, Google Contacts, and Google Calendar. Admins can govern availability from the Microsoft 365 admin center—reviewing, enabling, and disabling these connectors—while users connect with their own credentials. Federated connector data is retrieved in real time (not indexed) and is currently supported only in Researcher. This feature &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=501584" target="_blank" rel="noopener"&gt;rolled out in February&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;The &lt;STRONG&gt;Connector Usage Report &lt;/STRONG&gt;in Microsoft 365 admin center provides information on how connectors are augmenting Microsoft 365 Copilot experiences, with metrics including number of active connectors, and agents that reference connectors. With insights into daily trends, connector response counts, and individual-level engagement, organizations can optimize training, improve adoption strategies, and identify high-impact integrations. This feature is &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=519571" target="_blank" rel="noopener"&gt;rolling out in March&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Admins can now enable &lt;STRONG&gt;AI-powered skill updates for user profiles&lt;/STRONG&gt; directly from the Microsoft 365 admin center. This feature helps organizations maintain accurate skill data across their user base using Microsoft Graph activity. This feature &lt;A href="https://www.microsoft.com/en-us/microsoft-365/roadmap?id=548643" target="_blank" rel="noopener"&gt;rolled out in February&lt;/A&gt;.&lt;/P&gt;
                &lt;img /&gt;
                &lt;H4&gt;Risk-based inventory of AI agents for Microsoft Defender/h4&amp;gt;&lt;/H4&gt;
                &lt;P&gt;Microsoft Defender AI Security Posture Management now provides SOC teams with a &lt;STRONG&gt;risk-based inventory of AI agents across Microsoft Foundry and Copilot Studio&lt;/STRONG&gt;. Analysts can view an agent’s overall security posture, easily implement security recommendations, and identify vulnerabilities such as misconfigurations and excessive permissions. Agent activity is captured for investigation with hunting available through Defender's unified experience. This gives a security team the visibility needed to manage AI agents with the same rigor as human identities. This feature rolled out to Public Preview in November and rolled out worldwide in February.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;EM&gt;Did you know? The &lt;/EM&gt;&lt;A href="https://www.microsoft.com/microsoft-365/roadmap" target="_blank" rel="noopener"&gt;&lt;EM&gt;Microsoft 365 Roadmap&lt;/EM&gt;&lt;/A&gt;&lt;EM&gt; &lt;/EM&gt;&lt;EM&gt;is where you can get the latest updates on productivity apps and intelligent cloud services. &lt;/EM&gt;&lt;A href="https://learn.microsoft.com/copilot/microsoft-365/release-notes?tabs=all" target="_blank" rel="noopener"&gt;&lt;EM&gt;Microsoft 365 Copilot release notes&lt;/EM&gt;&lt;/A&gt;&lt;EM&gt; is where you can see the Microsoft 365 Copilot features that are generally available (Current Channel for Microsoft 365 apps) and specific to each platform. Check back regularly to see what features are in development, coming soon and generally available. Please note that the dates mentioned in this article are tentative and subject to change.&lt;/EM&gt;&lt;/P&gt;
                &lt;H4 id="inventory"&gt;&lt;/H4&gt;</description>
            <pubDate>Fri, 27 Feb 2026 16:30:00 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/microsoft-365-copilot-blog/what-s-new-in-microsoft-365-copilot-february-2026/ba-p/4496489</guid>
            <dc:creator>Seth_Patton</dc:creator>
            <dc:date>2026-02-27T16:30:00Z</dc:date>
        </item>
        <item>
            <title>Top 5 Microsoft Sentinel Queries for Threat Hunting</title>
            <link>https://techcommunity.microsoft.com/t5/microsoft-sentinel-blog/top-5-microsoft-sentinel-queries-for-threat-hunting/ba-p/4497667</link>
            <description>&lt;P&gt;Threat hunting in Microsoft Sentinel goes beyond relying on scheduled analytics rules. It’s about proactively asking better questions of your data to uncover stealthy or emerging attacker behavior before it turns into an incident. Effective hunting helps security teams spot activity that may never trigger an alert but still represents meaningful risk. Over time, these proactive hunts strengthen overall detection coverage and improve SOC maturity.&lt;/P&gt;
                &lt;P&gt;In this post, I’ll walk through five high‑value Sentinel hunting queries that security teams can use to uncover suspicious activity across identity, endpoints, and cloud resources. Each example focuses on why the hunt matters and what attacker behavior it can reveal. To make these hunts actionable and measurable, each query is explicitly mapped to MITRE ATT&amp;amp;CK tactics and techniques. This alignment helps teams communicate coverage, prioritize investigations, and evolve successful hunts into repeatable detections.&lt;/P&gt;
                &lt;H3&gt;&lt;STRONG&gt;1. Rare Sign‑In Locations for Privileged Accounts&lt;/STRONG&gt;&lt;/H3&gt;
                &lt;P&gt;&lt;STRONG&gt;Why it matters&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;Privileged identities are prime targets. A successful sign‑in from an unusual geography may indicate compromised credentials or token theft.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;What to hunt&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;Look for successful sign‑ins by privileged users from locations they rarely use.&lt;/P&gt;
                &lt;LI-CODE lang="kusto"&gt;// MITRE ATT&amp;amp;CK: T1078 (Valid Accounts), T1078.004 (Cloud Accounts) | Tactic: Initial Access
                SigninLogs
                | where ResultType == 0
                | where UserPrincipalName has_any ("admin", "svc")
                | summarize count() by UserPrincipalName, Location
                | join kind=leftanti (
                SigninLogs
                | where TimeGenerated &amp;lt; ago(30d)
                | summarize count() by UserPrincipalName, Location
                ) on UserPrincipalName, Location&lt;/LI-CODE&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;What to investigate next&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Conditional Access policies applied&lt;/LI&gt;
                &lt;LI&gt;MFA enforcement status&lt;/LI&gt;
                &lt;LI&gt;Correlation with device compliance or impossible travel alerts&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;&lt;STRONG&gt;2. Multiple Failed Logons Followed by Success&lt;/STRONG&gt;&lt;/H3&gt;
                &lt;P&gt;&lt;STRONG&gt;Why it matters&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;This pattern often indicates password spraying, brute force activity, or attackers testing credential validity before gaining access.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;What to hunt&lt;/STRONG&gt;&lt;/P&gt;
                &lt;LI-CODE lang="kusto"&gt;// MITRE ATT&amp;amp;CK: T1110 (Brute Force), T1110.003 (Password Spraying), T1110.001 (Password Guessing) | Tactic: Credential Access
                // Related: T1078 (Valid Accounts) once authentication succeeds
                SigninLogs
                | summarize
                Failed=countif(ResultType != 0),
                Success=countif(ResultType == 0)
                by UserPrincipalName, bin(TimeGenerated, 1h)
                | where Failed &amp;gt; 5 and Success &amp;gt; 0&lt;/LI-CODE&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;What to investigate next&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;IP reputation and ASN&lt;/LI&gt;
                &lt;LI&gt;Whether failures span multiple users (spray behavior)&lt;/LI&gt;
                &lt;LI&gt;Subsequent mailbox, SharePoint, or Azure activity&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;&lt;STRONG&gt;3. Unusual Process Execution on Endpoints&lt;/STRONG&gt;&lt;/H3&gt;
                &lt;P&gt;&lt;STRONG&gt;Why it matters&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;Attackers often use “living off the land” binaries (LOLBins) such as powershell.exe, wmic.exe, or rundll32.exe to evade detection.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;What to hunt&lt;/STRONG&gt;&lt;/P&gt;
                &lt;LI-CODE lang="kusto"&gt;// MITRE ATT&amp;amp;CK: T1059 (Command and Scripting Interpreter),
                // T1059.001 (PowerShell), T1059.003 (Windows Command Shell) | Tactic: Execution
                // Related: T1218 (Signed Binary Proxy Execution) when rundll32 and other signed binaries are abused
                DeviceProcessEvents
                | where FileName in~ ("powershell.exe", "wmic.exe", "rundll32.exe")
                | where InitiatingProcessFileName !in~ ("explorer.exe", "services.exe")
                | project TimeGenerated, DeviceName, FileName, ProcessCommandLine, InitiatingProcessFileName, InitiatingProcessCommandLine&lt;/LI-CODE&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;What to investigate next&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Encoded or obfuscated command lines&lt;/LI&gt;
                &lt;LI&gt;Parent process legitimacy&lt;/LI&gt;
                &lt;LI&gt;User context and device risk score&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;&lt;STRONG&gt;4. Newly Created or Modified Service Principals&lt;/STRONG&gt;&lt;/H3&gt;
                &lt;P&gt;&lt;STRONG&gt;Why it matters&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;Service principals are often abused for persistence or privilege escalation in Azure environments.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;What to hunt&lt;/STRONG&gt;&lt;/P&gt;
                &lt;LI-CODE lang="kusto"&gt;// MITRE ATT&amp;amp;CK: T1098 (Account Manipulation), T1098.001 (Additional Cloud Credentials) | Tactic: Persistence
                AuditLogs
                | where OperationName in ("Add service principal", "Update service principal")
                | project TimeGenerated, InitiatedBy, TargetResources, OperationName&lt;/LI-CODE&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;What to investigate next&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Assigned API permissions or directory roles&lt;/LI&gt;
                &lt;LI&gt;Token usage after creation&lt;/LI&gt;
                &lt;LI&gt;Correlation with unfamiliar IP addresses&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;&lt;STRONG&gt;5. Rare Azure Resource Access Patterns&lt;/STRONG&gt;&lt;/H3&gt;
                &lt;P&gt;&lt;STRONG&gt;Why it matters&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;Attackers exploring your environment often access subscriptions or resource groups they’ve never touched before.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;What to hunt&lt;/STRONG&gt;&lt;/P&gt;
                &lt;LI-CODE lang="kusto"&gt;// MITRE ATT&amp;amp;CK: T1526 (Cloud Service Discovery), T1069.003 (Permission Groups Discovery: Cloud) | Tactic: Discovery
                AzureActivity
                | summarize count() by Caller, ResourceGroup
                | join kind=leftanti (
                AzureActivity | where TimeGenerated &amp;lt; ago(30d)
                | summarize count() by Caller, ResourceGroup
                ) on Caller, ResourceGroup&lt;/LI-CODE&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;What to investigate next&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Role assignments for the caller&lt;/LI&gt;
                &lt;LI&gt;Whether access aligns with job function&lt;/LI&gt;
                &lt;LI&gt;Any subsequent configuration changes&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;&lt;STRONG&gt;Summary Table&amp;nbsp;&lt;/STRONG&gt;&lt;/H3&gt;
                &lt;P&gt;This table summarizes each Sentinel threat hunting query and maps it directly to the corresponding MITRE ATT&amp;amp;CK tactic and technique. By aligning hunts to ATT&amp;amp;CK, security teams can clearly communicate what adversary behaviors are being proactively investigated and identify gaps in coverage. This mapping also makes it easier to prioritize hunts, measure maturity, and transition high‑value hunts into analytics rules over time.&lt;/P&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table class="lia-border-style-solid" border="1" style="border-width: 1px;"&gt;&lt;thead&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;Sentinel Hunt&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;MITRE Tactic&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;&lt;STRONG&gt;MITRE Technique&lt;/STRONG&gt;&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Rare privileged sign‑ins&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Initial Access&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;T1078 – Valid Accounts&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Failed then successful logons&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Credential Access&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;T1110 – Brute Force&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;LOLBin execution&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Execution&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;T1059 / T1218&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Service principal changes&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Persistence&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;T1098.001&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;
                &lt;P&gt;Rare resource access&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;Discovery&lt;/P&gt;
                &lt;/td&gt;&lt;td&gt;
                &lt;P&gt;T1526 / T1069.003&lt;/P&gt;
                &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 33.33%" /&gt;&lt;col style="width: 33.33%" /&gt;&lt;col style="width: 33.33%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;H3&gt;&lt;STRONG&gt;Final Thoughts&lt;/STRONG&gt;&lt;/H3&gt;
                &lt;P&gt;Threat hunting in Microsoft Sentinel is most effective when it’s continuous, hypothesis‑driven, and contextual. These queries are starting points, not finished detections. Tune them based on your environment, enrich them with UEBA insights, and align your hunts to MITRE ATT&amp;amp;CK techniques, as outlined in your existing Sentinel content strategy.&lt;/P&gt;
                &lt;P&gt;If you consistently run hunts like these, you’ll catch suspicious behavior before it triggers an alert or before an attacker reaches their objective.&lt;/P&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&amp;nbsp;&lt;/DIV&gt;</description>
            <pubDate>Fri, 27 Feb 2026 16:00:00 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/microsoft-sentinel-blog/top-5-microsoft-sentinel-queries-for-threat-hunting/ba-p/4497667</guid>
            <dc:creator>SonjaEd</dc:creator>
            <dc:date>2026-02-27T16:00:00Z</dc:date>
        </item>
        <item>
            <title>What’s New in Windows Group Policy Preferences Debug Logging</title>
            <link>https://techcommunity.microsoft.com/t5/ask-the-directory-services-team/what-s-new-in-windows-group-policy-preferences-debug-logging/ba-p/4497060</link>
            <description>&lt;P&gt;Hello again — this is Potti Tagore Nadh from Directory Services team.&lt;/P&gt;
                &lt;P&gt;When troubleshooting Windows components, administrators often rely on enhanced logging to diagnose issues quickly and accurately. Group Policy Preferences (GPP) provide verbose debug logging capabilities for each client-side extension (CSE). Traditionally, these settings were available only through domain-based Group Policy Objects (GPOs).&lt;/P&gt;
                &lt;P&gt;With the release of February 2026 preview updates on Windows 11 24H2 and 25H2, this is changing—and it’s becoming much easier.&amp;nbsp;&lt;BR /&gt;&lt;EM&gt;Note: When the Server operating system update becomes available, we will update this article accordingly.&lt;/EM&gt;&lt;/P&gt;
                &lt;H2&gt;What’s New in Windows 11 24H2, 25H2?&lt;/H2&gt;
                &lt;P&gt;&lt;STRONG&gt;GPP Debug Logging Now Available in Local Group Policy&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;Starting with:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Windows 11 24H2&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Windows 11 25H2&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;And via Windows Updates from February 2026 Preview onward&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;Administrators can now enable &lt;STRONG&gt;Group Policy Preferences debug logging directly from Local Group Policy&lt;/STRONG&gt;—not just domain GPOs.&lt;/P&gt;
                &lt;P&gt;This enhancement allows troubleshooting directly on client devices &lt;STRONG&gt;without relying on domain controllers&lt;/STRONG&gt;, centralized GPO administration or manually moving Administrative Template files.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;This is a major quality-of-life improvement for IT pros who frequently debug GPP issues.&lt;/STRONG&gt;&lt;/P&gt;
                &lt;H2&gt;Group Policy Preferences Debug Logging – Visual Overview&lt;/H2&gt;
                &lt;P&gt;First, let's start off with some examples of the settings we are talking about.&lt;/P&gt;
                &lt;H3&gt;Figure 1. Group Policy Preferences Debug Logging using Local Group Policy&lt;/H3&gt;
                &lt;img /&gt;
                &lt;H2&gt;How to Enable Group Policy Preferences Logging and Tracing using Local Group Policy Editor (Gpedit.msc)&lt;/H2&gt;
                &lt;P&gt;You can enable logging and tracing for each individual preference CSE. These settings allow you to configure:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;What level of events are logged (&lt;STRONG&gt;Informational&lt;/STRONG&gt;, &lt;STRONG&gt;Warnings&lt;/STRONG&gt;, &lt;STRONG&gt;Errors&lt;/STRONG&gt;, or &lt;STRONG&gt;All&lt;/STRONG&gt;) (Typically, the most Verbose logging helps pin down difficult issues.)&lt;/LI&gt;
                &lt;LI&gt;Whether trace logging is enabled&lt;/LI&gt;
                &lt;LI&gt;Where trace logs are saved&lt;/LI&gt;
                &lt;LI&gt;Maximum trace file size&lt;STRONG style="color: rgb(30, 30, 30);"&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;Steps to Configure GPP Logging and Tracing&lt;/H3&gt;
                &lt;OL&gt;
                &lt;LI&gt;Open &lt;STRONG&gt;Local Group Policy Editor&lt;/STRONG&gt; using gpedit.msc.&lt;/LI&gt;
                &lt;LI&gt;Navigate to:&lt;BR /&gt;&lt;STRONG&gt;Computer Configuration → Policies → Administrative Templates → System → Group Policy → Logging and Tracing&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;LI&gt;Select the desired &lt;STRONG&gt;Preference CSE&lt;/STRONG&gt; (e.g., Drive Maps, Files, Shortcuts, Printers).&lt;/LI&gt;
                &lt;LI&gt;Set the policy to &lt;STRONG&gt;Enabled&lt;/STRONG&gt;.&lt;/LI&gt;
                &lt;LI&gt;Configure:&lt;/LI&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Event logging:&lt;/STRONG&gt; &lt;EM&gt;Informational, Warnings, and Errors&lt;/EM&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Tracing:&lt;/STRONG&gt; &lt;EM&gt;Enabled&lt;/EM&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;User trace path:&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;LI&gt;%COMMONAPPDATA%\GroupPolicy\Preference\Trace\User.log&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Maximum file size:&lt;/STRONG&gt; &lt;EM&gt;1024 KB (increase if logs roll over too quickly)&lt;/EM&gt;&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Computer trace path:&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;LI&gt;%COMMONAPPDATA%\GroupPolicy\Preference\Trace\Computer.log&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;LI&gt;Click &lt;STRONG&gt;Apply&lt;/STRONG&gt; and &lt;STRONG&gt;OK&lt;/STRONG&gt;.&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;H3&gt;Figure 2. Preference Logging and Tracing Policy Settings&lt;/H3&gt;
                &lt;img /&gt;
                &lt;H4&gt;Understanding Trace File Locations&lt;/H4&gt;
                &lt;P&gt;The default trace directory for all GPP CSEs is:&lt;/P&gt;
                &lt;P&gt;%COMMONAPPDATA%\GroupPolicy\Preference\Trace&lt;/P&gt;
                &lt;P&gt;While %COMMONAPPDATA% is &lt;STRONG&gt;not&lt;/STRONG&gt; a standard Windows environment variable, it is recognized and expanded internally by the GPP CSEs.&lt;/P&gt;
                &lt;P&gt;Equivalent physical path:&lt;/P&gt;
                &lt;P&gt;%SYSTEMDRIVE%\ProgramData\Microsoft\&lt;/P&gt;
                &lt;P&gt;Note: This folder is hidden by default. You can type the path directly into File Explorer.&lt;/P&gt;
                &lt;P&gt;If you choose a &lt;STRONG&gt;custom folder&lt;/STRONG&gt;, Windows requires:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Full access permissions for the &lt;STRONG&gt;SYSTEM&lt;/STRONG&gt; account&lt;/LI&gt;
                &lt;LI&gt;No restrictive ACLs that block service-level writes&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H4&gt;Figure 3. Required Permissions for Custom Log Folder&lt;/H4&gt;
                &lt;P&gt;When configuring a &lt;STRONG&gt;custom trace log folder&lt;/STRONG&gt; for Group Policy Preferences (GPP) Client‑Side Extensions (CSEs), the &lt;STRONG&gt;SYSTEM account must have Full Control&lt;/STRONG&gt; on the directory.&lt;/P&gt;
                &lt;P&gt;GPP CSEs run under &lt;STRONG&gt;Local System&lt;/STRONG&gt;, not the user context.&lt;BR /&gt;If SYSTEM lacks permissions:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Trace files will &lt;STRONG&gt;not be created&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;LI&gt;Logging will silently &lt;STRONG&gt;fail&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;img /&gt;
                &lt;H2&gt;Conclusion&lt;/H2&gt;
                &lt;P&gt;The introduction of Group Policy Preferences CSE logging to &lt;STRONG&gt;client-side Local Group Policy&lt;/STRONG&gt; in Windows 11 24H2/25H2 and later is a meaningful upgrade for administrators.&lt;/P&gt;
                &lt;P&gt;This enhancement:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;Simplifies troubleshooting&lt;/LI&gt;
                &lt;LI&gt;Reduces dependency on domain or GPO administrators&lt;/LI&gt;
                &lt;LI&gt;Provides a more flexible and scalable diagnostic workflow&lt;/LI&gt;
                &lt;LI&gt;Brings client, server-level policy debugging features directly to client devices&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;If you’re working with Group Policy Preferences regularly, this update will help you analyze issues faster and more independently.&lt;/P&gt;
                &lt;P&gt;Article for original release of Preference Debug Logging:&lt;/P&gt;
                &lt;P&gt;&lt;A href="https://techcommunity.microsoft.com/blog/askds/enabling-group-policy-preferences-debug-logging-using-the-rsat/395555" target="_blank"&gt;Enabling Group Policy Preferences Debug Logging using the RSAT | Microsoft Community Hub&lt;/A&gt;&lt;/P&gt;</description>
            <pubDate>Fri, 27 Feb 2026 13:36:57 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/ask-the-directory-services-team/what-s-new-in-windows-group-policy-preferences-debug-logging/ba-p/4497060</guid>
            <dc:creator>TagoreN</dc:creator>
            <dc:date>2026-02-27T13:36:57Z</dc:date>
        </item>
        <item>
            <title>Optimising AI Costs with Microsoft Foundry Model Router</title>
            <link>https://techcommunity.microsoft.com/t5/microsoft-developer-community/optimising-ai-costs-with-microsoft-foundry-model-router/ba-p/4494776</link>
            <description>&lt;DIV class="container"&gt;
                &lt;P&gt;Microsoft Foundry Model Router analyses each prompt in real-time and forwards it to the most appropriate LLM from a pool of underlying models. Simple requests go to fast, cheap models; complex requests go to premium ones, all automatically.&lt;/P&gt;
                &lt;P&gt;I built an &lt;A class="lia-external-url" href="https://github.com/leestott/router-demo-app/" target="_blank" rel="noopener"&gt;interactive demo app&lt;/A&gt; so you can see the routing decisions, measure latencies, and compare costs yourself. This post walks through how it works, what we measured, and when it makes sense to use.&lt;/P&gt;
                &lt;H2&gt;The Problem: One Model for Everything Is Wasteful&lt;/H2&gt;
                &lt;P&gt;Traditional deployments force a single choice:&lt;/P&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table border="1" style="border-width: 1px;"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Strategy&lt;/th&gt;&lt;th&gt;Upside&lt;/th&gt;&lt;th&gt;Downside&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Use a small model&lt;/td&gt;&lt;td&gt;Fast, cheap&lt;/td&gt;&lt;td&gt;Struggles with complex tasks&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Use a large model&lt;/td&gt;&lt;td&gt;Handles everything&lt;/td&gt;&lt;td&gt;Overpay for simple tasks&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Build your own router&lt;/td&gt;&lt;td&gt;Full control&lt;/td&gt;&lt;td&gt;Maintenance burden; hard to optimise&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 33.33%" /&gt;&lt;col style="width: 33.33%" /&gt;&lt;col style="width: 33.33%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;P&gt;Most production workloads are &lt;STRONG&gt;mixed-complexity&lt;/STRONG&gt;. Classification, FAQ look-ups, and data extraction sit alongside code analysis, multi-constraint planning, and long-document summarisation. Paying premium-model prices for the simple 40% is money left on the table.&lt;/P&gt;
                &lt;H2&gt;The Solution: Model Router&lt;/H2&gt;
                &lt;P&gt;Model Router is a &lt;STRONG&gt;trained language model&lt;/STRONG&gt; deployed as a single Azure endpoint. For each incoming request it:&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Analyses the prompt&lt;/STRONG&gt; — complexity, task type, context length&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Selects an underlying model&lt;/STRONG&gt; from the routing pool&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Forwards the request&lt;/STRONG&gt; and returns the response&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Exposes the choice&lt;/STRONG&gt; via the &lt;CODE&gt;response.model&lt;/CODE&gt; field&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;P&gt;You interact with one deployment. No if/else routing logic in your code.&lt;/P&gt;
                &lt;H3&gt;Routing Modes&lt;/H3&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table border="1" style="border-width: 1px;"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Mode&lt;/th&gt;&lt;th&gt;Goal&lt;/th&gt;&lt;th&gt;Trade-off&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;STRONG&gt;Balanced&lt;/STRONG&gt; (default)&lt;/td&gt;&lt;td&gt;Best cost-quality ratio&lt;/td&gt;&lt;td&gt;General-purpose&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;STRONG&gt;Cost&lt;/STRONG&gt;&lt;/td&gt;&lt;td&gt;Minimise spend&lt;/td&gt;&lt;td&gt;May use smaller models more aggressively&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;STRONG&gt;Quality&lt;/STRONG&gt;&lt;/td&gt;&lt;td&gt;Maximise accuracy&lt;/td&gt;&lt;td&gt;Higher cost for complex tasks&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 33.33%" /&gt;&lt;col style="width: 33.33%" /&gt;&lt;col style="width: 33.33%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;P&gt;Modes are configured in the Foundry Portal, no code change needed to switch.&lt;/P&gt;
                &lt;H2&gt;Building the Demo&lt;/H2&gt;
                &lt;P&gt;To make routing decisions tangible, we built a React + TypeScript app that sends the &lt;STRONG&gt;same prompt&lt;/STRONG&gt; through both Model Router and a fixed standard deployment (e.g. GPT-5-nano), then compares:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Which model&lt;/STRONG&gt; the router selected&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Latency&lt;/STRONG&gt; (ms)&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Token usage&lt;/STRONG&gt; (prompt + completion)&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Estimated cost&lt;/STRONG&gt; (based on per-model pricing)&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;FIGURE&gt;&lt;BR /&gt;
                &lt;FIGCAPTION&gt;Select a prompt, choose a routing mode, and hit Run Both to compare side-by-side&lt;/FIGCAPTION&gt;
                &lt;/FIGURE&gt;
                &lt;img /&gt;
                &lt;H3&gt;What You Can Do&lt;/H3&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;10 pre-built prompts&lt;/STRONG&gt; spanning simple classification to complex multi-constraint planning&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Custom prompt input&lt;/STRONG&gt; enter any text and benchmarks run automatically&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Three routing modes&lt;/STRONG&gt; switch and re-run to see how distribution changes&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Batch mode&lt;/STRONG&gt; run all 10 prompts in one click to gather aggregate stats&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;API Integration&lt;/H3&gt;
                &lt;P&gt;The integration is a standard Azure OpenAI chat completion call. The only difference is the deployment name (&lt;CODE&gt;model-router&lt;/CODE&gt; instead of a specific model):&lt;/P&gt;
                &lt;PRE&gt;&amp;nbsp;&lt;/PRE&gt;
                &lt;LI-CODE lang=""&gt;const response = await fetch(
                `${endpoint}/openai/deployments/model-router/chat/completions?api-version=2024-10-21`,
                {
                method: 'POST',
                headers: {
                'Content-Type': 'application/json',
                'api-key': apiKey,
                },
                body: JSON.stringify({
                messages: [{ role: 'user', content: prompt }],
                max_completion_tokens: 1024,
                }),
                }
                );

                const data = await response.json();

                // The key insight: response.model reveals the underlying model
                const selectedModel = data.model; // e.g. "gpt-5-nano-2025-08-07"&lt;/LI-CODE&gt;
                &lt;PRE&gt;&amp;nbsp;&lt;/PRE&gt;
                &lt;P&gt;That&amp;nbsp;&lt;CODE&gt;data.model&lt;/CODE&gt; field is what makes cost tracking and distribution analysis possible.&lt;/P&gt;
                &lt;H2&gt;Results: What the Data Shows&lt;/H2&gt;
                &lt;P&gt;We ran all 10 prompts through both Model Router (Balanced mode) and a fixed standard deployment.&lt;/P&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;&lt;STRONG&gt;Note&lt;/STRONG&gt;: Results vary by run, region, model versions, and Azure load. These numbers are from a representative sample run.&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;FIGURE&gt;&lt;BR /&gt;
                &lt;FIGCAPTION&gt;Side-by-side comparison across all 10 prompts in Balanced mode&lt;/FIGCAPTION&gt;
                &lt;/FIGURE&gt;
                &lt;img /&gt;
                &lt;H3&gt;Summary&lt;/H3&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table border="1" style="border-width: 1px;"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Metric&lt;/th&gt;&lt;th&gt;Router (Balanced)&lt;/th&gt;&lt;th&gt;Standard (GPT-5-nano)&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Avg Latency&lt;/td&gt;&lt;td&gt;~7,800 ms&lt;/td&gt;&lt;td&gt;~7,700 ms&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Total Cost (10 prompts)&lt;/td&gt;&lt;td&gt;~$0.029&lt;/td&gt;&lt;td&gt;~$0.030&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;STRONG&gt;Cost Savings&lt;/STRONG&gt;&lt;/td&gt;&lt;td&gt;&lt;STRONG&gt;~4.5%&lt;/STRONG&gt;&lt;/td&gt;&lt;td&gt;—&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Models Used&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 33.33%" /&gt;&lt;col style="width: 33.33%" /&gt;&lt;col style="width: 33.33%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;H3&gt;Model Distribution&lt;/H3&gt;
                &lt;P&gt;The router used &lt;STRONG&gt;4 different models&lt;/STRONG&gt; across 10 prompts:&lt;/P&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table border="1" style="border-width: 1px;"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model&lt;/th&gt;&lt;th&gt;Requests&lt;/th&gt;&lt;th&gt;Share&lt;/th&gt;&lt;th&gt;Typical Use&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;CODE&gt;gpt-5-nano&lt;/CODE&gt;&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;50%&lt;/td&gt;&lt;td&gt;Classification, summarisation, planning&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;CODE&gt;gpt-5-mini&lt;/CODE&gt;&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;20%&lt;/td&gt;&lt;td&gt;FAQ answers, data extraction&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;CODE&gt;gpt-oss-120b&lt;/CODE&gt;&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;20%&lt;/td&gt;&lt;td&gt;Long-context analysis, creative tasks&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;CODE&gt;gpt-4.1-mini&lt;/CODE&gt;&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;10%&lt;/td&gt;&lt;td&gt;Complex debugging &amp;amp; reasoning&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 25.00%" /&gt;&lt;col style="width: 25.00%" /&gt;&lt;col style="width: 25.00%" /&gt;&lt;col style="width: 25.00%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;FIGURE&gt;&lt;BR /&gt;
                &lt;FIGCAPTION&gt;Routing distribution chart — the router favours efficient models for simple prompts&lt;BR /&gt;&lt;BR /&gt;&lt;/FIGCAPTION&gt;
                &lt;/FIGURE&gt;
                &lt;img /&gt;
                &lt;H3&gt;Across All Three Modes&lt;/H3&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table border="1" style="border-width: 1px;"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Metric&lt;/th&gt;&lt;th&gt;Balanced&lt;/th&gt;&lt;th&gt;Cost-Optimised&lt;/th&gt;&lt;th&gt;Quality-Optimised&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Cost Savings&lt;/td&gt;&lt;td&gt;~4.5%&lt;/td&gt;&lt;td&gt;~4.7%&lt;/td&gt;&lt;td&gt;~14.2%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Avg Latency (Router)&lt;/td&gt;&lt;td&gt;~7,800 ms&lt;/td&gt;&lt;td&gt;~7,800 ms&lt;/td&gt;&lt;td&gt;~6,800 ms&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Avg Latency (Standard)&lt;/td&gt;&lt;td&gt;~7,700 ms&lt;/td&gt;&lt;td&gt;~7,300 ms&lt;/td&gt;&lt;td&gt;~8,300 ms&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Primary Goal&lt;/td&gt;&lt;td&gt;Balance cost + quality&lt;/td&gt;&lt;td&gt;Minimise spend&lt;/td&gt;&lt;td&gt;Maximise accuracy&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Model Selection&lt;/td&gt;&lt;td&gt;Mixed (4 models)&lt;/td&gt;&lt;td&gt;Prefers cheaper&lt;/td&gt;&lt;td&gt;Prefers premium&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 25.00%" /&gt;&lt;col style="width: 25.00%" /&gt;&lt;col style="width: 25.00%" /&gt;&lt;col style="width: 25.00%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;FIGURE&gt;
                &lt;FIGCAPTION&gt;Cost-optimised mode — routes more aggressively to nano/mini models&lt;BR /&gt;&lt;BR /&gt;&lt;/FIGCAPTION&gt;
                &lt;/FIGURE&gt;
                &lt;img /&gt;
                &lt;FIGURE&gt;&lt;BR /&gt;
                &lt;FIGCAPTION&gt;Quality-optimised mode — routes to larger models for complex tasks&lt;BR /&gt;&lt;BR /&gt;&lt;/FIGCAPTION&gt;
                &lt;/FIGURE&gt;
                &lt;img /&gt;
                &lt;H2&gt;Analysis&lt;/H2&gt;
                &lt;H3&gt;What Worked Well&lt;/H3&gt;
                &lt;P&gt;&lt;STRONG&gt;Intelligent distribution&lt;/STRONG&gt;&amp;nbsp; The router didn't just default to one model. It used 4 different models and mapped prompt complexity to model capability: simple classification → nano, FAQ answers → mini, long-context documents → oss-120b, complex debugging → 4.1-mini.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Measurable cost savings across all modes&lt;/STRONG&gt;&amp;nbsp; 4.5% in Balanced, 4.7% in Cost, and 14.2% in Quality mode. Quality mode was the surprise winner by choosing faster, cheaper models for simple prompts, it actually saved the most while still routing complex requests to capable models.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Zero routing logic in application code&lt;/STRONG&gt; One endpoint, one deployment name. The complexity lives in Azure's infrastructure, not yours.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Operational flexibility&lt;/STRONG&gt; Switch between Balanced, Cost, and Quality modes in the Foundry Portal without redeploying your app. Need to cut costs for a high-traffic period? Switch to Cost mode. Need accuracy for a compliance run? Switch to Quality.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Future-proofing&lt;/STRONG&gt;&amp;nbsp; As Azure adds new models to the routing pool, your deployment benefits automatically. No code changes needed.&lt;/P&gt;
                &lt;H3&gt;Trade-offs to Consider&lt;/H3&gt;
                &lt;P&gt;&lt;STRONG&gt;Latency is comparable, not always faster&lt;/STRONG&gt;&amp;nbsp; In Balanced mode, Router averaged ~7,800 ms vs Standard's ~7,700 ms&amp;nbsp; nearly identical. In Quality mode, the Router was actually &lt;EM&gt;faster&lt;/EM&gt; (~6,800 ms vs ~8,300 ms) because it chose more efficient models for simple prompts. The delta depends on which models the router selects.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Savings scale with workload diversity&lt;/STRONG&gt; Our 10-prompt test set showed 4.5–14.2% savings. Production workloads with a wider spread of simple vs complex prompts should see larger savings, since the router has more opportunity to route simple requests to cheaper models.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Opaque routing decisions&lt;/STRONG&gt;&amp;nbsp; You can see &lt;EM&gt;which&lt;/EM&gt; model was picked via &lt;CODE&gt;response.model&lt;/CODE&gt;, but you can't see &lt;EM&gt;why&lt;/EM&gt;. For most applications this is fine; for debugging edge cases you may want to test specific prompts in the demo first.&lt;/P&gt;
                &lt;H2&gt;Custom Prompt Testing&lt;/H2&gt;
                &lt;P&gt;One of the most practical features of the demo is testing &lt;STRONG&gt;your own prompts&lt;/STRONG&gt; before committing to Model Router in production.&lt;/P&gt;
                &lt;FIGURE&gt;
                &lt;FIGCAPTION&gt;Enter any prompt&amp;nbsp; `the quantum computing example is a medium-complexity educational prompt`&lt;BR /&gt;&lt;img /&gt;&lt;/FIGCAPTION&gt;
                &lt;/FIGURE&gt;
                &lt;FIGURE&gt;
                &lt;FIGCAPTION&gt;Benchmarks execute automatically, showing the selected model, latency, tokens, and cost&lt;BR /&gt;&lt;BR /&gt;&lt;/FIGCAPTION&gt;
                &lt;/FIGURE&gt;
                &lt;img /&gt;
                &lt;P&gt;&lt;STRONG&gt;Workflow:&lt;/STRONG&gt;&lt;/P&gt;
                &lt;OL&gt;
                &lt;LI&gt;Click &lt;STRONG&gt;✏️ Custom&lt;/STRONG&gt; in the prompt selector&lt;/LI&gt;
                &lt;LI&gt;Enter your production-representative prompt&lt;/LI&gt;
                &lt;LI&gt;Click &lt;STRONG&gt;✓ Use This Prompt&lt;/STRONG&gt; — Router and Standard run automatically&lt;/LI&gt;
                &lt;LI&gt;Compare results — repeat with different routing modes&lt;/LI&gt;
                &lt;LI&gt;Use the data to inform your deployment strategy&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;P&gt;This lets you &lt;STRONG&gt;predict costs and validate routing behaviour&lt;/STRONG&gt; with your actual workload before going to production.&lt;/P&gt;
                &lt;H2&gt;When to Use Model Router&lt;/H2&gt;
                &lt;H3&gt;Great Fit&lt;/H3&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Mixed-complexity workloads&lt;/STRONG&gt; — chatbots, customer service, content pipelines&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Cost-sensitive deployments&lt;/STRONG&gt; — where even single-digit percentage savings matter at scale&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Teams wanting simplicity&lt;/STRONG&gt; — one endpoint beats managing multi-model routing logic&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Rapid experimentation&lt;/STRONG&gt; — try new models without changing application code&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;Consider Carefully&lt;/H3&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Ultra-low-latency requirements&lt;/STRONG&gt; — if you need sub-second responses, the routing overhead matters&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Single-task, single-model workloads&lt;/STRONG&gt; — if one model is clearly optimal for 100% of your traffic, a router adds complexity without benefit&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Full control over model selection&lt;/STRONG&gt; — if you need deterministic model choice per request&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H3&gt;Mode Selection Guide&lt;/H3&gt;
                &lt;DIV class="decision-tree"&gt;Is accuracy critical (compliance, legal, medical)?&amp;nbsp;&lt;/DIV&gt;
                &lt;/DIV&gt;
                &lt;DIV class="decision-tree"&gt;&lt;LI-CODE lang=""&gt;Is accuracy critical (compliance, legal, medical)?
                └─ YES → Quality-Optimised
                └─ NO  → Strict budget constraints?
                └─ YES → Cost-Optimised
                └─ NO  → Balanced (recommended)&lt;/LI-CODE&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;DIV class="container"&gt;
                &lt;H2&gt;Best Practices&lt;/H2&gt;
                &lt;OL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Start with Balanced mode&lt;/STRONG&gt; — measure actual results, then optimise&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Test with your real prompts&lt;/STRONG&gt; — use the Custom Prompt feature to validate routing before production&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Monitor model distribution&lt;/STRONG&gt; — track which models handle your traffic over time&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Compare against a baseline&lt;/STRONG&gt; — always keep a standard deployment to measure savings&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Review regularly&lt;/STRONG&gt; — as new models enter the routing pool, distributions shift&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;H2&gt;Technical Stack&lt;/H2&gt;
                &lt;DIV class="styles_lia-table-wrapper__h6Xo9 styles_table-responsive__MW0lN"&gt;&lt;table border="1" style="border-width: 1px;"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Technology&lt;/th&gt;&lt;th&gt;Purpose&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;React 19 + TypeScript 5.9&lt;/td&gt;&lt;td&gt;UI and type safety&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Vite 7&lt;/td&gt;&lt;td&gt;Dev server and build tool&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Tailwind CSS 4&lt;/td&gt;&lt;td&gt;Styling&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Recharts 3&lt;/td&gt;&lt;td&gt;Distribution and comparison charts&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Azure OpenAI API (2024-10-21)&lt;/td&gt;&lt;td&gt;Model Router and standard completions&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;colgroup&gt;&lt;col style="width: 50.00%" /&gt;&lt;col style="width: 50.00%" /&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/DIV&gt;
                &lt;P&gt;Security measures include an &lt;CODE&gt;ErrorBoundary&lt;/CODE&gt; for crash resilience, sanitised API error messages, &lt;CODE&gt;AbortController&lt;/CODE&gt; request timeouts, input length validation, and restrictive security headers. API keys are loaded from environment variables and gitignored.&lt;BR /&gt;Source:&lt;A href="https://github.com/leestott/router-demo-app/" target="_blank" rel="noopener"&gt; leestott/router-demo-app: An interactive web application demonstrating the power of Microsoft Foundry Model Router - an intelligent routing system that automatically selects the optimal language model for each request based on complexity, reasoning requirements, and task type.&lt;/A&gt;&lt;/P&gt;
                &lt;DIV class="warning"&gt;
                &lt;P&gt;⚠️ &lt;STRONG&gt;This demo calls Azure OpenAI directly from the browser.&lt;/STRONG&gt; This is fine for local development. For production, proxy through a backend and use &lt;A href="https://learn.microsoft.com/azure/ai-services/openai/how-to/managed-identity" target="_blank" rel="noopener noreferrer"&gt;Managed Identity&lt;/A&gt;.&lt;/P&gt;
                &lt;/DIV&gt;
                &lt;H2&gt;&lt;A class="lia-external-url" href="https://github.com/leestott/router-demo-app/" target="_blank" rel="noopener"&gt;Try It Yourself&lt;/A&gt;&lt;BR /&gt;Quick Start&lt;/H2&gt;
                &lt;PRE&gt;&lt;CODE&gt;git clone &lt;/CODE&gt;https://github.com/leestott/router-demo-app/&lt;/PRE&gt;
                &lt;PRE&gt;&lt;CODE&gt;
                cd router-demo-app

                &lt;SPAN class="comment"&gt;# Option A: Use the setup script (recommended)&lt;/SPAN&gt;
                &lt;SPAN class="comment"&gt;# Windows:&lt;/SPAN&gt;
                .\setup.ps1 -StartDev
                &lt;SPAN class="comment"&gt;# macOS/Linux:&lt;/SPAN&gt;
                chmod +x setup.sh &amp;amp;&amp;amp; ./setup.sh --start-dev

                &lt;SPAN class="comment"&gt;# Option B: Manual&lt;/SPAN&gt;
                npm install
                cp .env.example .env.local
                &lt;SPAN class="comment"&gt;# Edit .env.local with your Azure credentials&lt;/SPAN&gt;
                npm run dev&lt;/CODE&gt;&lt;/PRE&gt;
                &lt;P&gt;Open &lt;CODE&gt;http://localhost:5173&lt;/CODE&gt;, select a prompt, and click &lt;STRONG&gt;⚡ Run Both&lt;/STRONG&gt;.&lt;/P&gt;
                &lt;H3&gt;Get Your Credentials&lt;/H3&gt;
                &lt;OL&gt;
                &lt;LI&gt;Go to &lt;A href="https://ai.azure.com" target="_blank" rel="noopener noreferrer"&gt;ai.azure.com&lt;/A&gt; → open your project&lt;/LI&gt;
                &lt;LI&gt;Copy the &lt;STRONG&gt;Project connection string&lt;/STRONG&gt; (endpoint URL)&lt;/LI&gt;
                &lt;LI&gt;Navigate to &lt;STRONG&gt;Deployments&lt;/STRONG&gt; → confirm &lt;CODE&gt;model-router&lt;/CODE&gt; is deployed&lt;/LI&gt;
                &lt;LI&gt;Get your &lt;STRONG&gt;API key&lt;/STRONG&gt; from &lt;STRONG&gt;Project Settings → Keys&lt;/STRONG&gt;&lt;/LI&gt;
                &lt;/OL&gt;
                &lt;H3&gt;Configuration&lt;/H3&gt;
                &lt;P&gt;Edit &lt;CODE&gt;.env.local&lt;/CODE&gt;:&lt;/P&gt;
                &lt;PRE&gt;&lt;CODE&gt;VITE_ROUTER_ENDPOINT=https://your-resource.cognitiveservices.azure.com
                VITE_ROUTER_API_KEY=your-api-key
                VITE_ROUTER_DEPLOYMENT=model-router

                VITE_STANDARD_ENDPOINT=https://your-resource.cognitiveservices.azure.com
                VITE_STANDARD_API_KEY=your-api-key
                VITE_STANDARD_DEPLOYMENT=gpt-5-nano&lt;/CODE&gt;&lt;/PRE&gt;
                &lt;H2&gt;Ideas for Enhancement&lt;/H2&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Historical analysis&lt;/STRONG&gt; — persist results to track routing trends over time&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Cost projections&lt;/STRONG&gt; — estimate monthly spend based on prompt patterns and volume&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;A/B testing framework&lt;/STRONG&gt; — compare modes with statistical significance&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Streaming support&lt;/STRONG&gt; — show model selection for streaming responses&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Export reports&lt;/STRONG&gt; — download benchmark data as CSV/JSON for further analysis&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;H2&gt;Conclusion&lt;/H2&gt;
                &lt;P&gt;Model Router addresses a real problem: most AI workloads have mixed complexity, but most deployments use a single model. By routing each request to the right model automatically, you get:&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;STRONG&gt;Cost savings&lt;/STRONG&gt; (~4.5–14.2% measured across modes, scaling with volume)&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Intelligent distribution&lt;/STRONG&gt; (4 models used, zero routing code)&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Operational simplicity&lt;/STRONG&gt; (one endpoint, mode changes via portal)&lt;/LI&gt;
                &lt;LI&gt;&lt;STRONG&gt;Future-proofing&lt;/STRONG&gt; (new models added to the pool automatically)&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;The latency trade-off is minimal — in Quality mode, the Router was actually &lt;EM&gt;faster&lt;/EM&gt; than the standard deployment. The real value is &lt;STRONG&gt;flexibility&lt;/STRONG&gt;: tune for cost, quality, or balance without touching your code.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Ready to try it?&lt;/STRONG&gt; Clone the demo repository, plug in your Azure credentials, and test with your own prompts.&lt;/P&gt;
                &lt;H2&gt;Resources&lt;/H2&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;A class="lia-external-url" href="https://github.com/leestott/router-demo-app/" target="_blank" rel="noopener"&gt;Model Router Benchmark Sample&lt;/A&gt;&amp;nbsp; Sample App&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://learn.microsoft.com/azure/ai-foundry/openai/concepts/model-router" target="_blank" rel="noopener noreferrer"&gt;Model Router Concepts&lt;/A&gt;&amp;nbsp; Official documentation&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://learn.microsoft.com/azure/ai-foundry/openai/how-to/model-router" target="_blank" rel="noopener noreferrer"&gt;Model Router How-To&lt;/A&gt;&amp;nbsp; Deployment guide&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://ai.azure.com" target="_blank" rel="noopener noreferrer"&gt;Microsoft Foundry Portal&lt;/A&gt;&amp;nbsp; Deploy and manage&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://ai.azure.com/catalog/models/model-router" target="_blank" rel="noopener noreferrer"&gt;Model Router in the Catalog&lt;/A&gt; Model listing&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://learn.microsoft.com/azure/ai-services/openai/how-to/managed-identity" target="_blank" rel="noopener noreferrer"&gt;Azure OpenAI Managed Identity&lt;/A&gt; Production auth&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;DIV class="tags"&gt;&amp;nbsp;&lt;/DIV&gt;
                &lt;FOOTER&gt;
                &lt;P&gt;Built to explore Model Router and share findings with the developer community.&lt;BR /&gt;&lt;BR /&gt;Feedback and contributions welcome, open an issue or PR on GitHub.&lt;/P&gt;
                &lt;/FOOTER&gt;&lt;/DIV&gt;</description>
            <pubDate>Fri, 27 Feb 2026 08:00:00 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/microsoft-developer-community/optimising-ai-costs-with-microsoft-foundry-model-router/ba-p/4494776</guid>
            <dc:creator>Lee_Stott</dc:creator>
            <dc:date>2026-02-27T08:00:00Z</dc:date>
        </item>
        <item>
            <title>Creating a Fun Multi-Agent Content Strategy System with Microsoft Agent Framework</title>
            <link>https://techcommunity.microsoft.com/t5/educator-developer-blog/creating-a-fun-multi-agent-content-strategy-system-with/ba-p/4495105</link>
            <description>&lt;P&gt;That's what we're building in this tutorial. Using Microsoft Agent Framework, we'll create a multi-agent system where three specialised AI agents collaborate to help gaming content creators craft posts that actually perform. One agent generates platform-native content. Another evaluates it the way TikTok's, Twitter's, or YouTube's recommendation algorithm would. A third reacts as a real audience member, complete with the slang, biases, and short attention span of an actual person scrolling their feed.&lt;/P&gt;
                &lt;P&gt;I have named the simulation app &lt;EM&gt;Viral or Fail&lt;/EM&gt;, and by the end of this tutorial you'll have a working tool that demonstrates some of the most important patterns in multi-agent system design: role specialisation, structured evaluation, iterative feedback loops, and tool integration with external data sources.&lt;/P&gt;
                &lt;H2&gt;What We Will Cover&lt;/H2&gt;
                &lt;P&gt;By the end of this tutorial, you'll understand how to design a multi-agent system where each agent has a distinct role and expertise, orchestrate agent communication using Agent Framework's Agent class and async sessions, integrate external tools (live Google Trends data) into an agent workflow, build iterative refinement pipelines where agents improve each other's output through structured feedback, and create evaluation rubrics that ground agent behaviour in real-world domain logic.&lt;/P&gt;
                &lt;P&gt;These patterns can be applied to numerous other tasks as this is the same building block behind multi-agent customer support systems, automated code review pipelines, and any application where specialised agents need to collaborate on a shared task.&lt;/P&gt;
                &lt;H2&gt;Prerequisites&lt;/H2&gt;
                &lt;P&gt;You'll need Python 3.10 or higher, a GitHub account with a Personal Access Token (free tier — get one at &lt;A href="https://github.com/settings/tokens" target="_blank" rel="noopener"&gt;github.com/settings/tokens&lt;/A&gt;), and a basic understanding of what AI agents are. If you're new to agents, I'd recommend the &lt;A href="https://github.com/microsoft/ai-agents-for-beginners" target="_blank" rel="noopener"&gt;AI Agents for Beginners&lt;/A&gt; course; this project was inspired by and builds on concepts from that curriculum.&lt;/P&gt;
                &lt;H2&gt;Why Multi-Agent? Why Not Just One Big Prompt?&lt;/H2&gt;
                &lt;P&gt;You &lt;EM&gt;could&lt;/EM&gt; write a single prompt that says "generate a gaming post, score it, and react to it." But you'd get mediocre results across the board. A single LLM call tries to be creative, analytical, and authentic simultaneously&amp;nbsp; and will probably end up being none of those things convincingly.&lt;/P&gt;
                &lt;P&gt;Multi-agent systems solve this through role specialisation. When an agent's only job is to think like TikTok's recommendation algorithm, it does that job significantly better than a generalist prompt. And when agents with different objectives interact, natural tension emerges: a creator wants to be bold and viral, an algorithm wants measurable engagement signals, and an audience member just wants to feel something. That tension produces more realistic, more useful outputs than any monolithic approach.&lt;/P&gt;
                &lt;P&gt;This is the same principle behind production multi-agent systems. Content moderation platforms use separate agents for classification, response generation, and quality assurance. Code review tools use one agent to identify issues and another to suggest fixes. The pattern scales because specialisation scales.&lt;/P&gt;
                &lt;img&gt;
                &lt;P&gt;&lt;EM&gt;System architecture: The Content Creator generates platform-native content from live trends, the Algorithm Simulator scores it against platform-specific rubrics, and a randomly selected Audience Persona reacts authentically. Feedback from both evaluators flows back to the Creator for iterative refinement.&lt;/EM&gt;&lt;/P&gt;
                &lt;/img&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H2&gt;System Design: Three Agents, Three Perspectives&lt;/H2&gt;
                &lt;P&gt;The system's power comes from the fact that each agent represents a fundamentally different lens on the same piece of content. Let's break down each one.&lt;/P&gt;
                &lt;H3&gt;The Content Creator Agent&lt;/H3&gt;
                &lt;P&gt;This agent, here, is the strategist. It is a trend-savvy gaming content creator who understands the nuances of each platform. it generates platform-native content that respects the conventions, formats, and cultural norms of TikTok, Twitter/X, YouTube, or Instagram.&lt;/P&gt;
                &lt;P&gt;The key design decision here is in the system prompt. Rather than generic instructions, we encode platform-specific knowledge directly:&lt;/P&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;CREATOR_SYSTEM_PROMPT = """You are the Content Creator — a trend-savvy gaming content creator who lives and breathes internet culture. You know every platform inside out and create content that feels native, not generic. RULES: - Be platform-native. A TikTok script should feel like a TikTok, not a blog post. - Use gaming terminology correctly. Don't say "the game Valorant" — say "Valo" or "Val". - For Twitter/X: Write punchy, provocative takes. Think ratio-worthy engagement bait. - For YouTube: Focus on title + thumbnail concept + video structure outline. - Be bold. Safe content doesn't go viral. When given FEEDBACK from the Algorithm Simulator and Audience Persona, revise your content to address their specific concerns while keeping the creative energy high. Explain what you changed and why."""&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;P&gt;That last instruction is important as it tells the Creator how to handle feedback from the other agents, which is what enables the iterative refinement loop we'll build later.&lt;/P&gt;
                &lt;H3&gt;The Algorithm Simulator Agent&lt;/H3&gt;
                &lt;P&gt;This is the most unusual agent in the system. Instead of acting as a generic critic, it role-plays as a social media platform's actual recommendation algorithm. It evaluates content the way an algorithm would through signals, weights, and distribution mechanics.&lt;/P&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;ALGORITHM_SYSTEM_PROMPT = """You are the Algorithm Simulator — a cold, analytical system that evaluates content exactly like a social media platform's recommendation algorithm would. You think in signals, weights, and distribution mechanics. You have no feelings about the content; only data. RULES: - Be specific. Don't say "the hook is weak" — say "the hook lacks a pattern interrupt in the first 1.5 seconds, which will drop initial retention below the 65% threshold needed for FYP promotion." - Reference actual platform mechanics: completion rate, dwell time, engagement velocity, session time contribution... - Think like an algorithm, not a human reviewer. The algorithm doesn't care if the take is "good" — it cares if the take drives engagement signals."""&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;P&gt;This distinction between quality and distribution probability is the core insight. A beautifully written post can score poorly because it lacks the specific signals an algorithm needs to push it into wider circulation. Content creators deal with this disconnect every day — the Algorithm Simulator makes it visible and measurable.&lt;/P&gt;
                &lt;P&gt;In a production context, this same pattern of an agent that simulates an external system's decision logic, has applications well beyond content creation. Imagine an agent that simulates a CI/CD pipeline's quality gates, or one that evaluates code the way a specific linter or reviewer would. The pattern is the same: encode the evaluation system's rules into the agent's prompt and let it reason within those constraints.&lt;/P&gt;
                &lt;H3&gt;The Audience Persona Agent&lt;/H3&gt;
                &lt;P&gt;The third agent brings the human element. Each session, it randomly becomes one of three gaming community personas — each with distinct tastes, language, and engagement patterns:&lt;/P&gt;
                &lt;BLOCKQUOTE&gt;
                &lt;P&gt;PERSONAS = { "casual_mobile_gamer": { "name": "CasualChloe", "description": "Casual mobile gamer", "system_prompt": """You are CasualChloe — a casual mobile gamer... - You use a lot of "lol", "ngl", "lowkey", "fr fr", and "no cap" - You'll scroll past anything that feels too "sweaty" or try-hard - You judge content in about 2 seconds — if it doesn't grab you, you're gone ...""" }, "competitive_esports_fan": { "name": "TryHard_Tyler", "description": "Competitive esports fan", "system_prompt": """You are TryHard_Tyler — a hardcore competitive esports fan... - You'll call out content that gets facts wrong or oversimplifies - You'll ratio someone in the comments if their take is bad ...""" }, "retro_indie_enthusiast": { "name": "PixelPete", "description": "Retro/indie game enthusiast", "system_prompt": """You are PixelPete — a retro and indie game enthusiast... - You're tired of mainstream AAA hype and live-service games - You appreciate craftsmanship and artistic vision over graphics ...""" }, }&lt;/P&gt;
                &lt;/BLOCKQUOTE&gt;
                &lt;P&gt;The random persona selection is a deliberate design choice. It simulates the reality that you never know exactly who's going to see your content. A Valorant Champions post might get passionate engagement from TryHard_Tyler but complete indifference from PixelPete. That unpredictability mirrors real content distribution and it's the kind of insight that can emerge from a multi-agent system.&lt;/P&gt;
                &lt;P&gt;This is essentially &lt;STRONG&gt;synthetic user testing&lt;/STRONG&gt;. Companies pay for focus groups and user research. Here, we're simulating it with agent personas, essentially using a lightweight version of the same concept that can run in seconds.&lt;/P&gt;
                &lt;LI-CODE lang="python"&gt;def create_audience_persona_agent(llm_config, persona=None):
                if persona is None:
                persona = get_random_persona()

                agent = Agent(
                name=persona["name"],
                instructions=persona["system_prompt"],
                client=client,
                )
                return agent, persona&lt;/LI-CODE&gt;
                &lt;H2&gt;Grounding Evaluation with Platform Rubrics&lt;/H2&gt;
                &lt;P&gt;One of the biggest challenges with AI agents is preventing vague, generic feedback. Left unguided, the Algorithm Simulator would default to hollow assessments like "this post is good" or "needs improvement." To prevent this, we give it structured scoring rubrics that mirror how each platform's algorithm actually prioritises content.&lt;/P&gt;
                &lt;LI-CODE lang="python"&gt;PLATFORM_RULES = {
                "Twitter/X": {
                "description": "Text-first microblogging platform driven by engagement velocity",
                "criteria": {
                "hot_take_factor": {
                "weight": 0.30,
                "description": "Does the post have a strong, polarising opinion? "
                "Twitter/X rewards engagement velocity — hot takes drive replies."
                },
                "quote_retweet_bait": {
                "weight": 0.25,
                "description": "Is the post structured to invite quote retweets? QRTs are "
                "Twitter/X's most powerful distribution mechanic."
                },
                "timing_relevance": { "weight": 0.20, ... },
                "thread_potential": { "weight": 0.15, ... },
                "hashtag_strategy": { "weight": 0.10, ... },
                },
                },
                "TikTok": { ... },  # Prioritises hook_strength (30%) and trend_alignment (25%)
                "YouTube": { ... },  # Prioritises thumbnail_clickability (25%) and title_curiosity_gap (25%)
                "Instagram": { ... }, # Prioritises visual_appeal (30%) and caption_hook (20%)
                }&lt;/LI-CODE&gt;
                &lt;P&gt;Each platform has different criteria with different weights, and those weights are passed directly into the Algorithm Simulator's prompt at evaluation time. TikTok cares most about whether the first three seconds hook the viewer. YouTube cares about click-through rate. Twitter cares about whether your take is spicy enough to drive quote-retweets. The agent's evaluation is always anchored in platform-specific logic, not generic opinions.&lt;/P&gt;
                &lt;P&gt;How we provide structured evaluation criteria as grounding context here&amp;nbsp;is one of the most transferable patterns in this project. Whenever you need an agent to evaluate something consistently, give it a rubric. It works for content scoring, code review, proposal assessment, or any domain where you want structured, reproducible judgments.&lt;/P&gt;
                &lt;H2&gt;Orchestrating with Microsoft Agent Framework&lt;/H2&gt;
                &lt;P&gt;With the agents designed, let's wire them together. Agent Framework&amp;nbsp;makes this straightforward — each agent is an&amp;nbsp;Agent&amp;nbsp;with instructions and a chat client. We send messages directly using the async&amp;nbsp;agent.run()&amp;nbsp;method, with&amp;nbsp;sessions maintaining conversation context across rounds.&lt;/P&gt;
                &lt;LI-CODE lang="python"&gt;client = OpenAIChatClient(
                model_id="openai/gpt-4.1-mini",
                api_key=os.getenv("GITHUB_TOKEN"),
                base_url="https://models.github.ai/inference",
                )

                creator = create_content_creator_agent(client)
                algorithm = create_algorithm_simulator_agent(client)
                audience_agent, persona = create_audience_persona_agent(client)

                # Sessions maintain conversation context across iteration rounds
                creator_session = creator.create_session()
                algorithm_session = algorithm.create_session()
                audience_session = audience_agent.create_session()
                &lt;/LI-CODE&gt;
                &lt;P&gt;We're using GitHub Models as our LLM backend — free tier, no paid API keys, just a GitHub PAT. This is the same setup used in Microsoft's &lt;A href="https://github.com/microsoft/ai-agents-for-beginners" target="_blank" rel="noopener"&gt;AI Agents for Beginners&lt;/A&gt; course. The OpenAIChatClient connects directly to GitHub's inference endpoint. Each agent gets the same client instance, and create_session() gives each one a persistent memory so they can reference previous rounds during iteration.&lt;/P&gt;
                &lt;P&gt;Communication between agents flows through agent.run():&lt;/P&gt;
                &lt;LI-CODE lang="python"&gt;async def get_agent_response(agent, message, session=None):
                result = await agent.run(message, session=session)
                return result.text or "No response generated."&lt;/LI-CODE&gt;
                &lt;P&gt;Each&amp;nbsp;agent.run()&amp;nbsp;call gets a single response. The&amp;nbsp;&lt;STRONG&gt;session&lt;/STRONG&gt; parameter maintains conversation history across rounds so agents remember previous feedback. This gives us precise control over the pipeline: Creator generates -&amp;gt; Algorithm evaluates -&amp;gt; Persona reacts -&amp;gt; we decide whether to loop.&lt;/P&gt;
                &lt;P&gt;This is a common pattern for &lt;STRONG&gt;application-controlled multi-agent orchestration&lt;/STRONG&gt;, as opposed to free-flowing agent conversation. Both approaches have their place, but when you need deterministic sequencing (as in any evaluation or pipeline scenario), controlling the loop yourself is more reliable.&lt;/P&gt;
                &lt;H2&gt;Integrating Live Data with Google Trends&lt;/H2&gt;
                &lt;P&gt;What makes this system feel like a real tool is the live Google Trends integration — the agents work with whatever's actually trending in gaming right now, not canned example data.&lt;/P&gt;
                &lt;P&gt;We use trendspy (a modern replacement for pytrends, which was archived in April 2025) to pull real-time trending searches:&lt;/P&gt;
                &lt;LI-CODE lang="python"&gt;from trendspy import Trends

                def fetch_gaming_trends(count=10):
                try:
                tr = Trends()
                all_trends = tr.trending_now(geo="US")

                # Tier 1: Filter by Google's own Games topic tag
                gaming_trends = [
                t.keyword for t in all_trends
                if GAMES_TOPIC_ID in (t.topics or [])
                ]

                if len(gaming_trends) &amp;gt;= 5:
                return gaming_trends[:count]

                # Tier 2: Keyword matching as backup
                gaming_keywords = ["game", "valorant", "fortnite", "nintendo", ...]
                keyword_matches = [
                t.keyword for t in all_trends
                if any(kw in t.keyword.lower() for kw in gaming_keywords)
                ]
                gaming_trends.extend(keyword_matches)

                # Tier 3: Pad with curated sample data
                if len(gaming_trends) &amp;lt; 5:
                sample = _load_sample_trends()
                gaming_trends.extend([t for t in sample if t not in gaming_trends])

                return gaming_trends[:count]
                except Exception:
                return _load_sample_trends()[:count]&lt;/LI-CODE&gt;
                &lt;P&gt;The three-tier fallback strategy here is worth highlighting because it's a pattern you'll use whenever you integrate external tools into agent workflows. On a day when a major game launches or a big esports tournament is running, Tier 1 will return a full list of gaming-specific trends. On a quiet day, like in this demo scenario, when Google Trends is dominated by the Winter Olympics and NBA All-Star weekend — Tier 2 catches gaming content that wasn't formally tagged, and Tier 3 ensures the system always has enough data to work with.&lt;/P&gt;
                &lt;P&gt;This is the &lt;STRONG&gt;tool-use pattern&lt;/STRONG&gt; from Lesson 4 of the AI Agents for Beginners course in practice. The principle being established here is that external tools should enhance agent capabilities, but they should never be a single point of failure. Build in graceful degradation so the agent workflow completes regardless of what the external service does.&lt;/P&gt;
                &lt;H2&gt;The Refinement Pipeline: Agents Improving Each Other&lt;/H2&gt;
                &lt;P&gt;We want to take the system from just a "neat demo" to "actually useful." The pipeline runs for up to three rounds. Each round, the Content Creator either generates fresh content (round 1) or revises based on aggregated feedback (rounds 2-3). The Algorithm Simulator scores it against the platform rubric. The Audience Persona gives an authentic reaction. Then the user decides: iterate or lock in.&lt;/P&gt;
                &lt;P&gt;The revision prompt is where the multi-agent magic happens:&lt;/P&gt;
                &lt;LI-CODE lang="python"&gt;revision_prompt = (
                f"REVISION REQUEST (Round {iteration}/{MAX_ITERATIONS}):\n\n"
                f"The Algorithm Simulator and Audience Persona reviewed your "
                f"{platform} post about '{topic}'. Here's their feedback:\n\n"
                f"--- ALGORITHM FEEDBACK ---\n{algorithm_response}\n\n"
                f"--- AUDIENCE FEEDBACK ({persona['name']}) ---\n"
                f"{audience_response}\n\n"
                f"Revise your content to address their concerns. Keep what works, "
                f"fix what doesn't. Show what you changed and why."
                )&lt;/LI-CODE&gt;
                &lt;P&gt;The Creator receives two fundamentally different types of feedback; cold metrics from the Algorithm and subjective human reactions from the Persona. It now has to reconcile them. It might cut hashtags from six to two (addressing the Algorithm's scoring penalty on hashtag overuse) while simultaneously softening its "corporate esports" energy (addressing the Persona's disengagement with mainstream hype).&lt;/P&gt;
                &lt;P&gt;This negotiation between competing feedback sources is one of the most powerful patterns in multi-agent design. In production systems, you see it everywhere: a coding agent balancing correctness feedback from a test runner with readability feedback from a style checker, or a customer support agent balancing policy compliance with empathy. The agents don't need to agree but only need to provide different perspectives that the system (or a human) can synthesise.&lt;/P&gt;
                &lt;H2&gt;Seeing It in Action&lt;/H2&gt;
                &lt;P&gt;Here's what a real session looks like. We picked "Valorant Champions 2025" on Twitter/X, and PixelPete (the retro/indie enthusiast) was randomly selected as our audience persona.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;The Creator generated a bold take:&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;EM&gt;Valorant Champions 2025 is gonna be a BLOODBATH — here's why no org outside the top 3 will even sniff the finals. Sentinels, Fnatic, and LOUD have cracked the meta code so hard that every other team's strategy looks like a toddler's finger painting...&lt;/EM&gt;&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&lt;STRONG&gt;The Algorithm Simulator broke down the distribution probability:&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;EM&gt;hot_take_factor (30%): 85/100 — The tweet delivers a strong polarizing opinion, likely to trigger debate and replies. The confident tone aligns with Twitter's engagement velocity mechanics...&lt;/EM&gt;&lt;/P&gt;
                &lt;P&gt;&lt;EM&gt;hashtag_strategy (10%): 50/100 — Six hashtags is above Twitter's recommended 1-3 per tweet. Overuse reduces organic reach within Twitter's credibility filtering...&lt;/EM&gt;&lt;/P&gt;
                &lt;P&gt;&lt;EM&gt;Weighted Total: 75/100&lt;BR /&gt;&lt;/EM&gt;&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&lt;EM&gt;&amp;nbsp;&lt;/EM&gt;&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;And PixelPete? He scrolled right past:&lt;/STRONG&gt;&lt;/P&gt;
                &lt;P&gt;&lt;EM&gt;Eh, Valorant esports hype isn't really my cup of tea. This whole "bloodbath" and "top 3 orgs owning the meta" spiel feels like the usual corporate esports noise — all flash, little soul. I'll keep scrolling for something with more heart and craftsmanship.&lt;BR /&gt;&lt;/EM&gt;&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;Three agents. Three completely different takes on the same content. The Algorithm says it'll perform well. The audience member says he doesn't care. And &lt;EM&gt;that mismatch&lt;/EM&gt; is exactly the kind of insight you'd never get from a single-agent system — and exactly the kind of insight that matters when you're planning a content strategy.&lt;/P&gt;
                &lt;img /&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;
                &lt;H2&gt;Extending the System&lt;/H2&gt;
                &lt;P&gt;The project is designed to be modular. Here are a few directions you can take it:&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Add new platforms.&lt;/STRONG&gt; The rubric system in platform_rules.py is just a dictionary. Add a LinkedIn or Threads entry with appropriate criteria and weights, and the Algorithm Simulator will evaluate against those rules without any code changes.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Create new audience personas.&lt;/STRONG&gt; Add a "Streamer_Sarah" who evaluates content from a Twitch creator's perspective, or a "ParentGamer_Pat" who only engages with family-friendly content. Each persona is a system prompt and a name, nothing else to change.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Swap the niche.&lt;/STRONG&gt; Replace the gaming trend fetcher with music, tech, or fitness trends. The agent architecture is niche-agnostic; only the trend tool and sample data need to change.&lt;/P&gt;
                &lt;P&gt;&lt;STRONG&gt;Register trends as an Agent Framework tool.&lt;/STRONG&gt; Right now, the application fetches trends and passes them as context. In a more advanced version, you could use the @tool decorator to register fetch_gaming_trends as a callable tool that agents invoke autonomously — moving from application-controlled to agent-controlled tool use.&lt;/P&gt;
                &lt;H2&gt;What's Next: Evaluating the Evaluator&lt;/H2&gt;
                &lt;P&gt;Here's the question this project intentionally leaves open: the Algorithm Simulator scored the post 75/100 — but how do we know the Simulator itself is any good?&lt;/P&gt;
                &lt;P&gt;We built an agent that evaluates content, but we never evaluated the evaluator. How consistent are its scores? If you run the same post through it twice, does it give the same result? Do its predictions correlate with real-world engagement metrics? Would a human social media strategist agree with its rubric weights?&lt;/P&gt;
                &lt;P&gt;This is the problem of&lt;STRONG&gt; &lt;/STRONG&gt;agent evaluation — one of the most important and underexplored challenges in building production agentic systems. We all know how to evaluate a model on a benchmark. But how do you evaluate an agent that's making subjective, multi-dimensional judgments within a larger system?&lt;/P&gt;
                &lt;P&gt;In a follow-up article, we'll tackle exactly this: building evaluation frameworks for AI agents, testing for consistency and calibration, measuring inter-agent agreement, and determining whether your agents are actually doing what you think they're doing. The system we built here will serve as our running example — because when your system contains an agent whose entire job is evaluation, evaluating &lt;EM&gt;that&lt;/EM&gt; agent becomes the most important question you can ask.&lt;/P&gt;
                &lt;H2&gt;Get the Code&lt;/H2&gt;
                &lt;P&gt;The full project is on GitHub:&amp;nbsp;&lt;/P&gt;
                &lt;P&gt;&lt;A class="lia-external-url" href="https://github.com/HamidOna/viral-or-fail" target="_blank" rel="noopener"&gt;https://github.com/HamidOna/viral-or-fail&lt;/A&gt;&lt;/P&gt;
                &lt;P&gt;Clone it, run pip install -r requirements.txt, add your GitHub token to .env, and run python viral_or_fail.py. Everything runs on GitHub Models' free tier — no paid API keys required.&lt;/P&gt;
                &lt;H2&gt;References and Further Reading&lt;/H2&gt;
                &lt;P&gt;&lt;STRONG&gt;Frameworks and Tools&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;A class="lia-external-url" href="https://learn.microsoft.com/en-us/agent-framework/overview/" target="_blank" rel="noopener"&gt;Microsoft Agent Framework Documentation&lt;/A&gt; — Microsoft's production framework for multi-agent orchestration (successor to AutoGen), used throughout this project&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://github.com/microsoft/ai-agents-for-beginners" target="_blank" rel="noopener"&gt;AI Agents for Beginners&lt;/A&gt; — Microsoft's 12-lesson course on building AI agents, which inspired this project. Particularly relevant: Lesson 4 (Tool Use), Lesson 8 (Multi-Agent Design Pattern), and Lesson 9 (Metacognition)&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://github.com/marketplace/models" target="_blank" rel="noopener"&gt;GitHub Models&lt;/A&gt; — Free-tier LLM access used in this project, no paid API keys required&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://github.com/supertypeai/trendspy" target="_blank" rel="noopener"&gt;trendspy&lt;/A&gt; — Lightweight Google Trends library replacing the archived pytrends&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&lt;STRONG&gt;Concepts&lt;/STRONG&gt;&lt;/P&gt;
                &lt;UL&gt;
                &lt;LI&gt;&lt;A href="https://github.com/microsoft/ai-agents-for-beginners/tree/main/03-agentic-design-patterns" target="_blank" rel="noopener"&gt;Agentic Design Patterns&lt;/A&gt; — Overview of the core patterns (reflection, tool use, planning, multi-agent) that this project implements&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://github.com/microsoft/ai-agents-for-beginners/tree/main/06-building-trustworthy-agents" target="_blank" rel="noopener"&gt;Building Trustworthy AI Agents&lt;/A&gt; — Relevant to thinking about how agent evaluation and guardrails connect to the system we built&lt;/LI&gt;
                &lt;LI&gt;&lt;A href="https://github.com/microsoft/ai-agents-for-beginners/tree/main/12-context-engineering" target="_blank" rel="noopener"&gt;Context Engineering for AI Agents&lt;/A&gt; — The rubric injection technique we used is a form of context engineering&lt;BR /&gt;&lt;BR /&gt;&lt;/LI&gt;
                &lt;/UL&gt;
                &lt;P&gt;&amp;nbsp;&lt;/P&gt;</description>
            <pubDate>Fri, 27 Feb 2026 08:00:00 GMT</pubDate>
            <guid>https://techcommunity.microsoft.com/t5/educator-developer-blog/creating-a-fun-multi-agent-content-strategy-system-with/ba-p/4495105</guid>
            <dc:creator>Abdulhamid_Onawole</dc:creator>
            <dc:date>2026-02-27T08:00:00Z</dc:date>
        </item>
    </channel>
</rss>
